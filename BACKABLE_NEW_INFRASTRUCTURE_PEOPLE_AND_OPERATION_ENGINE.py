import logging
import warnings
import requests
import time
import json
import re
import random
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple, Union
from pathlib import Path
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
import numpy as np
from dotenv import load_dotenv
import os
import pandas as pd
import tiktoken
import io
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
from threading import Thread
from fastapi import FastAPI, Request, Response, HTTPException, BackgroundTasks, Depends, Header, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel
import jwt
import hashlib
from psycopg2.extras import RealDictCursor
from azure.storage.blob import BlobServiceClient, ContainerClient, ContentSettings
import psycopg2
import uvicorn
import base64
from dataclasses import dataclass
from typing import Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
import aiohttp
from typing import Optional, Dict, Any
import platform
from contextlib import asynccontextmanager
from collections import deque
import statistics
import asyncpg
import threading, sys
from collections import defaultdict

# Google GenAI SDK for Vertex AI (new architecture - primary method)
from google import genai
from google.oauth2 import service_account

# Global connection pools with better management
_connection_pools = {}
_pool_creation_locks = defaultdict(asyncio.Lock)
_pool_lock = asyncio.Lock()  # Add this missing global lock


# ======================================================
#                 Configuration
# ======================================================

# Windows-specific event loop fix for aiohttp
if platform.system() == 'Windows':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# Notification configuration
NOTIFICATION_API_URL = "https://philotimo-backend-staging.azurewebsites.net/send-notification"
NOTIFICATION_TIMEOUT = 10  # seconds

# Indexer configuration
INDEXER_API_BASE_URL = "https://autoindexerwebapp.azurewebsites.net"
INDEXER_TIMEOUT = 300  # 5 minutes timeout for indexer operations
INDEXER_RETRY_ATTEMPTS = 3
INDEXER_RETRY_DELAY = 30  # seconds

# People and Operations Engine Database Configuration
PEOPLE_OPS_DB_CONFIG = {
    "host": "memberchat-db.postgres.database.azure.com",
    "database": "BACKABLE-PEOPLE-AND-OPERATIONS-ENGINE",
    "user": "backable",
    "password": "Utkar$h007",
    "port": 5432,
    "sslmode": "require"
}

async def get_db_pool(db_config: Dict):
    """FIXED: Get or create connection pool for database with Python 3.10 compatibility"""
    global _connection_pools, _pool_creation_locks
    
    # FIX 1: Clean and validate database name to prevent typos
    db_key = str(db_config['database']).strip()
    
    # FIX 2: Validate against known good database names
    valid_db_names = {
        "BACKABLE-PROFILE-ENGINE",
        "BACKABLE-THE-ANALYST", 
        "BACKABLE-THE-GROWTH-ENGINE",
        "BACKABLE-COMPONENT-ENGINE",
        "BACKABLE-DREAM-ANALYZER",
        "BACKABLE-PEOPLE-AND-OPERATIONS-ENGINE",
        "philotimodb"
    }
    
    if db_key not in valid_db_names:
        logging.error(f"‚ùå INVALID DATABASE NAME: '{db_key}' not in valid list")
        # Try to find closest match and correct
        for valid_name in valid_db_names:
            clean_valid = valid_name.replace('-', '').replace('_', '').lower()
            clean_input = db_key.replace('-', '').replace('_', '').lower()
            if clean_valid in clean_input or clean_input in clean_valid:
                logging.warning(f"üîß AUTO-CORRECTING: '{db_key}' ‚Üí '{valid_name}'")
                db_key = valid_name
                break
        else:
            raise ValueError(f"Cannot map database name '{db_key}' to valid database")
    
    pool_creation_start = time.time()
    
    logging.info(f"üîó POOL REQUEST: Starting pool acquisition for {db_key}")
    logging.info(f"üìä Pool request details:")
    logging.info(f"   - Database: {db_config.get('database', 'Unknown')}")
    logging.info(f"   - Host: {db_config.get('host', 'Unknown')}")
    logging.info(f"   - User: {db_config.get('user', 'Unknown')}")
    logging.info(f"   - Port: {db_config.get('port', 'Unknown')}")
    logging.info(f"   - Current pools in memory: {len(_connection_pools)}")
    logging.info(f"   - Existing pool keys: {list(_connection_pools.keys())}")
    
    # CRITICAL FIX 3: Check if pool exists and validate its health
    if db_key in _connection_pools:
        existing_pool = _connection_pools[db_key]
        logging.info(f"üîç POOL EXISTS: Found existing pool for {db_key}")
        logging.info(f"üìä Existing pool details:")
        logging.info(f"   - Pool object type: {type(existing_pool)}")
        logging.info(f"   - Pool closed status: {getattr(existing_pool, '_closed', 'Unknown')}")
        
        # CRITICAL FIX: Health check with Python 3.10 compatible timeout
        try:
            logging.info(f"üß™ HEALTH CHECK: Testing existing pool for {db_key}")
            health_check_start = time.time()
            
            # FIX 3: Use asyncio.wait_for instead of asyncio.timeout (Python 3.10 compatible)
            async def health_check():
                async with existing_pool.acquire() as test_conn:
                    await test_conn.execute('SELECT 1')
            
            await asyncio.wait_for(health_check(), timeout=3.0)
            
            health_check_time = time.time() - health_check_start
            logging.info(f"‚úÖ HEALTH CHECK PASSED: Pool {db_key} is healthy ({health_check_time:.3f}s)")
            logging.info(f"üìä Pool stats:")
            logging.info(f"   - Min size: {getattr(existing_pool, '_minsize', 'Unknown')}")
            logging.info(f"   - Max size: {getattr(existing_pool, '_maxsize', 'Unknown')}")
            logging.info(f"   - Current size: {getattr(existing_pool, 'get_size', lambda: 'Unknown')()}")
            logging.info(f"   - Idle connections: {getattr(existing_pool, 'get_idle_size', lambda: 'Unknown')()}")
            
            return existing_pool
            
        except asyncio.TimeoutError:
            logging.error(f"‚è∞ HEALTH CHECK TIMEOUT: Pool {db_key} timed out after 3s")
            logging.error(f"üîß Pool appears to be stuck, will recreate")
        except Exception as health_error:
            logging.error(f"‚ùå HEALTH CHECK FAILED: Pool {db_key} failed health check: {health_error}")
            logging.error(f"üîß Pool is corrupted, will recreate")
            logging.error(f"üîç Health check error type: {type(health_error).__name__}")
        
        # FIX 4: Proper cleanup of failed pool
        logging.warning(f"üóëÔ∏è REMOVING UNHEALTHY POOL: {db_key}")
        try:
            if not existing_pool.is_closing():
                await existing_pool.close()
                # Wait for pool to actually close
                await asyncio.sleep(0.1)
            logging.info(f"‚úÖ Closed unhealthy pool for {db_key}")
        except Exception as close_error:
            logging.error(f"‚ùå Error closing unhealthy pool: {close_error}")
        finally:
            # Always remove from dictionary
            _connection_pools.pop(db_key, None)
            logging.info(f"‚úÖ Removed {db_key} from pools dictionary")
    
    # CRITICAL FIX 5: Create new pool with enhanced safety using per-database locks
    async with _pool_creation_locks[db_key]:
        # Double-check pool doesn't exist (race condition protection)
        if db_key not in _connection_pools:
            logging.info(f"üèóÔ∏è CREATING NEW POOL: Starting pool creation for {db_key}")
            
            try:
                # Validate required config keys
                required_config_keys = ['host', 'database', 'user', 'password', 'port']
                missing_keys = [key for key in required_config_keys if not db_config.get(key)]
                
                if missing_keys:
                    raise ValueError(f"Missing required database config keys: {missing_keys}")
                
                logging.info(f"‚úÖ Database config validation passed for {db_key}")
                
                # FIX 5: Test connection first before creating pool
                try:
                    test_conn = await asyncio.wait_for(
                        asyncpg.connect(
                            host=db_config["host"],
                            database=db_config["database"],
                            user=db_config["user"],
                            password=db_config["password"],
                            port=db_config["port"],
                            ssl="require"
                        ),
                        timeout=5.0
                    )
                    await test_conn.close()
                    logging.info(f"‚úÖ Connection test passed for {db_key}")
                except Exception as test_error:
                    logging.error(f"‚ùå Connection test failed for {db_key}: {test_error}")
                    raise Exception(f"Cannot connect to database {db_key}: {test_error}")
                
                # FIX 6: Reduced pool configuration for stability
                pool_config = {
                    "host": db_config["host"],
                    "database": db_config["database"],
                    "user": db_config["user"],
                    "password": db_config["password"],
                    "port": db_config["port"],
                    "ssl": "require",
                    "min_size": 1,  # Minimum connections
                    "max_size": 2,  # REDUCED: From 5 to 2 for stability
                    "command_timeout": 15,  # REDUCED: From 30 to 15
                    "server_settings": {
                        'application_name': f'backable_people_ops_{db_key.replace("-", "_")}',
                        'jit': 'off',
                        'tcp_keepalives_idle': '300',
                        'tcp_keepalives_interval': '30',
                        'tcp_keepalives_count': '3'
                    }
                }
                
                logging.info(f"üîß Pool configuration:")
                logging.info(f"   - Min size: {pool_config['min_size']}")
                logging.info(f"   - Max size: {pool_config['max_size']}")
                logging.info(f"   - Command timeout: {pool_config['command_timeout']}s")
                logging.info(f"   - SSL: {pool_config['ssl']}")
                
                # FIX 7: Create pool with shorter timeout
                pool_creation_timeout = 10.0  # REDUCED: From 15s to 10s
                
                logging.info(f"‚è≥ Creating pool with {pool_creation_timeout}s timeout...")
                pool_start_time = time.time()
                
                pool = await asyncio.wait_for(
                    asyncpg.create_pool(**pool_config),
                    timeout=pool_creation_timeout
                )
                
                pool_creation_time = time.time() - pool_start_time
                logging.info(f"‚úÖ Pool creation successful in {pool_creation_time:.3f}s")
                
                # FIX 8: Quick post-creation validation with Python 3.10 compatible timeout
                logging.info(f"üß™ POST-CREATION VALIDATION: Testing new pool for {db_key}")
                validation_start = time.time()
                
                try:
                    # PYTHON 3.10 COMPATIBLE: Use asyncio.wait_for instead of asyncio.timeout
                    async def validation_test():
                        async with pool.acquire() as test_conn:
                            await test_conn.execute('SELECT 1')
                    
                    await asyncio.wait_for(validation_test(), timeout=2.0)
                    
                    validation_time = time.time() - validation_start
                    logging.info(f"‚úÖ Post-creation validation passed ({validation_time:.3f}s)")
                    
                    # Store pool
                    _connection_pools[db_key] = pool
                    
                    # Log final pool status
                    total_time = time.time() - pool_creation_start
                    logging.info(f"üéâ POOL READY: {db_key} pool fully operational")
                    logging.info(f"üìä Final pool statistics:")
                    logging.info(f"   - Total creation time: {total_time:.3f}s")
                    logging.info(f"   - Pool size: {pool.get_size()}")
                    logging.info(f"   - Idle connections: {pool.get_idle_size()}")
                    logging.info(f"   - Pool status: HEALTHY")
                    logging.info(f"   - Pools in memory: {len(_connection_pools)}")
                    
                except Exception as validation_error:
                    logging.error(f"‚ùå POST-CREATION VALIDATION FAILED: {validation_error}")
                    logging.error(f"üîß Closing failed pool...")
                    
                    try:
                        await pool.close()
                        await asyncio.sleep(0.1)  # Wait for cleanup
                    except Exception:
                        pass
                    
                    raise Exception(f"Pool validation failed: {validation_error}")
                
            except asyncio.TimeoutError:
                pool_creation_time = time.time() - pool_creation_start
                logging.error(f"‚è∞ POOL CREATION TIMEOUT: {db_key} timed out after {pool_creation_timeout}s")
                raise Exception(f"Pool creation timed out after {pool_creation_timeout}s")
                
            except Exception as creation_error:
                pool_creation_time = time.time() - pool_creation_start
                logging.error(f"‚ùå POOL CREATION FAILED: Error creating pool for {db_key}")
                logging.error(f"üîç Error: {type(creation_error).__name__}: {creation_error}")
                raise Exception(f"Failed to create pool for {db_key}: {creation_error}")
        
        else:
            # Pool was created by another task during lock wait
            existing_pool = _connection_pools[db_key]
            total_time = time.time() - pool_creation_start
            logging.info(f"üèÉ RACE CONDITION: Pool {db_key} was created by another task ({total_time:.3f}s)")
    
    # FINAL RETURN: Return the pool
    final_pool = _connection_pools[db_key]
    total_function_time = time.time() - pool_creation_start
    
    logging.info(f"üéØ POOL ACQUIRED: Returning pool for {db_key}")
    logging.info(f"üìä Final acquisition statistics:")
    logging.info(f"   - Total function time: {total_function_time:.3f}s")
    logging.info(f"   - Pool object: {type(final_pool)}")
    logging.info(f"   - Pool size: {final_pool.get_size()}")
    logging.info(f"   - Idle connections: {final_pool.get_idle_size()}")
    logging.info(f"   - Pool health: VALIDATED")
    
    return final_pool

# Multi-Database Intelligence Sources
COMPONENT_DB_CONFIG = {
    "host": "memberchat-db.postgres.database.azure.com",
    "database": "BACKABLE-COMPONENT-ENGINE",
    "user": "backable",
    "password": "Utkar$h007",
    "port": 5432,
    "sslmode": "require"
}

PROFILE_DB_CONFIG = {
    "host": "memberchat-db.postgres.database.azure.com",
    "database": "BACKABLE-PROFILE-ENGINE",
    "user": "backable",
    "password": "Utkar$h007",
    "port": 5432,
    "sslmode": "require"
}

DREAM_DB_CONFIG = {
    "host": "memberchat-db.postgres.database.azure.com",
    "database": "BACKABLE-DREAM-ANALYZER",
    "user": "backable",
    "password": "Utkar$h007",
    "port": 5432,
    "sslmode": "require"
}

ANALYST_DB_CONFIG = {
    "host": "memberchat-db.postgres.database.azure.com",
    "database": "BACKABLE-THE-ANALYST",
    "user": "backable",
    "password": "Utkar$h007",
    "port": 5432,
    "sslmode": "require"
}

GROWTH_DB_CONFIG = {
    "host": "memberchat-db.postgres.database.azure.com",
    "database": "BACKABLE-THE-GROWTH-ENGINE",
    "user": "backable",
    "password": "Utkar$h007",
    "port": 5432,
    "sslmode": "require"
}

USER_DB_CONFIG = {
    "host": "philotimo-staging-db.postgres.database.azure.com",
    "database": "philotimodb",
    "user": "wchen",
    "password": "DevPhilot2024!!",
    "port": 5432,
    "sslmode": "require"
}

AZURE_STORAGE_CONNECTION_STRING = os.getenv(
    'AZURE_STORAGE_CONNECTION_STRING',
    # Fallback for local development (should not be used in production)
    ""
)

ONBOARDING_DB_HOST = "memberchat-db.postgres.database.azure.com"
ONBOARDING_DB_NAME = "BACKABLE-GOOGLE-RAG"  # Updated to new unified architecture database
ONBOARDING_DB_USER = "backable"
ONBOARDING_DB_PASSWORD = "Utkar$h007"
ONBOARDING_DB_PORT = 5432

# ======================================================
#   Gemini 2.5 Pro Configuration - PEOPLE & OPERATIONS
# ======================================================
# Enhanced API Key Management - Load from environment variables
def load_api_keys_from_env():
    """Load API keys from environment variables"""
    api_keys_config = {}

    # Try to load 10 API keys from environment
    for i in range(1, 11):
        env_key = f"GEMINI_API_KEY_{i:02d}"
        api_key = os.getenv(env_key)
        if api_key:
            api_keys_config[api_key] = {
                "name": f"Back_Peop{i:02d}",
                "priority": 1,
                "health": True
            }

    # Fallback: if no env keys found, log warning
    if not api_keys_config:
        logging.warning("‚ö†Ô∏è No GEMINI_API_KEY environment variables found!")
    else:
        logging.info(f"‚úÖ Loaded {len(api_keys_config)} Gemini API keys from environment")

    return api_keys_config

API_KEYS_CONFIG = load_api_keys_from_env()
GEMINI_API_KEYS = list(API_KEYS_CONFIG.keys())

# ======================================================
#           Vertex AI Configuration (Primary Method)
# ======================================================
VERTEX_PROJECT_ID = "backable-machine-learning-apis"
VERTEX_LOCATION = "us-central1"
USE_VERTEX_AI = True  # Primary method - will fallback to API keys if fails

# API Key Management Variables
api_key_stats = defaultdict(lambda: {"requests": 0, "failures": 0, "last_used": 0, "cooldown_until": 0})
api_key_lock = threading.Lock()

# Configuration - INCREASED RETRY VALUES
MAX_RETRIES = 10                    # Increased from 2 to 10
MAX_REQUESTS_PER_ENDPOINT = 100     # Kept same
REQUEST_TIMEOUT = 120               # Kept same
MAX_SECTION_RETRIES = 10            # Increased from 3 to 10
MAX_REPORT_RETRIES = 10             # Increased from 2 to 10
MIN_ACCEPTABLE_WORDS = 100          # Kept same
RETRY_WAIT_BASE = 30                # Kept same
people_ops_job_status = {}

# ======================================================
#           Vertex AI Initialization
# ======================================================

def initialize_vertex_ai_client():
    """
    Initialize Google GenAI client for Vertex AI.
    Supports both file-based and environment variable credentials.
    Returns None if initialization fails (will use API keys fallback).
    """
    try:
        # Try loading credentials from environment variable first (Azure deployment)
        creds_json = os.getenv('GOOGLE_APPLICATION_CREDENTIALS_JSON')

        if creds_json:
            logging.info("Loading Vertex AI credentials from environment variable")
            import tempfile
            creds_dict = json.loads(creds_json)
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as temp_file:
                json.dump(creds_dict, temp_file)
                temp_path = temp_file.name

            credentials = service_account.Credentials.from_service_account_file(
                temp_path,
                scopes=['https://www.googleapis.com/auth/cloud-platform']
            )
            os.unlink(temp_path)
        else:
            # Fall back to file-based credentials (local development)
            creds_file = "vertex-key.json"
            if os.path.exists(creds_file):
                logging.info(f"Loading Vertex AI credentials from {creds_file}")
                credentials = service_account.Credentials.from_service_account_file(
                    creds_file,
                    scopes=['https://www.googleapis.com/auth/cloud-platform']
                )
            else:
                logging.warning("No Vertex AI credentials found - will use API keys fallback")
                return None

        # Initialize GenAI client
        client = genai.Client(
            vertexai=True,
            credentials=credentials,
            project=VERTEX_PROJECT_ID,
            location=VERTEX_LOCATION
        )

        logging.info(f"‚úÖ Vertex AI GenAI client initialized successfully (Project: {VERTEX_PROJECT_ID})")
        return client

    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Vertex AI initialization failed: {str(e)} - Will use API keys fallback")
        return None

# Initialize Vertex AI client at startup
vertex_ai_client = initialize_vertex_ai_client() if USE_VERTEX_AI else None

# ======================================================
#           VERTEX AI REQUEST FUNCTION
# ======================================================

def try_vertex_ai_people_ops_request(
    enhanced_prompt: str,
    temperature: float,
    max_tokens: int,
    start_time: float
) -> Optional[Dict]:
    """
    Try making request using Vertex AI (PRIMARY METHOD for People & Operations Engine).
    Returns response dict if successful, None if fails.
    """
    if not vertex_ai_client:
        logging.info("Vertex AI client not available - using API keys fallback")
        return None

    try:
        logging.info("üöÄ Trying Vertex AI (Primary Method for People & Operations Analysis)")

        # Call Vertex AI using GenAI SDK with gemini-2.5-pro
        response = vertex_ai_client.models.generate_content(
            model="gemini-2.5-pro",
            contents=enhanced_prompt,
            config={
                "temperature": temperature,
                "max_output_tokens": max_tokens,
                "top_p": 0.95,
            }
        )

        # Extract content
        if response and response.text:
            content = response.text
            token_count = response.usage_metadata.total_token_count if response.usage_metadata else 0
            request_time = time.time() - start_time

            logging.info(f"‚úÖ Vertex AI SUCCESS - {len(content.split())} words, {token_count} tokens, {request_time:.2f}s")

            return {
                "success": True,
                "content": content,
                "token_count": token_count,
                "request_time": request_time,
                "model": "gemini-2.5-pro-vertex"
            }
        else:
            logging.warning("‚ö†Ô∏è Vertex AI returned empty response - falling back to API keys")
            return None

    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Vertex AI failed: {str(e)} - Falling back to API keys")
        return None

# Add this global dictionary after your GEMINI_API_KEYS list
api_key_health = {}

def get_smart_api_key(section_index: int, retry_attempt: int = 0) -> str:
    """Enhanced smart API key selection with load balancing"""
    global api_key_health
    
    # Initialize health tracking if not exists
    if not api_key_health:
        for i, key in enumerate(GEMINI_API_KEYS):
            api_key_health[key] = {
                'last_503_time': None,
                'consecutive_failures': 0,
                'total_requests': 0,
                'key_id': f'PeopleOps_{i+1:02d}',
                'response_times': deque(maxlen=10),  # Track last 10 response times
                'success_rate': 1.0,
                'last_used': 0,
                'current_load': 0  # Track concurrent requests
            }
    
    current_time = time.time()
    
    # Calculate health scores for all keys
    key_scores = []
    for key in GEMINI_API_KEYS:
        health = api_key_health[key]
        score = calculate_key_health_score(health, current_time)
        key_scores.append((key, score, health))
    
    # Sort by health score (higher is better)
    key_scores.sort(key=lambda x: x[1], reverse=True)
    
    # Select best available key
    for key, score, health in key_scores:
        if score > 0:  # Key is usable
            # Update usage tracking
            health['total_requests'] += 1
            health['last_used'] = current_time
            health['current_load'] += 1
            
            logging.info(f"üîë [{section_index}] Selected {health['key_id']} (score: {score:.2f}, load: {health['current_load']})")
            return key
    
    # Fallback: use least recently failed key
    logging.warning("‚ö†Ô∏è All keys degraded, using least recently failed")
    fallback_key = min(GEMINI_API_KEYS, 
                      key=lambda k: api_key_health[k]['last_503_time'] or 0)
    api_key_health[fallback_key]['total_requests'] += 1
    return fallback_key

# ======================================================
# STEP 1: Add the reset functions BEFORE your generate_people_ops_section_with_dedicated_client function
# ======================================================

def reset_api_key_immediately(api_key: str):
    """Immediately reset a failed API key with detailed logging"""
    if api_key in api_key_health:
        old_health = api_key_health[api_key].copy()
        
        # Reset critical health metrics
        api_key_health[api_key]['consecutive_failures'] = 0
        api_key_health[api_key]['last_503_time'] = None
        api_key_health[api_key]['current_load'] = 0
        # Keep success_rate but improve it slightly
        old_rate = api_key_health[api_key].get('success_rate', 1.0)
        api_key_health[api_key]['success_rate'] = min(1.0, old_rate + 0.1)
        
        key_id = api_key_health[api_key].get('key_id', 'unknown')
        
        logging.info(f"üîÑ RESET API KEY: {key_id} (...{api_key[-4:]})")
        logging.info(f"üìä Reset details:")
        logging.info(f"   - Consecutive failures: {old_health.get('consecutive_failures', 0)} ‚Üí 0")
        logging.info(f"   - Success rate: {old_health.get('success_rate', 1.0):.3f} ‚Üí {api_key_health[api_key]['success_rate']:.3f}")
        logging.info(f"   - Current load: {old_health.get('current_load', 0)} ‚Üí 0")
        logging.info(f"   - Cooldown cleared: {bool(old_health.get('last_503_time'))}")
        
    else:
        logging.warning(f"‚ö†Ô∏è Cannot reset API key ...{api_key[-4:]}: not found in health tracking")

def reset_all_failed_api_keys():
    """Reset all failed API keys for batch retry"""
    global api_key_health
    
    reset_count = 0
    for api_key, health in api_key_health.items():
        if health.get('consecutive_failures', 0) >= 3:
            reset_api_key_immediately(api_key)
            reset_count += 1
    
    logging.info(f"üîÑ BATCH RESET: Reset {reset_count} failed API keys")
    return reset_count


def calculate_key_health_score(health: Dict, current_time: float) -> float:
    """Calculate health score for API key (0-100, higher is better)"""
    score = 100.0
    
    # Penalize recent 503 errors
    if health['last_503_time'] and (current_time - health['last_503_time']) < 300:
        score *= 0.1  # Major penalty for recent 503
    
    # Penalize consecutive failures
    failure_penalty = min(0.9, health['consecutive_failures'] * 0.3)
    score *= (1.0 - failure_penalty)
    
    # Penalize high current load
    load_penalty = min(0.5, health['current_load'] * 0.1)
    score *= (1.0 - load_penalty)
    
    # Bonus for good response times
    if health['response_times']:
        avg_response_time = statistics.mean(health['response_times'])
        if avg_response_time < 30:  # Fast responses
            score *= 1.2
        elif avg_response_time > 60:  # Slow responses
            score *= 0.8
    
    # Bonus for high success rate
    score *= health['success_rate']
    
    return max(0, score)

def update_api_key_health(api_key: str, success: bool, error_code: str = None, response_time: float = None):
    """Enhanced API key health update with detailed metrics"""
    global api_key_health
    
    if api_key not in api_key_health:
        return
    
    health = api_key_health[api_key]
    
    # Decrease current load
    health['current_load'] = max(0, health['current_load'] - 1)
    
    # Track response time
    if response_time:
        health['response_times'].append(response_time)
    
    if success:
        health['consecutive_failures'] = 0
        # Update success rate (sliding window)
        old_rate = health['success_rate']
        health['success_rate'] = min(1.0, old_rate * 0.9 + 0.1)  # Weighted moving average
        
        logging.debug(f"‚úÖ {health['key_id']} success (rate: {health['success_rate']:.2f})")
    else:
        health['consecutive_failures'] += 1
        # Update success rate
        old_rate = health['success_rate']
        health['success_rate'] = max(0.0, old_rate * 0.9)  # Penalize failures
        
        # Special handling for different error types
        if error_code == "503":
            health['last_503_time'] = time.time()
            logging.warning(f"üö® {health['key_id']} got 503 - cooling down")
        elif error_code == "429":
            health['last_503_time'] = time.time() - 150  # Shorter cooldown for rate limits
            logging.warning(f"üö¶ {health['key_id']} rate limited")
        
        logging.warning(f"‚ùå {health['key_id']} failed (consecutive: {health['consecutive_failures']})")

def get_load_balanced_api_key(section_index: int) -> str:
    """Get API key using round-robin with health awareness"""
    global api_key_health
    
    if not api_key_health:
        # Initialize if needed
        return get_smart_api_key(section_index, 0)
    
    current_time = time.time()
    
    # Filter healthy keys
    healthy_keys = []
    for key in GEMINI_API_KEYS:
        health = api_key_health[key]
        
        # Skip if in cooldown
        if health['last_503_time'] and (current_time - health['last_503_time']) < 180:
            continue
            
        # Skip if too many failures
        if health['consecutive_failures'] >= 3:
            continue
            
        # Skip if overloaded
        if health['current_load'] >= 3:
            continue
            
        healthy_keys.append(key)
    
    if not healthy_keys:
        # Fallback to smart selection
        return get_smart_api_key(section_index, 0)
    
    # Use weighted random selection based on inverse load
    weights = []
    for key in healthy_keys:
        load = api_key_health[key]['current_load']
        success_rate = api_key_health[key]['success_rate']
        weight = success_rate / max(1, load + 1)  # Higher success rate, lower load = higher weight
        weights.append(weight)
    
    # Weighted random selection
    selected_key = random.choices(healthy_keys, weights=weights)[0]
    
    # Update usage
    api_key_health[selected_key]['current_load'] += 1
    api_key_health[selected_key]['total_requests'] += 1
    
    health = api_key_health[selected_key]
    logging.info(f"üéØ Load balanced selection: {health['key_id']} (load: {health['current_load']}, rate: {health['success_rate']:.2f})")
    
    return selected_key

def get_api_key_status_summary() -> str:
    """Get summary of all API key health for logging"""
    if not api_key_health:
        return "No health data available"
    
    healthy_count = 0
    cooling_down = 0
    failed_count = 0
    
    for key, health in api_key_health.items():
        current_time = time.time()
        
        if health['last_503_time'] and (current_time - health['last_503_time']) < 300:
            cooling_down += 1
        elif health['consecutive_failures'] >= 3:
            failed_count += 1
        else:
            healthy_count += 1
    
    return f"Healthy: {healthy_count}, Cooling: {cooling_down}, Failed: {failed_count}"

def get_enhanced_api_key_status() -> Dict:
    """Get comprehensive API key status"""
    if not api_key_health:
        return {"status": "not_initialized"}
    
    current_time = time.time()
    status = {
        "total_keys": len(GEMINI_API_KEYS),
        "healthy_keys": 0,
        "degraded_keys": 0,
        "failed_keys": 0,
        "cooling_down": 0,
        "total_load": 0,
        "average_success_rate": 0,
        "key_details": []
    }
    
    success_rates = []
    
    for key, health in api_key_health.items():
        # Determine status
        if health['last_503_time'] and (current_time - health['last_503_time']) < 180:
            key_status = "cooling_down"
            status["cooling_down"] += 1
        elif health['consecutive_failures'] >= 3:
            key_status = "failed"
            status["failed_keys"] += 1
        elif health['consecutive_failures'] > 0 or health['success_rate'] < 0.8:
            key_status = "degraded"
            status["degraded_keys"] += 1
        else:
            key_status = "healthy"
            status["healthy_keys"] += 1
        
        status["total_load"] += health['current_load']
        success_rates.append(health['success_rate'])
        
        # Add key details
        avg_response = statistics.mean(health['response_times']) if health['response_times'] else 0
        
        status["key_details"].append({
            "key_id": health['key_id'],
            "status": key_status,
            "success_rate": health['success_rate'],
            "current_load": health['current_load'],
            "consecutive_failures": health['consecutive_failures'],
            "total_requests": health['total_requests'],
            "avg_response_time": round(avg_response, 2)
        })
    
    status["average_success_rate"] = statistics.mean(success_rates) if success_rates else 0
    
    return status

def reset_failed_api_keys():
    """Reset failed API keys for retry attempts"""
    global api_key_health
    
    reset_count = 0
    for key, health in api_key_health.items():
        if health.get('consecutive_failures', 0) >= 3:
            health['consecutive_failures'] = 1  # Reduce but don't fully reset
            health['last_503_time'] = None  # Clear cooldown
            reset_count += 1
            logging.info(f"üîÑ Partially reset API key {health.get('key_id', 'unknown')} for retry")
    
    logging.info(f"üîÑ Reset {reset_count} failed API keys for retry attempt")

# Production-optimized settings
MAX_RETRIES = 10
MAX_REQUESTS_PER_ENDPOINT = 100
REQUEST_TIMEOUT = 120  # 2 minutes
MAX_SECTION_RETRIES = 3
MAX_REPORT_RETRIES = 2
MIN_ACCEPTABLE_WORDS = 100
RETRY_WAIT_BASE = 30
people_ops_job_status = {}

# ======================================================
#           PERSONALIZED NOTIFICATION SYSTEM
# ======================================================

class PersonalizedNotificationService:
    """
    Enhanced notification service with personalized, HILARIOUS messages using Gemini AI
    FIXED for Windows compatibility
    """
    
    def __init__(self, gemini_api_key: str):
        self.gemini_api_key = gemini_api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models"
        self.model = "gemini-2.5-pro"
        
        # Professional fallback messages (used if generation fails)
        self.fallback_messages = {
            "start": [
                "Your People & Operations Engine comprehensive assessment has begun. This integrated analysis will expand your Backable Mind with organizational intelligence combining your profile, vision, and business assessment data.",
                "People & Operations Engine analysis initiated. Your people and operations strategy is being analyzed across multiple dimensions to provide comprehensive organizational insights.",
                "Analysis started for your comprehensive people and operations strategy. The People & Operations Engine is now examining your organizational positioning, vision alignment, and growth potential across all engines."
            ],
            "middle": [
                "Your People & Operations Engine analysis is progressing well. We're currently integrating insights from your profile, vision, and business data to build comprehensive intelligence.",
                "Analysis update: The People & Operations Engine has completed multiple sections of your cross-engine assessment. Strategic insights are being compiled across all dimensions.",
                "Progress update on your comprehensive analysis. Key areas including profile patterns, vision alignment, and business assessment have been examined and are being integrated."
            ],
            "complete": [
                "Your People & Operations Engine comprehensive analysis is now complete and has expanded your Backable Mind with integrated organizational intelligence. Head to your dashboard to explore organizational insights.",
                "People & Operations Engine analysis complete. Your Backable Mind now contains comprehensive intelligence including profile patterns, vision alignment, and organizational recommendations. Visit your dashboard to explore these insights.",
                "Analysis finished. Your Backable Mind has been enhanced with cross-engine organizational insights covering all key business dimensions. Access your dashboard now to review comprehensive recommendations."
            ]
        }
    
    async def generate_personalized_message(self, user_profile: Dict, stage: str, progress_data: Dict = None) -> str:
        """
        Generate professional, value-focused notification message using Vertex AI (primary) or Gemini API (fallback)
        Focuses on how The Analyst makes Backable Mind smarter with comprehensive people and operations strategy
        """
        try:
            # Extract user context
            business_name = user_profile.get('business_name', 'Your Business')
            username = user_profile.get('username', 'Entrepreneur')
            industry = user_profile.get('industry', 'Business')
            team_size = user_profile.get('team_size', 'Unknown')
            biggest_challenge = user_profile.get('biggest_challenge', 'organizational growth')

            # Create stage-specific professional prompts focused on Backable Mind value
            if stage == "start":
                prompt = f"""
                Create a professional, value-focused notification for {username} from {business_name} in the {industry} industry.
                They just started their People & Operations Engine comprehensive intelligence analysis (People, Operations, Leadership & Culture integration).

                Make it:
                - Professional and encouraging
                - Focus on how this comprehensive analysis will make their Backable Mind smarter
                - Explain the value they'll receive (organizational insights, organizational intelligence, comprehensive recommendations)
                - Reference their business name ({business_name}) naturally
                - 2-3 sentences max
                - NO emojis
                - Sound like a trusted organizational advisor
                - Emphasize comprehensive intelligence and data-driven insights

                Example style:
                "Hi {username}, your People & Operations Engine comprehensive assessment has begun. This integrated analysis of {business_name} will expand your Backable Mind with organizational intelligence combining your profile, vision, and business assessment data in the {industry} industry. The system is now building comprehensive cross-engine recommendations to enhance your decision-making capabilities."

                Be professional, value-focused, and clear about the comprehensive benefit.
                """
            
            elif stage == "middle":
                sections_done = progress_data.get('sections_completed', 5) if progress_data else 5
                total_sections = progress_data.get('total_sections', 10) if progress_data else 10

                prompt = f"""
                Create a professional mid-progress notification for {username} from {business_name}.
                They're {sections_done}/{total_sections} sections through their People & Operations Engine comprehensive intelligence analysis.

                Make it:
                - Professional and informative
                - Highlight what aspects of their business are being analyzed (cross-engine integration)
                - Focus on how each section adds intelligence to their Backable Mind
                - Mention specific value being created (organizational insights, comprehensive patterns, actionable intelligence)
                - 2-3 sentences max
                - NO emojis
                - Sound like a organizational consultant providing updates
                - Emphasize growing comprehensive intelligence from multiple data sources

                Example style:
                "Hi {username}, your People & Operations Engine is progressing well ({sections_done}/{total_sections} sections complete). We're currently integrating insights from your profile, vision, and business assessment data to build comprehensive intelligence for {business_name} in the {industry} space. Each section is adding organizational insights to your Backable Mind, revealing patterns and strategies that single-engine analysis would miss."

                Be professional, specific about progress, and value-focused on comprehensive intelligence.
                """
            
            elif stage == "complete":
                total_words = progress_data.get('total_words', 100000) if progress_data else 100000

                prompt = f"""
                Create a professional completion notification for {username} from {business_name}.
                Their People & Operations Engine comprehensive intelligence analysis is complete with {total_words:,} words of integrated insights.

                Make it:
                - Professional and celebratory in a business-appropriate way
                - Focus on how their Backable Mind is now smarter with comprehensive cross-engine intelligence
                - Clearly tell them what they can do next (visit dashboard, explore comprehensive insights)
                - Explain how this adds value with integrated analysis from multiple engines
                - 2-3 sentences max
                - NO emojis
                - Sound like a organizational advisor delivering valuable comprehensive intelligence
                - Emphasize actionable next steps and enhanced organizational decision-making

                Example style:
                "Hi {username}, your People & Operations Engine comprehensive analysis is now complete and has expanded your Backable Mind with {total_words:,} words of integrated organizational intelligence for {business_name}. Your dashboard now contains organizational insights combining your profile patterns, vision alignment, and business assessment data in the {industry} space. Head to your dashboard to explore these comprehensive insights and leverage the power of multi-engine intelligence for your organizational decisions."

                Be professional, action-oriented, and emphasize the comprehensive value delivered through cross-engine integration.
                """

            # ===================================================================
            # STEP 1: TRY VERTEX AI FIRST (PRIMARY METHOD)
            # ===================================================================
            if vertex_ai_client:
                try:
                    logging.info("üöÄ Trying Vertex AI for notification message")
                    response = vertex_ai_client.models.generate_content(
                        model="gemini-2.5-pro",
                        contents=prompt,
                        config={
                            "temperature": 1.0,
                            "max_output_tokens": 1000,
                            "top_p": 0.95,
                        }
                    )

                    if response and response.text:
                        content = response.text.strip()
                        content = content.replace('"', '').replace("'", "'")

                        # Validate it's a proper professional people & operations message
                        if len(content.split()) > 10:
                            if not any(tech_indicator in content.lower() for tech_indicator in ['role', 'model', 'parts', 'content', 'candidate', 'response']):
                                logging.info(f"‚úÖ Vertex AI people & operations notification for {username}: {stage}")
                                return content

                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è Vertex AI notification failed: {str(e)} - Falling back to API key")

            # ===================================================================
            # STEP 2: FALLBACK TO API KEY
            # ===================================================================
            # FIXED: Use TCPConnector to avoid aiodns issues on Windows
            connector = aiohttp.TCPConnector(use_dns_cache=False) if platform.system() == 'Windows' else None

            # Make API call to Gemini
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=15),
                connector=connector
            ) as session:
                url = f"{self.base_url}/{self.model}:generateContent"
                
                payload = {
                    "contents": [{
                        "role": "user",
                        "parts": [{"text": prompt}]
                    }],
                    "generationConfig": {
                        "temperature": 1.0,
                        "maxOutputTokens": 1000,
                        "topP": 0.95,
                        "candidateCount": 1
                    }
                }
                
                params = {'key': self.gemini_api_key}
                
                async with session.post(url, json=payload, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        if 'candidates' in data and len(data['candidates']) > 0:
                            candidate = data['candidates'][0]
                            
                            # Extract content with multiple fallbacks
                            content = ""
                            try:
                                if 'content' in candidate and 'parts' in candidate['content']:
                                    content = candidate['content']['parts'][0]['text']
                                elif 'content' in candidate:
                                    if isinstance(candidate['content'], str):
                                        content = candidate['content']
                                    elif isinstance(candidate['content'], dict):
                                        content = (candidate['content'].get('text') or 
                                                 candidate['content'].get('message') or 
                                                 str(candidate['content']))
                                elif 'text' in candidate:
                                    content = candidate['text']
                                elif 'message' in candidate:
                                    content = candidate['message']
                                else:
                                    content = str(candidate)
                                    
                            except (KeyError, IndexError, TypeError) as e:
                                logging.warning(f"Content extraction issue: {e}")
                                content = str(candidate)
                            
                            # Clean up the content and validate it's actually a professional message
                            if content:
                                content = content.strip()
                                content = content.replace('"', '').replace("'", "'")

                                # Check if content looks like a proper professional people & operations message
                                if len(content.split()) > 10:
                                    if not any(tech_indicator in content.lower() for tech_indicator in ['role', 'model', 'parts', 'content', 'candidate', 'response']):
                                        logging.info(f"üìä Generated professional {stage} people & operations message for {username}")
                                        return content

                            logging.warning("Generated content doesn't look like a proper professional message, using fallback")
                            return self._get_professional_people_ops_fallback(stage, username, business_name, industry)
                        else:
                            logging.warning("No candidates in Gemini response")
                            return self._get_professional_people_ops_fallback(stage, username, business_name, industry)
                    else:
                        logging.error(f"Gemini API error: {response.status}")
                        return self._get_professional_people_ops_fallback(stage, username, business_name, industry)
                    
        except Exception as e:
            logging.error(f"‚ùå Error generating professional people & operations message: {str(e)}")

        return self._get_professional_people_ops_fallback(stage, username, business_name, industry)
    
    def _get_professional_people_ops_fallback(self, stage: str, username: str, business_name: str, industry: str) -> str:
        """Get a professional people & operations fallback message"""

        fallback_messages = {
            "start": [
                f"Hi {username}, your People & Operations Engine comprehensive assessment has begun. This integrated analysis of {business_name} will expand your Backable Mind with organizational intelligence combining your profile, vision, and business assessment data in the {industry} industry.",
                f"Hi {username}, we're starting your comprehensive People & Operations Engine analysis for {business_name}. The system is now integrating insights from multiple engines to provide comprehensive people and operations strategy tailored to the {industry} space.",
                f"Hi {username}, your comprehensive intelligence analysis for {business_name} has commenced. This cross-engine assessment will add organizational insights to your Backable Mind about your business patterns, vision, and growth opportunities in {industry}."
            ],
            "middle": [
                f"Hi {username}, your People & Operations Engine is progressing well. We're currently integrating insights from your profile, vision, and business data to build comprehensive intelligence for {business_name} in the {industry} space.",
                f"Hi {username}, we're making excellent progress on your comprehensive analysis. Each section is adding organizational insights to your Backable Mind, revealing patterns that single-engine analysis would miss.",
                f"Hi {username}, good progress on your comprehensive intelligence analysis for {business_name}. The system is building integrated insights from multiple data sources in the {industry} space."
            ],
            "complete": [
                f"Hi {username}, your People & Operations Engine comprehensive analysis is now complete and has expanded your Backable Mind with integrated organizational intelligence for {business_name}. Head to your dashboard to explore these comprehensive organizational insights.",
                f"Hi {username}, your comprehensive intelligence analysis for {business_name} is ready. Your dashboard now contains integrated insights from your profile patterns, vision alignment, and business assessment in the {industry} space.",
                f"Hi {username}, your People & Operations Engine assessment is complete. Visit your dashboard to access comprehensive insights that leverage multi-engine intelligence for organizational decision-making at {business_name}."
            ]
        }

        return random.choice(fallback_messages[stage])
    
    @staticmethod
    async def send_notification(user_id: str, title: str, body: str, data_type: str = "notification", save_to_db: bool = False, report_id: str = None, business_name: str = None):
        """
        Send notification to user with optional database persistence
        FIXED for Windows compatibility
        """
        try:
            from datetime import timedelta

            payload = {
                "userId": int(user_id),
                "title": title,
                "body": body,
                "data": {
                    "type": data_type,
                    "timestamp": str(int(datetime.now().timestamp()))
                }
            }

            # Add enhanced payload and DB persistence for completion notification
            if save_to_db and report_id:
                payload["saveToDb"] = True
                payload["expiresAt"] = (datetime.now() + timedelta(days=30)).strftime("%Y-%m-%dT%H:%M:%SZ")
                payload["data"]["screen"] = "AnalystReport"
                payload["data"]["reportId"] = report_id

                # IMPORTANT: payload must be inside data object for proper handling
                payload["data"]["payload"] = {
                    "type": "ai_report_complete",
                    "params": {
                        "reportId": report_id,
                        "reportTitle": "Analyst Intelligence Report",
                        "reportType": "comprehensive_people & operations",
                        "userId": int(user_id),
                        "businessName": business_name or "Your Business",
                        "completionStatus": "success",
                        "sections": 16,
                        "generatedAt": datetime.now().isoformat()
                    },
                    "actionType": "navigate",
                    "screen": "AnalystReport",
                    "url": f"/people & operations/{report_id}"
                }

            logging.info(f"üîî Sending professional people & operations notification to user {user_id}: {title} (saveToDb: {save_to_db})")
            
            # FIXED: Use TCPConnector to avoid aiodns issues on Windows
            connector = aiohttp.TCPConnector(use_dns_cache=False) if platform.system() == 'Windows' else None
            
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=NOTIFICATION_TIMEOUT),
                connector=connector
            ) as session:
                async with session.post(
                    NOTIFICATION_API_URL,
                    json=payload,
                    headers={"Content-Type": "application/json"}
                ) as response:
                    
                    if response.status == 200:
                        result = await response.text()
                        logging.info(f"‚úÖ Professional people & operations notification sent successfully to user {user_id}")
                        return True, result
                    else:
                        error_text = await response.text()
                        logging.error(f"‚ùå Analyst notification failed for user {user_id}: {response.status} - {error_text}")
                        return False, f"HTTP {response.status}: {error_text}"

        except Exception as e:
            logging.error(f"‚ùå Analyst notification error for user {user_id}: {str(e)}")
            return False, str(e)
    
    async def send_personalized_notification(self, user_id: str, user_profile: Dict, stage: str, progress_data: Dict = None, report_id: str = None):
        """
        Send personalized professional people & operations notification for specific stage
        """
        try:
            # Generate personalized professional message
            message = await self.generate_personalized_message(user_profile, stage, progress_data)

            # Create professional titles for comprehensive analysis
            username = user_profile.get('username', 'Entrepreneur')
            business_name = user_profile.get('business_name', 'Your Business')

            professional_titles = {
                "start": [
                    f"People & Operations Engine - Analysis Started",
                    f"{business_name} - Comprehensive Assessment Beginning",
                    f"People & Operations Engine Assessment - {username}",
                    f"{business_name} - Strategic Intelligence Analysis",
                    f"Comprehensive Analysis Initiated"
                ],
                "middle": [
                    f"People & Operations Engine - Progress Update",
                    f"{business_name} - Analysis Progressing",
                    f"Comprehensive Assessment Update - {username}",
                    f"{business_name} - Strategic Analysis In Progress",
                    f"Your People & Operations Engine Progress"
                ],
                "complete": [
                    f"People & Operations Engine - Analysis Complete",
                    f"{business_name} - Comprehensive Intelligence Ready",
                    f"Your Comprehensive Analysis is Complete",
                    f"{business_name} - Strategic Insights Available",
                    f"People & Operations Engine Assessment Complete"
                ]
            }

            title = random.choice(professional_titles[stage])

            # For completion notifications, save to database
            save_to_db = (stage == "complete")

            # Send notification with DB persistence for completion
            success, result = await self.send_notification(user_id, title, message, "notification", save_to_db, report_id, business_name)
            
            if success:
                logging.info(f"‚úÖ Sent professional {stage} people & operations notification to user {user_id}")
            else:
                logging.error(f"‚ùå Failed to send professional notification: {result}")

            return success, message

        except Exception as e:
            logging.error(f"‚ùå Error sending professional people & operations notification: {str(e)}")
            return False, str(e)

    @staticmethod
    def send_personalized_notification_sync(user_id: str, user_profile: Dict, stage: str, progress_data: Dict = None, gemini_api_key: str = None, report_id: str = None):
        """
        Synchronous wrapper for sending personalized professional people & operations notifications
        FIXED for Windows compatibility
        """
        try:
            # FIXED: Handle Windows event loop policy BEFORE creating new loop
            if platform.system() == 'Windows':
                asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

            # Create new loop after setting policy
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                service = PersonalizedNotificationService(gemini_api_key or GEMINI_API_KEYS[0])
                return loop.run_until_complete(
                    service.send_personalized_notification(user_id, user_profile, stage, progress_data, report_id)
                )
            finally:
                loop.close()

        except Exception as e:
            logging.error(f"‚ùå Sync professional people & operations notification error: {str(e)}")
            return False, str(e)
# ======================================================
#           NOTIFICATION CONTROLLER
# ======================================================



class NotificationController:
    """
    Controls when notifications are sent during comprehensive report generation
    """
    
    def __init__(self, user_id: str, user_profile: Dict):
        self.user_id = user_id
        self.user_profile = user_profile
        self.notifications_sent = {
            "start": False,
            "middle": False,
            "complete": False
        }
        self.start_time = datetime.now()
        self.total_sections = 10  # Comprehensive people_ops has ~10 sections
    
    def should_send_notification(self, stage: str, current_data: Dict = None) -> bool:
        """
        Determine if we should send a notification for this stage
        """
        if self.notifications_sent[stage]:
            return False
            
        if stage == "start":
            return True
            
        elif stage == "middle":
            # Send middle notification when ~50% complete
            sections_completed = current_data.get('sections_completed', 0) if current_data else 0
            progress_percentage = (sections_completed / self.total_sections) * 100
            return progress_percentage >= 45 and progress_percentage <= 65
            
        elif stage == "complete":
            return True
            
        return False
    
    def send_notification_if_needed(self, stage: str, progress_data: Dict = None):
        """
        Send notification if it's the right time and hasn't been sent yet
        """
        if self.should_send_notification(stage, progress_data):
            self._send_personalized_notification_background(stage, progress_data)
            self.notifications_sent[stage] = True
            logging.info(f"üì® Triggered {stage} notification for user {self.user_id}")
    
    def force_send_notification(self, stage: str, progress_data: Dict = None):
        """
        Force send a notification regardless of previous sends
        """
        self._send_personalized_notification_background(stage, progress_data)
        self.notifications_sent[stage] = True
        logging.info(f"üì® Force sent {stage} notification for user {self.user_id}")
    
    def _send_personalized_notification_background(self, stage: str, progress_data: Dict = None):
        """
        Send personalized notification using PersonalizedNotificationService in background
        """
        def notification_worker():
            try:
                # Use the first available API key for notifications
                gemini_api_key = GEMINI_API_KEYS[0] if GEMINI_API_KEYS else None
                
                # Call the PersonalizedNotificationService method
                success, message = PersonalizedNotificationService.send_personalized_notification_sync(
                    self.user_id, 
                    self.user_profile, 
                    stage, 
                    progress_data, 
                    gemini_api_key
                )
                
                if success:
                    logging.info(f"üé≠ Personalized {stage} notification sent to user {self.user_id}")
                else:
                    logging.warning(f"‚ö†Ô∏è Personalized {stage} notification failed for user {self.user_id}: {message}")
                    
            except Exception as e:
                logging.error(f"‚ùå Background personalized notification error for user {self.user_id}: {str(e)}")
        
        # Start in background thread
        Thread(target=notification_worker, daemon=True).start()

# ======================================================
#           INDEXER INTEGRATION FUNCTIONS
# ======================================================

async def trigger_indexer_for_client(client_id: str, force: bool = False, new_client: bool = False) -> tuple[bool, str, Optional[str]]:
    """
    Trigger the indexer for a specific client after comprehensive report generation
    
    Args:
        client_id: The client ID to run indexer for
        force: Force indexing even if there's a recent job in progress
        new_client: Mark this as a new client
    
    Returns:
        tuple: (success, message, job_id)
    """
    try:
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=INDEXER_TIMEOUT)) as session:
            payload = {
                "client_id": client_id,
                "force": force,
                "new_client": new_client
            }
            
            logging.info(f"üîÑ Triggering indexer for comprehensive analysis: client_id={client_id}")
            
            async with session.post(
                f"{INDEXER_API_BASE_URL}/run-indexer",
                json=payload,
                headers={"Content-Type": "application/json"}
            ) as response:
                
                response_data = await response.json()
                
                if response.status == 202:  # Accepted
                    job_id = response_data.get("job_id")
                    message = response_data.get("message", "Indexer job started")
                    logging.info(f"‚úÖ Comprehensive indexer triggered successfully for client_id={client_id}, job_id={job_id}")
                    return True, message, job_id
                
                elif response.status == 409:  # Conflict - job in progress
                    message = response_data.get("message", "Indexer job already in progress")
                    logging.warning(f"‚ö†Ô∏è Comprehensive indexer conflict for client_id={client_id}: {message}")
                    return False, message, None
                
                elif response.status == 404:  # Client not found
                    message = response_data.get("message", "Client not found")
                    logging.warning(f"‚ö†Ô∏è Client not found for comprehensive indexer: client_id={client_id}")
                    # Try again with new_client=True
                    return await trigger_indexer_for_client(client_id, force, True)
                
                else:
                    message = response_data.get("message", f"Indexer failed with status {response.status}")
                    logging.error(f"‚ùå Comprehensive indexer failed for client_id={client_id}: {message}")
                    return False, message, None
                    
    except asyncio.TimeoutError:
        error_msg = f"Comprehensive indexer request timed out for client_id={client_id}"
        logging.error(f"‚è∞ {error_msg}")
        return False, error_msg, None
    
    except Exception as e:
        error_msg = f"Error triggering comprehensive indexer for client_id={client_id}: {str(e)}"
        logging.error(f"‚ùå {error_msg}")
        return False, error_msg, None

async def check_indexer_status(job_id: str) -> tuple[bool, Dict[str, Any]]:
    """
    Check the status of an indexer job
    
    Args:
        job_id: The indexer job ID to check
    
    Returns:
        tuple: (success, status_data)
    """
    try:
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
            async with session.get(f"{INDEXER_API_BASE_URL}/status/{job_id}") as response:
                
                if response.status == 200:
                    status_data = await response.json()
                    logging.info(f"üìä Comprehensive indexer status for job_id={job_id}: {status_data.get('status', 'unknown')}")
                    return True, status_data
                
                elif response.status == 404:
                    logging.warning(f"‚ö†Ô∏è Comprehensive indexer job not found: job_id={job_id}")
                    return False, {"status": "not_found", "message": "Indexer job not found"}
                
                else:
                    error_data = await response.json()
                    logging.error(f"‚ùå Error checking comprehensive indexer status for job_id={job_id}: {error_data}")
                    return False, error_data
                    
    except Exception as e:
        error_msg = f"Error checking comprehensive indexer status for job_id={job_id}: {str(e)}"
        logging.error(f"‚ùå {error_msg}")
        return False, {"status": "error", "message": error_msg}

def store_indexer_job_metadata(report_id: str, user_id: str, indexer_job_id: str, indexer_status: str):
    """Store indexer job metadata in the people_ops database"""
    conn = None
    try:
        conn = get_people_ops_connection()
        
        with conn.cursor() as cur:
            sql = """
                UPDATE people_ops_reports 
                SET indexer_job_id = %s, indexer_status = %s, indexer_triggered_at = %s
                WHERE report_id = %s AND user_id = %s
            """
            
            cur.execute(sql, (
                indexer_job_id,
                indexer_status,
                datetime.now(),
                report_id,
                user_id
            ))
        
        logging.info(f"üìä Stored comprehensive indexer metadata: report_id={report_id}, job_id={indexer_job_id}")
        
    except Exception as e:
        logging.error(f"‚ùå Error storing comprehensive indexer metadata: {str(e)}")
    finally:
        if conn:
            conn.close()

def get_people_ops_connection():
    """Get connection to The PeopleOps database"""
    try:
        conn = psycopg2.connect(
            host=ANALYST_DB_CONFIG["host"],
            dbname=ANALYST_DB_CONFIG["database"],
            user=ANALYST_DB_CONFIG["user"],
            password=ANALYST_DB_CONFIG["password"],
            port=ANALYST_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"PeopleOps database connection error: {str(e)}")
        raise

def get_profile_connection():
    """Get connection to Profile Engine database"""
    try:
        conn = psycopg2.connect(
            host=PROFILE_DB_CONFIG["host"],
            dbname=PROFILE_DB_CONFIG["database"],
            user=PROFILE_DB_CONFIG["user"],
            password=PROFILE_DB_CONFIG["password"],
            port=PROFILE_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"Profile database connection error: {str(e)}")
        raise

def get_dream_connection():
    """Get connection to Dream Analyzer database"""
    try:
        conn = psycopg2.connect(
            host=DREAM_DB_CONFIG["host"],
            dbname=DREAM_DB_CONFIG["database"],
            user=DREAM_DB_CONFIG["user"],
            password=DREAM_DB_CONFIG["password"],
            port=DREAM_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"Dream database connection error: {str(e)}")
        raise

def get_user_connection():
    """Get connection to User database"""
    try:
        conn = psycopg2.connect(
            host=USER_DB_CONFIG["host"],
            dbname=USER_DB_CONFIG["database"],
            user=USER_DB_CONFIG["user"],
            password=USER_DB_CONFIG["password"],
            port=USER_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"User database connection error: {str(e)}")
        raise

def get_azure_container_name(user_id: str) -> str:
    """Get Azure container name for user"""
    conn = None
    try:
        conn = psycopg2.connect(
            host=ONBOARDING_DB_HOST,
            dbname=ONBOARDING_DB_NAME,
            user=ONBOARDING_DB_USER,
            password=ONBOARDING_DB_PASSWORD,
            port=ONBOARDING_DB_PORT
        )
        conn.autocommit = True

        with conn.cursor() as cur:
            sql = """
                SELECT azure_container_name
                FROM client_onboarding
                WHERE client_id = %s
                LIMIT 1
            """
            cur.execute(sql, (user_id,))
            row = cur.fetchone()
            if not row:
                logging.warning(f"No container found for user_id={user_id}, using default container 'unified-clients-prod'")
                return "unified-clients-prod"  # Updated to new unified architecture container

            container_name = row[0]
            logging.info(f"Found container for user_id={user_id}: {container_name}")
            return container_name

    except Exception as e:
        logging.error(f"Error retrieving container from DB: {str(e)}")
        return "unified-clients-prod"  # Updated to new unified architecture container

    finally:
        if conn:
            conn.close()

def get_client_folder_name(user_id: str) -> str:
    """
    Get the client's folder name from database.
    Returns folder_name like '666-tim' from client_onboarding table.
    This ensures people_ops reports go to: {container}/{client_folder}/the people_ops engine report/
    """
    conn = None
    try:
        conn = psycopg2.connect(
            host=ONBOARDING_DB_HOST,
            dbname=ONBOARDING_DB_NAME,
            user=ONBOARDING_DB_USER,
            password=ONBOARDING_DB_PASSWORD,
            port=ONBOARDING_DB_PORT
        )
        conn.autocommit = True

        with conn.cursor() as cur:
            sql = """
                SELECT folder_name
                FROM client_onboarding
                WHERE client_id = %s
                LIMIT 1
            """
            cur.execute(sql, (user_id,))
            row = cur.fetchone()
            if not row:
                logging.warning(f"No folder_name found for user_id={user_id}, using client_id as fallback")
                return user_id

            folder_name = row[0]
            logging.info(f"Found folder_name for user_id={user_id}: {folder_name}")
            return folder_name

    except Exception as e:
        logging.error(f"Error retrieving folder_name from DB: {str(e)}")
        return user_id  # Fallback to client_id

    finally:
        if conn:
            conn.close()

# ======================================================
#          COMPLETE DATA INTEGRATION FUNCTIONS
# ======================================================

def get_user_profile_data(user_id: str):
    """Get COMPLETE user profile from the main user database"""
    conn = None
    try:
        logging.info(f"üîç Getting COMPLETE user profile data for user_id={user_id}")
        conn = get_user_connection()
        
        with conn.cursor() as cur:
            sql = """
                SELECT 
                    id, email, username, password, remember_me_token,
                    created_at, updated_at, is_email_verified, client_id,
                    business_name, contact_name, phone_number, ppr_id,
                    company_url, last_name, abn, archive, personal_bio, 
                    location, profile_image_url, skills, interests, 
                    last_login_at, achievements, provider, provider_id, 
                    login_count, last_login_provider, industry, team_size, 
                    business_description, biggest_challenge
                FROM users
                WHERE id = %s OR client_id = %s
                LIMIT 1
            """
            
            cur.execute(sql, (user_id, user_id))
            row = cur.fetchone()
            
            if not row:
                logging.warning(f"No user found for user_id={user_id}")
                return None
            
            columns = [
                'id', 'email', 'username', 'password', 'remember_me_token',
                'created_at', 'updated_at', 'is_email_verified', 'client_id',
                'business_name', 'contact_name', 'phone_number', 'ppr_id',
                'company_url', 'last_name', 'abn', 'archive', 'personal_bio',
                'location', 'profile_image_url', 'skills', 'interests',
                'last_login_at', 'achievements', 'provider', 'provider_id',
                'login_count', 'last_login_provider', 'industry', 'team_size',
                'business_description', 'biggest_challenge'
            ]
            
            user_data = dict(zip(columns, row))
            
            # Convert datetime objects to ISO format
            for key, value in user_data.items():
                if hasattr(value, 'isoformat'):
                    user_data[key] = value.isoformat()
            
            logging.info(f"‚úÖ Found COMPLETE user profile data for user_id={user_id}")
            return user_data
            
    except Exception as e:
        logging.error(f"Error getting user profile data: {str(e)}")
        return None
    finally:
        if conn:
            conn.close()

def get_complete_profile_engine_data(user_id: str):
    """Get ALL profile engine data for a user - MAXIMUM UTILIZATION"""
    conn = None
    try:
        logging.info(f"üß¨ Getting COMPLETE Profile Engine data for user_id={user_id}")
        conn = get_profile_connection()
        
        profile_data = {
            "assessment": None,
            "responses": [],
            "behavioral_analytics": None,
            "reports": [],
            "data_completeness": {
                "assessment_available": False,
                "responses_count": 0,
                "behavioral_available": False,
                "reports_count": 0
            }
        }
        
        with conn.cursor() as cur:
            # Get COMPLETE profile assessment with ALL fields
            cur.execute("""
                SELECT id, user_id, assessment_type, version, created_at, last_updated,
                       timezone, session_metadata, device_fingerprint, 
                       progress_tracking, completion_flags, raw_data, created_timestamp
                FROM profile_assessments 
                WHERE user_id = %s
                ORDER BY created_at DESC LIMIT 1
            """, (user_id,))
            
            assessment_row = cur.fetchone()
            if assessment_row:
                assessment_id = assessment_row[0]
                profile_data["assessment"] = {
                    "id": assessment_row[0],
                    "user_id": assessment_row[1],
                    "assessment_type": assessment_row[2],
                    "version": assessment_row[3],
                    "created_at": assessment_row[4].isoformat() if assessment_row[4] else None,
                    "last_updated": assessment_row[5].isoformat() if assessment_row[5] else None,
                    "timezone": assessment_row[6],
                    "session_metadata": assessment_row[7],
                    "device_fingerprint": assessment_row[8],
                    "progress_tracking": assessment_row[9],
                    "completion_flags": assessment_row[10],
                    "raw_data": assessment_row[11],
                    "created_timestamp": assessment_row[12].isoformat() if assessment_row[12] else None
                }
                profile_data["data_completeness"]["assessment_available"] = True
                
                # Get ALL profile responses - NO LIMIT
                cur.execute("""
                    SELECT id, assessment_id, user_id, question_id, section, question_type, 
                           question_text, response_format, response_data, all_options, 
                           metadata, weight, answered_at, last_modified_at, created_timestamp
                    FROM profile_responses
                    WHERE assessment_id = %s
                    ORDER BY answered_at ASC
                """, (assessment_id,))
                
                for response_row in cur.fetchall():
                    profile_data["responses"].append({
                        "id": response_row[0],
                        "assessment_id": response_row[1],
                        "user_id": response_row[2],
                        "question_id": response_row[3],
                        "section": response_row[4],
                        "question_type": response_row[5],
                        "question_text": response_row[6],
                        "response_format": response_row[7],
                        "response_data": response_row[8],
                        "all_options": response_row[9],
                        "metadata": response_row[10],
                        "weight": response_row[11],
                        "answered_at": response_row[12].isoformat() if response_row[12] else None,
                        "last_modified_at": response_row[13].isoformat() if response_row[13] else None,
                        "created_timestamp": response_row[14].isoformat() if response_row[14] else None
                    })
                
                profile_data["data_completeness"]["responses_count"] = len(profile_data["responses"])
                
                # Get COMPLETE behavioral analytics
                cur.execute("""
                    SELECT id, assessment_id, user_id, mouse_behavior, keyboard_behavior, 
                           attention_patterns, decision_making_style, created_at, created_timestamp
                    FROM behavioral_analytics
                    WHERE assessment_id = %s
                """, (assessment_id,))
                
                behavioral_row = cur.fetchone()
                if behavioral_row:
                    profile_data["behavioral_analytics"] = {
                        "id": behavioral_row[0],
                        "assessment_id": behavioral_row[1],
                        "user_id": behavioral_row[2],
                        "mouse_behavior": behavioral_row[3],
                        "keyboard_behavior": behavioral_row[4],
                        "attention_patterns": behavioral_row[5],
                        "decision_making_style": behavioral_row[6],
                        "created_at": behavioral_row[7].isoformat() if behavioral_row[7] else None,
                        "created_timestamp": behavioral_row[8].isoformat() if behavioral_row[8] else None
                    }
                    profile_data["data_completeness"]["behavioral_available"] = True
                
                # Get ALL profile reports with COMPLETE metadata
                cur.execute("""
                    SELECT id, report_id, user_id, assessment_id, report_type, status, 
                           azure_container, blob_paths, chunk_count, generation_metadata, 
                           created_at, completed_at, quality_metrics, indexer_job_id, 
                           indexer_status, indexer_triggered_at, indexer_completed_at, 
                           indexer_error_message, indexer_retry_count
                    FROM profile_reports
                    WHERE user_id = %s
                    ORDER BY created_at DESC
                """, (user_id,))
                
                for report_row in cur.fetchall():
                    profile_data["reports"].append({
                        "id": report_row[0],
                        "report_id": report_row[1],
                        "user_id": report_row[2],
                        "assessment_id": report_row[3],
                        "report_type": report_row[4],
                        "status": report_row[5],
                        "azure_container": report_row[6],
                        "blob_paths": report_row[7],
                        "chunk_count": report_row[8],
                        "generation_metadata": report_row[9],
                        "created_at": report_row[10].isoformat() if report_row[10] else None,
                        "completed_at": report_row[11].isoformat() if report_row[11] else None,
                        "quality_metrics": report_row[12],
                        "indexer_job_id": report_row[13],
                        "indexer_status": report_row[14],
                        "indexer_triggered_at": report_row[15].isoformat() if report_row[15] else None,
                        "indexer_completed_at": report_row[16].isoformat() if report_row[16] else None,
                        "indexer_error_message": report_row[17],
                        "indexer_retry_count": report_row[18]
                    })
                
                profile_data["data_completeness"]["reports_count"] = len(profile_data["reports"])
        
        logging.info(f"‚úÖ COMPLETE Profile Engine data retrieved for user_id={user_id}:")
        logging.info(f"   üìä Responses: {profile_data['data_completeness']['responses_count']}")
        logging.info(f"   üß† Behavioral: {profile_data['data_completeness']['behavioral_available']}")
        logging.info(f"   üìÑ Reports: {profile_data['data_completeness']['reports_count']}")
        
        return profile_data
        
    except Exception as e:
        logging.error(f"Error getting complete profile engine data: {str(e)}")
        return None
    finally:
        if conn:
            conn.close()

def get_complete_dream_analyzer_data(user_id: str):
    """Get ALL dream analyzer data for a user - MAXIMUM UTILIZATION"""
    conn = None
    try:
        logging.info(f"üí≠ Getting COMPLETE Dream Analyzer data for user_id={user_id}")
        conn = get_dream_connection()
        
        dream_data = {
            "assessment": None,
            "responses": [],
            "behavioral_analytics": None,
            "reports": [],
            "data_completeness": {
                "assessment_available": False,
                "responses_count": 0,
                "behavioral_available": False,
                "reports_count": 0
            }
        }
        
        with conn.cursor() as cur:
            # Get COMPLETE dream assessment with ALL fields
            cur.execute("""
                SELECT id, user_id, assessment_type, version, created_at, last_updated,
                       timezone, session_metadata, device_fingerprint, 
                       progress_tracking, completion_flags, raw_data,
                       profile_integration_data, created_timestamp
                FROM dream_assessments 
                WHERE user_id = %s
                ORDER BY created_at DESC LIMIT 1
            """, (user_id,))
            
            assessment_row = cur.fetchone()
            if assessment_row:
                assessment_id = assessment_row[0]
                dream_data["assessment"] = {
                    "id": assessment_row[0],
                    "user_id": assessment_row[1],
                    "assessment_type": assessment_row[2],
                    "version": assessment_row[3],
                    "created_at": assessment_row[4].isoformat() if assessment_row[4] else None,
                    "last_updated": assessment_row[5].isoformat() if assessment_row[5] else None,
                    "timezone": assessment_row[6],
                    "session_metadata": assessment_row[7],
                    "device_fingerprint": assessment_row[8],
                    "progress_tracking": assessment_row[9],
                    "completion_flags": assessment_row[10],
                    "raw_data": assessment_row[11],
                    "profile_integration_data": assessment_row[12],
                    "created_timestamp": assessment_row[13].isoformat() if assessment_row[13] else None
                }
                dream_data["data_completeness"]["assessment_available"] = True
                
                # Get ALL dream responses - NO LIMIT
                cur.execute("""
                    SELECT id, assessment_id, user_id, question_id, section, question_type, 
                           question_text, response_format, response_data, all_options, 
                           metadata, weight, answered_at, last_modified_at, created_timestamp
                    FROM dream_responses
                    WHERE assessment_id = %s
                    ORDER BY answered_at ASC
                """, (assessment_id,))
                
                for response_row in cur.fetchall():
                    dream_data["responses"].append({
                        "id": response_row[0],
                        "assessment_id": response_row[1],
                        "user_id": response_row[2],
                        "question_id": response_row[3],
                        "section": response_row[4],
                        "question_type": response_row[5],
                        "question_text": response_row[6],
                        "response_format": response_row[7],
                        "response_data": response_row[8],
                        "all_options": response_row[9],
                        "metadata": response_row[10],
                        "weight": response_row[11],
                        "answered_at": response_row[12].isoformat() if response_row[12] else None,
                        "last_modified_at": response_row[13].isoformat() if response_row[13] else None,
                        "created_timestamp": response_row[14].isoformat() if response_row[14] else None
                    })
                
                dream_data["data_completeness"]["responses_count"] = len(dream_data["responses"])
                
                # Get COMPLETE behavioral analytics
                cur.execute("""
                    SELECT id, assessment_id, user_id, mouse_behavior, keyboard_behavior, 
                           attention_patterns, decision_making_style, created_at, created_timestamp
                    FROM dream_behavioral_analytics
                    WHERE assessment_id = %s
                """, (assessment_id,))
                
                behavioral_row = cur.fetchone()
                if behavioral_row:
                    dream_data["behavioral_analytics"] = {
                        "id": behavioral_row[0],
                        "assessment_id": behavioral_row[1],
                        "user_id": behavioral_row[2],
                        "mouse_behavior": behavioral_row[3],
                        "keyboard_behavior": behavioral_row[4],
                        "attention_patterns": behavioral_row[5],
                        "decision_making_style": behavioral_row[6],
                        "created_at": behavioral_row[7].isoformat() if behavioral_row[7] else None,
                        "created_timestamp": behavioral_row[8].isoformat() if behavioral_row[8] else None
                    }
                    dream_data["data_completeness"]["behavioral_available"] = True
                
                # Get ALL dream reports with COMPLETE metadata
                cur.execute("""
                    SELECT id, report_id, user_id, assessment_id, report_type, status, 
                           azure_container, blob_paths, chunk_count, generation_metadata, 
                           created_at, completed_at, indexer_job_id, indexer_status, 
                           indexer_triggered_at, indexer_completed_at, indexer_error_message, 
                           indexer_retry_count, profile_integration_used, profile_assessment_id
                    FROM dream_reports
                    WHERE user_id = %s
                    ORDER BY created_at DESC
                """, (user_id,))
                
                for report_row in cur.fetchall():
                    dream_data["reports"].append({
                        "id": report_row[0],
                        "report_id": report_row[1],
                        "user_id": report_row[2],
                        "assessment_id": report_row[3],
                        "report_type": report_row[4],
                        "status": report_row[5],
                        "azure_container": report_row[6],
                        "blob_paths": report_row[7],
                        "chunk_count": report_row[8],
                        "generation_metadata": report_row[9],
                        "created_at": report_row[10].isoformat() if report_row[10] else None,
                        "completed_at": report_row[11].isoformat() if report_row[11] else None,
                        "indexer_job_id": report_row[12],
                        "indexer_status": report_row[13],
                        "indexer_triggered_at": report_row[14].isoformat() if report_row[14] else None,
                        "indexer_completed_at": report_row[15].isoformat() if report_row[15] else None,
                        "indexer_error_message": report_row[16],
                        "indexer_retry_count": report_row[17],
                        "profile_integration_used": report_row[18],
                        "profile_assessment_id": report_row[19]
                    })
                
                dream_data["data_completeness"]["reports_count"] = len(dream_data["reports"])
        
        logging.info(f"‚úÖ COMPLETE Dream Analyzer data retrieved for user_id={user_id}:")
        logging.info(f"   üìä Responses: {dream_data['data_completeness']['responses_count']}")
        logging.info(f"   üß† Behavioral: {dream_data['data_completeness']['behavioral_available']}")
        logging.info(f"   üìÑ Reports: {dream_data['data_completeness']['reports_count']}")
        
        return dream_data
        
    except Exception as e:
        logging.error(f"Error getting complete dream analyzer data: {str(e)}")
        return None
    finally:
        if conn:
            conn.close()

def build_maximum_comprehensive_context(user_id: str, people_ops_assessment_data: Dict = None):
    """Build MAXIMUM comprehensive user context from ALL available data sources"""
    logging.info(f"üöÄ Building MAXIMUM comprehensive user context for user_id={user_id}")
    
    # Get data from ALL sources with COMPLETE datasets
    user_profile = get_user_profile_data(user_id)
    profile_data = get_complete_profile_engine_data(user_id)
    dream_data = get_complete_dream_analyzer_data(user_id)
    
    # Build COMPREHENSIVE context with ALL available data
    comprehensive_context = {
        "user_id": user_id,
        "analysis_timestamp": datetime.now().isoformat(),
        "data_sources": {
            "user_profile_available": user_profile is not None,
            "profile_engine_available": profile_data is not None and profile_data.get("assessment") is not None,
            "dream_analyzer_available": dream_data is not None and dream_data.get("assessment") is not None,
            "people_ops_assessment_available": people_ops_assessment_data is not None
        },
        
        # COMPLETE USER PROFILE DATA
        "user_profile": user_profile,
        
        # COMPLETE PROFILE ENGINE DATA
        "profile_engine": profile_data,
        
        # COMPLETE DREAM ANALYZER DATA  
        "dream_analyzer": dream_data,
        
        # CURRENT ANALYST ASSESSMENT DATA
        "people_ops_assessment_data": people_ops_assessment_data,
        
        # INTEGRATION METADATA with detailed analysis
        "integration_metadata": {
            "total_profile_responses": profile_data["data_completeness"]["responses_count"] if profile_data else 0,
            "total_dream_responses": dream_data["data_completeness"]["responses_count"] if dream_data else 0,
            "total_people_ops_responses": len(people_ops_assessment_data.get("responses", [])) if people_ops_assessment_data else 0,
            "total_responses_available": (
                (profile_data["data_completeness"]["responses_count"] if profile_data else 0) + 
                (dream_data["data_completeness"]["responses_count"] if dream_data else 0) +
                (len(people_ops_assessment_data.get("responses", [])) if people_ops_assessment_data else 0)
            ),
            "profile_behavioral_available": profile_data["data_completeness"]["behavioral_available"] if profile_data else False,
            "dream_behavioral_available": dream_data["data_completeness"]["behavioral_available"] if dream_data else False,
            "profile_reports_count": profile_data["data_completeness"]["reports_count"] if profile_data else 0,
            "dream_reports_count": dream_data["data_completeness"]["reports_count"] if dream_data else 0,
            "data_richness_score": 0,
            "cross_engine_opportunities": [],
            "behavioral_correlation_opportunities": [],
            "temporal_analysis_opportunities": []
        },
        
        # CROSS-ENGINE ANALYSIS OPPORTUNITIES
        "cross_engine_insights": {
            "response_correlations": [],
            "behavioral_patterns": [],
            "temporal_patterns": [],
            "contradiction_analysis": [],
            "reinforcement_patterns": []
        }
    }
    
    # Calculate COMPREHENSIVE data richness score
    richness_score = 0
    
    # User profile scoring (25 points max)
    if user_profile:
        richness_score += 15  # Base profile
        if user_profile.get('business_description'):
            richness_score += 3
        if user_profile.get('biggest_challenge'):
            richness_score += 3
        if user_profile.get('industry'):
            richness_score += 2
        if user_profile.get('team_size'):
            richness_score += 2
    
    # Profile engine scoring (25 points max) - reduced to make room for people_ops
    if profile_data and profile_data.get("responses"):
        response_count = len(profile_data["responses"])
        richness_score += min(20, response_count * 0.8)  # Up to 20 points for responses
        
        if profile_data.get("behavioral_analytics"):
            richness_score += 3  # Behavioral data
        
        if profile_data.get("assessment", {}).get("raw_data"):
            richness_score += 2  # Raw data available
    
    # Dream analyzer scoring (25 points max) - reduced to make room for people_ops
    if dream_data and dream_data.get("responses"):
        response_count = len(dream_data["responses"])
        richness_score += min(20, response_count * 0.8)  # Up to 20 points for responses
        
        if dream_data.get("behavioral_analytics"):
            richness_score += 3  # Behavioral data
        
        if dream_data.get("assessment", {}).get("raw_data"):
            richness_score += 2  # Raw data available
    
    # PeopleOps engine scoring (25 points max) - NEW
    if people_ops_assessment_data and people_ops_assessment_data.get("responses"):
        response_count = len(people_ops_assessment_data["responses"])
        richness_score += min(20, response_count * 0.3)  # Up to 20 points for responses (61 questions)
        
        if people_ops_assessment_data.get("assessment_metadata"):
            richness_score += 3  # Assessment metadata available
        
        if people_ops_assessment_data.get("comprehensive_metadata"):
            richness_score += 2  # Comprehensive metadata available
    
    # Cross-engine bonus (expand to include people_ops)
    engines_available = sum([
        bool(profile_data),
        bool(dream_data),
        bool(people_ops_assessment_data)
    ])
    
    if engines_available >= 2:
        richness_score += 5  # Cross-engine analysis possible
    if engines_available == 3:
        richness_score += 5  # All three engines - maximum integration
    
    comprehensive_context["integration_metadata"]["data_richness_score"] = min(100, richness_score)
    
    # Identify CROSS-ENGINE OPPORTUNITIES (expand to include people_ops)
    cross_engine_opportunities = []
    behavioral_correlation_opportunities = []
    temporal_analysis_opportunities = []
    
    if profile_data and dream_data:
        cross_engine_opportunities.extend([
            "cross_engine_behavioral_analysis",
            "professional_vs_personal_alignment",
            "decision_making_consistency",
            "values_alignment_analysis",
            "goal_achievement_correlation",
            "personality_trait_validation",
            "leadership_style_consistency",
            "growth_mindset_correlation"
        ])
    
    # Add people_ops-specific opportunities
    if people_ops_assessment_data:
        cross_engine_opportunities.extend([
            "operational_vs_aspirational_alignment",
            "leadership_theory_vs_practice",
            "financial_psychology_validation",
            "team_perception_vs_reality",
            "strategic_vision_vs_execution",
            "growth_ambition_vs_capacity"
        ])
        
        # Check for behavioral data correlation opportunities
        if profile_data and profile_data.get("behavioral_analytics"):
            behavioral_correlation_opportunities.extend([
                "profile_vs_people_ops_decision_patterns",
                "energy_vs_operational_efficiency",
                "learning_style_vs_planning_approach"
            ])
        
        if dream_data and dream_data.get("behavioral_analytics"):
            behavioral_correlation_opportunities.extend([
                "aspiration_vs_operational_reality",
                "vision_vs_execution_alignment",
                "motivation_vs_performance_correlation"
            ])
    
    comprehensive_context["integration_metadata"]["cross_engine_opportunities"] = cross_engine_opportunities
    comprehensive_context["integration_metadata"]["behavioral_correlation_opportunities"] = behavioral_correlation_opportunities
    comprehensive_context["integration_metadata"]["temporal_analysis_opportunities"] = temporal_analysis_opportunities
    
    # DETAILED CROSS-ENGINE INSIGHTS ANALYSIS (expand to include people_ops)
    if profile_data and dream_data:
        # Analyze response correlations
        profile_responses = profile_data.get("responses", [])
        dream_responses = dream_data.get("responses", [])
        
        # Find thematic correlations
        comprehensive_context["cross_engine_insights"]["response_correlations"] = analyze_response_correlations(profile_responses, dream_responses)
        
        # Analyze behavioral patterns
        if profile_data.get("behavioral_analytics") and dream_data.get("behavioral_analytics"):
            comprehensive_context["cross_engine_insights"]["behavioral_patterns"] = analyze_behavioral_correlations(
                profile_data["behavioral_analytics"], 
                dream_data["behavioral_analytics"]
            )
        
        # Analyze temporal patterns
        profile_assessment = profile_data.get("assessment", {})
        dream_assessment = dream_data.get("assessment", {})
        comprehensive_context["cross_engine_insights"]["temporal_patterns"] = analyze_temporal_patterns(
            profile_assessment, 
            dream_assessment
        )
    
    logging.info(f"‚úÖ MAXIMUM comprehensive context built for user_id={user_id}:")
    logging.info(f"   üìä Data richness score: {comprehensive_context['integration_metadata']['data_richness_score']}/100")
    logging.info(f"   üîó Cross-engine opportunities: {len(cross_engine_opportunities)}")
    logging.info(f"   üß† Behavioral correlations: {len(behavioral_correlation_opportunities)}")
    logging.info(f"   ‚è±Ô∏è Temporal analyses: {len(temporal_analysis_opportunities)}")
    logging.info(f"   üîß PeopleOps responses included: {comprehensive_context['integration_metadata']['total_people_ops_responses']}")
    
    return comprehensive_context

def analyze_response_correlations(profile_responses: List[Dict], dream_responses: List[Dict]) -> List[Dict]:
    """Analyze correlations between profile and dream responses"""
    correlations = []
    
    # Group responses by themes
    profile_themes = {}
    dream_themes = {}
    
    for response in profile_responses:
        section = response.get("section", "unknown")
        if section not in profile_themes:
            profile_themes[section] = []
        profile_themes[section].append(response)
    
    for response in dream_responses:
        section = response.get("section", "unknown")
        if section not in dream_themes:
            dream_themes[section] = []
        dream_themes[section].append(response)
    
    # Look for thematic overlaps
    common_themes = set(profile_themes.keys()) & set(dream_themes.keys())
    
    for theme in common_themes:
        correlations.append({
            "theme": theme,
            "profile_responses_count": len(profile_themes[theme]),
            "dream_responses_count": len(dream_themes[theme]),
            "correlation_opportunity": "thematic_alignment"
        })
    
    return correlations

def analyze_behavioral_correlations(profile_behavioral: Dict, dream_behavioral: Dict) -> List[Dict]:
    """Analyze behavioral data correlations between engines"""
    patterns = []
    
    # Compare mouse behavior
    profile_mouse = profile_behavioral.get("mouse_behavior", {})
    dream_mouse = dream_behavioral.get("mouse_behavior", {})
    
    if profile_mouse and dream_mouse:
        patterns.append({
            "pattern_type": "mouse_behavior_correlation",
            "profile_data": profile_mouse,
            "dream_data": dream_mouse,
            "analysis_opportunity": "interaction_consistency"
        })
    
    # Compare decision making
    profile_decisions = profile_behavioral.get("decision_making_style", {})
    dream_decisions = dream_behavioral.get("decision_making_style", {})
    
    if profile_decisions and dream_decisions:
        patterns.append({
            "pattern_type": "decision_making_correlation", 
            "profile_data": profile_decisions,
            "dream_data": dream_decisions,
            "analysis_opportunity": "cognitive_consistency"
        })
    
    return patterns

def analyze_temporal_patterns(profile_assessment: Dict, dream_assessment: Dict) -> List[Dict]:
    """Analyze temporal patterns between assessments"""
    patterns = []
    
    profile_created = profile_assessment.get("created_at")
    dream_created = dream_assessment.get("created_at")
    
    if profile_created and dream_created:
        patterns.append({
            "pattern_type": "assessment_timing",
            "profile_timestamp": profile_created,
            "dream_timestamp": dream_created,
            "analysis_opportunity": "temporal_behavior_evolution"
        })
    
    # Compare session metadata
    profile_session = profile_assessment.get("session_metadata", {})
    dream_session = dream_assessment.get("session_metadata", {})
    
    if profile_session and dream_session:
        patterns.append({
            "pattern_type": "session_consistency",
            "profile_session": profile_session,
            "dream_session": dream_session,
            "analysis_opportunity": "device_and_context_consistency"
        })
    
    return patterns

# ======================================================
#                THE ANALYST DATABASE SETUP
# ======================================================

def create_people_ops_tables():
    """Create tables for The PeopleOps database with comprehensive fields and indexer support"""
    conn = None
    try:
        conn = get_people_ops_connection()
        
        with conn.cursor() as cur:
            # Create people_ops_assessments table
            cur.execute("""
                CREATE TABLE IF NOT EXISTS people_ops_assessments (
                    id SERIAL PRIMARY KEY,
                    user_id VARCHAR(255) UNIQUE NOT NULL,
                    assessment_type VARCHAR(100) NOT NULL,
                    version VARCHAR(20) NOT NULL,
                    created_at TIMESTAMPTZ,
                    last_updated TIMESTAMPTZ,
                    timezone VARCHAR(100),
                    session_metadata JSONB,
                    device_fingerprint JSONB,
                    progress_tracking JSONB,
                    completion_flags JSONB,
                    raw_data JSONB,
                    profile_integration_data JSONB,
                    dream_integration_data JSONB,
                    comprehensive_context JSONB,
                    cross_engine_insights JSONB,
                    created_timestamp TIMESTAMPTZ DEFAULT NOW()
                )
            """)
            
            # Create people_ops_responses table
            cur.execute("""
                CREATE TABLE IF NOT EXISTS people_ops_responses (
                    id SERIAL PRIMARY KEY,
                    assessment_id INTEGER REFERENCES people_ops_assessments(id),
                    user_id VARCHAR(255) NOT NULL,
                    question_id VARCHAR(50) NOT NULL,
                    section VARCHAR(100) NOT NULL,
                    question_type VARCHAR(50),
                    question_text TEXT,
                    response_format VARCHAR(50),
                    response_data JSONB,
                    all_options JSONB,
                    metadata JSONB,
                    weight VARCHAR(20),
                    answered_at TIMESTAMPTZ,
                    last_modified_at TIMESTAMPTZ,
                    profile_context JSONB,
                    dream_context JSONB,
                    created_timestamp TIMESTAMPTZ DEFAULT NOW(),
                    UNIQUE(assessment_id, question_id)
                )
            """)
            
            # Create people_ops_behavioral_analytics table
            cur.execute("""
                CREATE TABLE IF NOT EXISTS people_ops_behavioral_analytics (
                    id SERIAL PRIMARY KEY,
                    assessment_id INTEGER REFERENCES people_ops_assessments(id) UNIQUE,
                    user_id VARCHAR(255) NOT NULL,
                    mouse_behavior JSONB,
                    keyboard_behavior JSONB,
                    attention_patterns JSONB,
                    decision_making_style JSONB,
                    profile_comparison JSONB,
                    dream_comparison JSONB,
                    cross_engine_insights JSONB,
                    behavioral_evolution JSONB,
                    created_at TIMESTAMPTZ,
                    created_timestamp TIMESTAMPTZ DEFAULT NOW()
                )
            """)
            
            # Create people_ops_reports table WITH ALL INDEXER COLUMNS
            cur.execute("""
                CREATE TABLE IF NOT EXISTS people_ops_reports (
                    id SERIAL PRIMARY KEY,
                    report_id VARCHAR(255) UNIQUE NOT NULL,
                    user_id VARCHAR(255) NOT NULL,
                    assessment_id INTEGER REFERENCES people_ops_assessments(id),
                    report_type VARCHAR(100) NOT NULL,
                    status VARCHAR(50) NOT NULL,
                    azure_container VARCHAR(255),
                    blob_paths JSONB,
                    chunk_count INTEGER,
                    generation_metadata JSONB,
                    created_at TIMESTAMPTZ DEFAULT NOW(),
                    completed_at TIMESTAMPTZ,
                    indexer_job_id VARCHAR(255),
                    indexer_status VARCHAR(50),
                    indexer_triggered_at TIMESTAMPTZ,
                    indexer_completed_at TIMESTAMPTZ,
                    indexer_error_message TEXT,
                    indexer_retry_count INTEGER DEFAULT 0,
                    profile_integration_used BOOLEAN DEFAULT false,
                    dream_integration_used BOOLEAN DEFAULT false,
                    profile_assessment_id INTEGER,
                    dream_assessment_id INTEGER,
                    comprehensive_analysis_score FLOAT,
                    cross_engine_insights_score FLOAT,
                    data_utilization_score FLOAT
                )
            """)
            
            # Create indexes for optimal performance
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_assessments_user_id ON people_ops_assessments(user_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_responses_user_id ON people_ops_responses(user_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_responses_section ON people_ops_responses(section)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_user_id ON people_ops_reports(user_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_report_id ON people_ops_reports(report_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_integration ON people_ops_reports(profile_integration_used, dream_integration_used)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_comprehensive ON people_ops_reports(comprehensive_analysis_score)")
            
            # CRITICAL: Add missing indexer columns to existing tables if they don't exist
            logging.info("üîß Checking and adding missing indexer columns...")
            
            # Check if indexer columns exist in people_ops_reports
            cur.execute("""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_name = 'people_ops_reports' 
                AND column_name IN ('indexer_job_id', 'indexer_status', 'indexer_triggered_at', 
                                  'indexer_completed_at', 'indexer_error_message', 'indexer_retry_count')
            """)
            
            existing_columns = [row[0] for row in cur.fetchall()]
            
            # Add missing indexer columns
            indexer_columns = {
                'indexer_job_id': 'VARCHAR(255)',
                'indexer_status': 'VARCHAR(50)',
                'indexer_triggered_at': 'TIMESTAMPTZ',
                'indexer_completed_at': 'TIMESTAMPTZ',
                'indexer_error_message': 'TEXT',
                'indexer_retry_count': 'INTEGER DEFAULT 0'
            }
            
            for column_name, column_type in indexer_columns.items():
                if column_name not in existing_columns:
                    try:
                        cur.execute(f"ALTER TABLE people_ops_reports ADD COLUMN {column_name} {column_type}")
                        logging.info(f"‚úÖ Added indexer column: {column_name}")
                    except Exception as e:
                        if "already exists" in str(e).lower():
                            logging.info(f"‚úÖ Column {column_name} already exists")
                        else:
                            logging.error(f"‚ùå Error adding column {column_name}: {str(e)}")
                            raise
                else:
                    logging.info(f"‚úÖ Column {column_name} already exists")
            
            # Create indexer-specific indexes
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_indexer_job_id ON people_ops_reports(indexer_job_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_indexer_status ON people_ops_reports(indexer_status)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_indexer_triggered ON people_ops_reports(indexer_triggered_at)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_user_indexer ON people_ops_reports(user_id, indexer_status)")
            
            # Commit the changes
            conn.commit()
            
            # DROP EXISTING VIEWS BEFORE RECREATING THEM
            logging.info("üóëÔ∏è Dropping existing views to recreate them...")
            cur.execute("DROP VIEW IF EXISTS people_ops_comprehensive_summary CASCADE")
            cur.execute("DROP VIEW IF EXISTS people_ops_indexer_monitoring CASCADE")
            cur.execute("DROP VIEW IF EXISTS people_ops_performance_analytics CASCADE")
            
            # Create enhanced view for comprehensive reporting with indexer data
            cur.execute("""
                CREATE VIEW people_ops_comprehensive_summary AS
                SELECT 
                    r.report_id,
                    r.user_id,
                    r.report_type,
                    r.status,
                    r.created_at,
                    r.completed_at,
                    r.comprehensive_analysis_score,
                    r.cross_engine_insights_score,
                    r.data_utilization_score,
                    r.profile_integration_used,
                    r.dream_integration_used,
                    r.indexer_job_id,
                    r.indexer_status,
                    r.indexer_triggered_at,
                    r.indexer_completed_at,
                    r.indexer_error_message,
                    r.indexer_retry_count,
                    a.assessment_type,
                    a.version,
                    (SELECT COUNT(*) FROM people_ops_responses WHERE assessment_id = a.id) as total_responses,
                    CASE 
                        WHEN r.indexer_status = 'completed' THEN 'success'
                        WHEN r.indexer_status IN ('failed', 'error') THEN 'failed'
                        WHEN r.indexer_status IN ('triggered', 'running', 'queued') THEN 'in_progress'
                        WHEN r.indexer_status IS NULL THEN 'not_triggered'
                        ELSE 'unknown'
                    END as indexer_summary_status,
                    CASE 
                        WHEN r.indexer_completed_at IS NOT NULL AND r.indexer_triggered_at IS NOT NULL 
                        THEN EXTRACT(EPOCH FROM (r.indexer_completed_at - r.indexer_triggered_at))
                        ELSE NULL
                    END as indexer_duration_seconds
                FROM people_ops_reports r
                LEFT JOIN people_ops_assessments a ON r.assessment_id = a.id
                WHERE r.report_type = 'comprehensive_people_ops_report'
            """)
            
            # Create indexer monitoring view
            cur.execute("""
                CREATE VIEW people_ops_indexer_monitoring AS
                SELECT 
                    r.report_id,
                    r.user_id,
                    r.indexer_job_id,
                    r.indexer_status,
                    r.indexer_triggered_at,
                    r.indexer_completed_at,
                    r.indexer_error_message,
                    r.indexer_retry_count,
                    r.created_at as report_created_at,
                    r.completed_at as report_completed_at,
                    r.comprehensive_analysis_score,
                    r.cross_engine_insights_score,
                    r.data_utilization_score,
                    CASE 
                        WHEN r.indexer_status = 'completed' THEN 'Indexing Complete'
                        WHEN r.indexer_status = 'triggered' THEN 'Indexing In Progress'
                        WHEN r.indexer_status = 'failed' THEN 'Indexing Failed'
                        WHEN r.indexer_status = 'error' THEN 'Indexing Error'
                        WHEN r.indexer_status IS NULL THEN 'Not Indexed'
                        ELSE 'Unknown Status'
                    END as indexer_status_description,
                    CASE 
                        WHEN r.indexer_completed_at IS NOT NULL AND r.indexer_triggered_at IS NOT NULL 
                        THEN EXTRACT(EPOCH FROM (r.indexer_completed_at - r.indexer_triggered_at))
                        ELSE NULL
                    END as indexer_processing_seconds
                FROM people_ops_reports r
                WHERE r.report_type = 'comprehensive_people_ops_report'
                ORDER BY r.created_at DESC
            """)
            
            # Create performance analytics view
            cur.execute("""
                CREATE VIEW people_ops_performance_analytics AS
                SELECT 
                    COUNT(*) as total_reports,
                    COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_reports,
                    COUNT(CASE WHEN indexer_status = 'completed' THEN 1 END) as indexed_reports,
                    COUNT(CASE WHEN indexer_status IN ('failed', 'error') THEN 1 END) as indexer_failures,
                    AVG(comprehensive_analysis_score) as avg_comprehensive_score,
                    AVG(cross_engine_insights_score) as avg_cross_engine_score,
                    AVG(data_utilization_score) as avg_data_utilization_score,
                    COUNT(CASE WHEN profile_integration_used = true THEN 1 END) as profile_integrations,
                    COUNT(CASE WHEN dream_integration_used = true THEN 1 END) as dream_integrations,
                    COUNT(CASE WHEN profile_integration_used = true AND dream_integration_used = true THEN 1 END) as full_integrations,
                    AVG(CASE 
                        WHEN indexer_completed_at IS NOT NULL AND indexer_triggered_at IS NOT NULL 
                        THEN EXTRACT(EPOCH FROM (indexer_completed_at - indexer_triggered_at))
                        ELSE NULL
                    END) as avg_indexer_duration_seconds
                FROM people_ops_reports
                WHERE report_type = 'comprehensive_people_ops_report'
                AND created_at >= NOW() - INTERVAL '30 days'
            """)
            
        logging.info("‚úÖ PeopleOps database tables with indexer support created/updated successfully")
        logging.info("üìä All indexer columns verified and added")
        logging.info("üìà Indexer indexes created for optimized querying")
        logging.info("üîç Enhanced reporting views recreated with indexer monitoring")
        logging.info("üìã Performance analytics view created")
        
    except Exception as e:
        logging.error(f"‚ùå Error creating/updating people_ops tables: {str(e)}")
        raise
    finally:
        if conn:
            conn.close()
# ======================================================
#                ENHANCED GEMINI CLIENT FOR THE ANALYST
# ======================================================

# ======================================================
#           FIXED Notification Functions
# ======================================================

async def send_people_ops_notification(user_id: str, title: str, body: str, data_type: str = "notification", save_to_db: bool = False, report_id: str = None, business_name: str = None):
    """
    Send notification to user with optional database persistence
    FIXED for Windows compatibility - People & Operations Engine
    """
    try:
        from datetime import timedelta

        payload = {
            "userId": int(user_id),
            "title": title,
            "body": body,
            "data": {
                "type": data_type,
                "timestamp": str(int(datetime.now().timestamp()))
            }
        }

        # Add enhanced payload and DB persistence for completion notification
        if save_to_db and report_id:
            payload["saveToDb"] = True
            payload["expiresAt"] = (datetime.now() + timedelta(days=30)).strftime("%Y-%m-%dT%H:%M:%SZ")
            payload["data"]["screen"] = "PeopleOpsReport"
            payload["data"]["reportId"] = report_id

            # IMPORTANT: payload must be inside data object for proper handling
            payload["data"]["payload"] = {
                "type": "ai_report_complete",
                "params": {
                    "reportId": report_id,
                    "reportTitle": "People & Operations Strategy Report",
                    "reportType": "comprehensive_people_ops",
                    "userId": int(user_id),
                    "businessName": business_name or "Your Business",
                    "completionStatus": "success",
                    "sections": 16,
                    "generatedAt": datetime.now().isoformat()
                },
                "actionType": "navigate",
                "screen": "PeopleOpsReport",
                "url": f"/people-ops/{report_id}"
            }

        logging.info(f"üîî Sending professional people & ops notification to user {user_id}: {title} (saveToDb: {save_to_db})")

        # FIXED: Use TCPConnector to avoid aiodns issues on Windows
        connector = aiohttp.TCPConnector(use_dns_cache=False) if platform.system() == 'Windows' else None

        async with aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=NOTIFICATION_TIMEOUT),
            connector=connector
        ) as session:
            async with session.post(
                NOTIFICATION_API_URL,
                json=payload,
                headers={"Content-Type": "application/json"}
            ) as response:

                if response.status == 200:
                    result = await response.text()
                    logging.info(f"‚úÖ Professional people & ops notification sent successfully to user {user_id}")
                    return True, result
                else:
                    error_text = await response.text()
                    logging.error(f"‚ùå People & ops notification failed for user {user_id}: {response.status} - {error_text}")
                    return False, f"HTTP {response.status}: {error_text}"

    except Exception as e:
        logging.error(f"‚ùå People & ops notification error for user {user_id}: {str(e)}")
        return False, str(e)


def send_people_ops_notification_sync(user_id: str, title: str, body: str, data_type: str = "notification"):
    """Synchronous wrapper for sending people & ops notifications"""
    try:
        if platform.system() == 'Windows':
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(
                send_people_ops_notification(user_id, title, body, data_type)
            )
        finally:
            loop.close()
            
    except Exception as e:
        logging.error(f"‚ùå Sync people & ops notification error: {str(e)}")
        return False, str(e)

async def generate_personalized_people_ops_message(user_profile: Dict, stage: str, progress_data: Dict = None) -> str:
    """Generate personalized, engaging people & operations message using Gemini AI"""
    try:
        # Extract user context
        business_name = user_profile.get('business_name', 'Your Business')
        username = user_profile.get('username', 'Leader')
        industry = user_profile.get('industry', 'Business')
        team_size = user_profile.get('team_size', 'Unknown')
        
        # Create stage-specific prompts for people & operations
        if stage == "start":
            prompt = f"""
            Create a MOTIVATING, personalized notification for {username} from {business_name} in the {industry} industry.
            They just started their PEOPLE & OPERATIONS assessment (focus on team, leadership, systems, culture).
            
            Make it:
            - INSPIRING and energizing about organizational excellence
            - Include a motivational reference to {industry} people/operations opportunities
            - Reference {business_name} with excitement about building foundations
            - Focus on TEAM DEVELOPMENT, LEADERSHIP, SYSTEMS, CULTURE
            - 1-2 sentences max with people/ops emojis (üë•üè¢‚öôÔ∏èüéØ)
            - Make them excited about their organizational journey!
            """
        
        elif stage == "middle":
            chapters_done = progress_data.get('chapters_completed', 4) if progress_data else 4
            total_chapters = progress_data.get('total_chapters', 8) if progress_data else 8
            
            prompt = f"""
            Create an ENERGIZING mid-progress notification for {username} from {business_name}.
            They're {chapters_done}/{total_chapters} chapters through their people & operations assessment.
            
            Make it:
            - MOTIVATING and encouraging about organizational discovery progress
            - Reference their {industry} team/systems potential enthusiastically
            - Focus on LEADERSHIP INSIGHTS, TEAM DEVELOPMENT
            - 1-2 sentences max with progress emojis
            - Keep them excited about organizational excellence!
            """
        
        elif stage == "complete":
            total_words = progress_data.get('total_words', 15000) if progress_data else 15000
            
            prompt = f"""
            Create a CELEBRATORY completion notification for {username} from {business_name}.
            Their people & operations foundation blueprint is complete with {total_words:,} words of organizational insights.
            
            Make it:
            - TRIUMPHANT and celebratory about their organizational blueprint
            - Reference {industry} people/operations excellence enthusiastically
            - Focus on FOUNDATION BLUEPRINT, ORGANIZATIONAL EXCELLENCE completion
            - 1-2 sentences max with celebration + people/ops emojis
            - Make them feel like an organizational architect!
            """
        
        # Use first available API key for notifications
        gemini_api_key = GEMINI_API_KEYS[0]
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=15)) as session:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent"
            
            payload = {
                "contents": [{
                    "role": "user",
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 1.0,
                    "maxOutputTokens": 150,
                    "topP": 0.95,
                    "candidateCount": 1
                }
            }
            
            params = {'key': gemini_api_key}
            
            async with session.post(url, json=payload, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    if 'candidates' in data and len(data['candidates']) > 0:
                        candidate = data['candidates'][0]
                        
                        content = ""
                        try:
                            if 'content' in candidate and 'parts' in candidate['content']:
                                content = candidate['content']['parts'][0]['text']
                            elif 'text' in candidate:
                                content = candidate['text']
                            else:
                                content = str(candidate.get('content', candidate))
                        except Exception as e:
                            logging.warning(f"Content extraction issue: {e}")
                            content = str(candidate)
                        
                        if content:
                            content = content.strip().replace('"', '').replace("'", "'")
                            if any(char in content for char in ['üë•', 'üè¢', '‚öôÔ∏è', 'üéØ', 'üî•', 'üéâ']) or len(content.split()) > 3:
                                if not any(tech in content.lower() for tech in ['role', 'model', 'parts', 'content']):
                                    logging.info(f"üé≠ Generated people & ops {stage} message for {username}")
                                    return content
    
    except Exception as e:
        logging.error(f"‚ùå Error generating people & ops message: {str(e)}")
    
    # Fallback messages for people & operations
    fallback_messages = {
        "start": [
            f"üë• {business_name}'s organizational foundation assessment starting! {username}, prepare for people insights!",
            f"üè¢ Breaking: {username}'s people & operations blueprint is being created! Warning: May cause team excellence!",
            f"‚öôÔ∏è Plot twist: {business_name}'s organizational potential is about to be unleashed!"
        ],
        "middle": [
            f"üéØ Halfway there! {username}'s people & operations foundations are being analyzed!",
            f"üë• {business_name}'s organizational opportunities are more exciting than expected! 50% complete!",
            f"üè¢ Update: {username}'s leadership and systems potential is off the charts!"
        ],
        "complete": [
            f"üéâ FOUNDATION COMPLETE! {username}'s people & operations blueprint is ready! {business_name} = unstoppable organization!",
            f"‚ú® Mission accomplished! {business_name} just became more organized than ever imagined!",
            f"üë• {username} is officially an organizational architect! Blueprint ready for implementation!"
        ]
    }
    
    return random.choice(fallback_messages.get(stage, fallback_messages["start"]))

async def send_personalized_people_ops_notification(user_id: str, user_profile: Dict, stage: str, progress_data: Dict = None):
    """Send personalized people & operations notification"""
    try:
        # Generate personalized message
        message = await generate_personalized_people_ops_message(user_profile, stage, progress_data)
        
        # Create titles for people & operations
        username = user_profile.get('username', 'Leader')
        business_name = user_profile.get('business_name', 'Your Business')
        
        motivating_titles = {
            "start": [
                f"üë• {username}, Foundation Time!",
                f"üè¢ {business_name} Organization!",
                f"‚öôÔ∏è People Assessment Started!"
            ],
            "middle": [
                f"üéØ {username} Building Foundations!",
                f"üë• {business_name} Halfway There!",
                f"üè¢ Organization Progress Update!"
            ],
            "complete": [
                f"üéâ {username}, Blueprint Complete!",
                f"‚ú® {business_name} Foundation Ready!",
                f"üë• Organizational Success!"
            ]
        }
        
        title = random.choice(motivating_titles[stage])
        
        # Send notification
        success, result = await send_people_ops_notification(user_id, title, message, "notification")
        
        if success:
            logging.info(f"üé≠ Sent people & ops {stage} notification to user {user_id}")
        else:
            logging.error(f"‚ùå Failed to send people & ops notification: {result}")
        
        return success, message
        
    except Exception as e:
        logging.error(f"‚ùå Error sending people & ops notification: {str(e)}")
        return False, str(e)

def send_people_ops_notification_background(user_id: str, user_profile: Dict, stage: str, progress_data: Dict = None):
    """FIXED: Send people & ops notification in background thread with proper async handling"""
    
    # Generate unique notification ID for tracking
    notification_id = f"people_ops_{stage}_{user_id}_{int(time.time())}"
    
    def notification_worker():
        worker_start_time = time.time()
        thread_id = threading.current_thread().ident
        
        try:
            logging.info(f"üîî NOTIFICATION WORKER START: {notification_id}")
            logging.info(f"üìä Notification details:")
            logging.info(f"   - User ID: {user_id}")
            logging.info(f"   - Stage: {stage}")
            logging.info(f"   - Thread ID: {thread_id}")
            logging.info(f"   - Business: {user_profile.get('business_name', 'Unknown') if user_profile else 'No profile'}")
            logging.info(f"   - Progress data: {bool(progress_data)}")
            
            # Validate inputs with detailed logging
            if not user_id:
                raise ValueError("user_id is required")
            
            if not stage:
                raise ValueError("stage is required")
            
            if stage not in ['start', 'middle', 'complete']:
                logging.warning(f"‚ö†Ô∏è Unusual stage value: '{stage}' (expected: start/middle/complete)")
            
            logging.info(f"‚úÖ Input validation passed for notification {notification_id}")
            
            # Platform-specific setup with detailed logging
            if platform.system() == 'Windows':
                logging.debug(f"ü™ü Setting Windows event loop policy for thread {thread_id}")
                asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
            
            # Event loop creation with detailed logging
            logging.debug(f"üîÑ Creating new event loop in thread {thread_id}")
            loop_start_time = time.time()
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop_creation_time = time.time() - loop_start_time
            
            logging.debug(f"‚úÖ Event loop created in {loop_creation_time:.3f}s")
            
            try:
                # üî• CRITICAL FIX: Execute notification with timeout using loop.run_until_complete
                logging.info(f"üì§ Executing notification for {notification_id}...")
                notification_start_time = time.time()
                
                # üî• MAIN FIX: Use loop.run_until_complete instead of await (since this is a sync function)
                try:
                    success, message = loop.run_until_complete(
                        asyncio.wait_for(
                            send_personalized_people_ops_notification(user_id, user_profile, stage, progress_data),
                            timeout=30.0  # 30 second timeout
                        )
                    )
                    
                    notification_time = time.time() - notification_start_time
                    
                    logging.info(f"üì° Notification execution completed in {notification_time:.3f}s")
                    logging.info(f"üìä Notification result:")
                    logging.info(f"   - Success: {success}")
                    logging.info(f"   - Message: {message}")
                    
                except asyncio.TimeoutError:
                    notification_time = time.time() - notification_start_time
                    success = False
                    message = f"Notification timed out after {notification_time:.1f}s"
                    
                    logging.error(f"‚è∞ TIMEOUT: Notification {notification_id} timed out after {notification_time:.1f}s")
                    logging.error(f"üîç This may indicate network issues or API problems")
                
                # Log final results with context
                total_worker_time = time.time() - worker_start_time
                
                if success:
                    logging.info(f"üéâ SUCCESS: Background people & ops {stage} notification sent")
                    logging.info(f"üìä Success metrics:")
                    logging.info(f"   - Notification ID: {notification_id}")
                    logging.info(f"   - User ID: {user_id}")
                    logging.info(f"   - Stage: {stage}")
                    logging.info(f"   - Total time: {total_worker_time:.3f}s")
                    logging.info(f"   - Notification time: {notification_time:.3f}s")
                    logging.info(f"   - Thread ID: {thread_id}")
                else:
                    logging.warning(f"‚ö†Ô∏è FAILURE: Background people & ops {stage} notification failed")
                    logging.warning(f"üìä Failure details:")
                    logging.warning(f"   - Notification ID: {notification_id}")
                    logging.warning(f"   - User ID: {user_id}")
                    logging.warning(f"   - Stage: {stage}")
                    logging.warning(f"   - Error message: {message}")
                    logging.warning(f"   - Total time: {total_worker_time:.3f}s")
                    logging.warning(f"   - Thread ID: {thread_id}")
                    
                    # Log additional context for failures
                    logging.warning(f"üîç Failure context:")
                    logging.warning(f"   - User profile available: {bool(user_profile)}")
                    logging.warning(f"   - Progress data available: {bool(progress_data)}")
                    if user_profile:
                        logging.warning(f"   - Business name: {user_profile.get('business_name', 'Not provided')}")
                        logging.warning(f"   - Username: {user_profile.get('username', 'Not provided')}")
                
            except Exception as loop_error:
                loop_error_time = time.time() - notification_start_time if 'notification_start_time' in locals() else 0
                total_worker_time = time.time() - worker_start_time
                
                logging.error(f"‚ùå LOOP ERROR: Exception in notification execution")
                logging.error(f"üîç Loop error details:")
                logging.error(f"   - Notification ID: {notification_id}")
                logging.error(f"   - Error type: {type(loop_error).__name__}")
                logging.error(f"   - Error message: {str(loop_error)}")
                logging.error(f"   - Loop error time: {loop_error_time:.3f}s")
                logging.error(f"   - Total worker time: {total_worker_time:.3f}s")
                logging.error(f"   - Thread ID: {thread_id}")
                
                # Log the full traceback for debugging
                import traceback
                logging.error(f"üîç Loop error traceback:")
                for line in traceback.format_exc().split('\n'):
                    if line.strip():
                        logging.error(f"   {line}")
                
            finally:
                # Clean up event loop with logging
                try:
                    loop_cleanup_start = time.time()
                    
                    logging.debug(f"üîÑ Cleaning up event loop for thread {thread_id}")
                    
                    # Cancel any remaining tasks
                    pending_tasks = [task for task in asyncio.all_tasks(loop) if not task.done()]
                    if pending_tasks:
                        logging.warning(f"‚ö†Ô∏è Found {len(pending_tasks)} pending tasks, cancelling...")
                        for task in pending_tasks:
                            task.cancel()
                    
                    loop.close()
                    loop_cleanup_time = time.time() - loop_cleanup_start
                    
                    logging.debug(f"‚úÖ Event loop cleaned up in {loop_cleanup_time:.3f}s")
                    
                except Exception as cleanup_error:
                    logging.error(f"‚ùå Error during loop cleanup: {cleanup_error}")
                
        except Exception as worker_error:
            total_worker_time = time.time() - worker_start_time
            
            logging.error(f"üí• WORKER ERROR: Critical error in notification worker")
            logging.error(f"üîç Worker error details:")
            logging.error(f"   - Notification ID: {notification_id}")
            logging.error(f"   - User ID: {user_id}")
            logging.error(f"   - Stage: {stage}")
            logging.error(f"   - Error type: {type(worker_error).__name__}")
            logging.error(f"   - Error message: {str(worker_error)}")
            logging.error(f"   - Total worker time: {total_worker_time:.3f}s")
            logging.error(f"   - Thread ID: {thread_id}")
            
            # Log additional context
            logging.error(f"üîç Worker error context:")
            logging.error(f"   - Platform: {platform.system()}")
            logging.error(f"   - Python version: {sys.version}")
            logging.error(f"   - User profile type: {type(user_profile)}")
            logging.error(f"   - Progress data type: {type(progress_data)}")
            
            # Log the full traceback for debugging
            import traceback
            logging.error(f"üîç Worker error traceback:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    logging.error(f"   {line}")
        
        finally:
            # Final cleanup and statistics
            total_worker_time = time.time() - worker_start_time
            
            logging.info(f"üèÅ NOTIFICATION WORKER END: {notification_id}")
            logging.info(f"üìä Worker final statistics:")
            logging.info(f"   - Total execution time: {total_worker_time:.3f}s")
            logging.info(f"   - Thread ID: {thread_id}")
            logging.info(f"   - Worker completed at: {datetime.now().isoformat()}")
            
            # Clean up thread-local data if needed
            try:
                # Remove any thread-local references
                if hasattr(threading.current_thread(), '_notification_data'):
                    delattr(threading.current_thread(), '_notification_data')
            except:
                pass  # Ignore cleanup errors
    
    # üî• ENHANCEMENT: Better thread creation with error handling
    try:
        logging.info(f"üöÄ LAUNCHING: Background notification thread for {notification_id}")
        
        # Create thread with proper naming and error handling
        notification_thread = Thread(
            target=notification_worker, 
            daemon=True,
            name=f"PeopleOpsNotification-{stage}-{user_id}"
        )
        
        # Store notification metadata in thread for debugging
        notification_thread._notification_data = {
            'notification_id': notification_id,
            'user_id': user_id,
            'stage': stage,
            'created_at': time.time()
        }
        
        thread_start_time = time.time()
        notification_thread.start()
        thread_start_duration = time.time() - thread_start_time
        
        logging.info(f"‚úÖ Notification thread launched successfully")
        logging.info(f"üìä Thread launch details:")
        logging.info(f"   - Notification ID: {notification_id}")
        logging.info(f"   - Thread name: {notification_thread.name}")
        logging.info(f"   - Thread ID: {notification_thread.ident}")
        logging.info(f"   - Launch time: {thread_start_duration:.3f}s")
        logging.info(f"   - Daemon thread: {notification_thread.daemon}")
        
        # üî• ENHANCEMENT: Optional thread monitoring (can be enabled for debugging)
        if logging.getLogger().isEnabledFor(logging.DEBUG):
            def monitor_thread():
                time.sleep(1)  # Give thread time to start
                if notification_thread.is_alive():
                    logging.debug(f"üîç Thread {notification_thread.name} is running")
                else:
                    logging.warning(f"‚ö†Ô∏è Thread {notification_thread.name} finished quickly")
            
            Thread(target=monitor_thread, daemon=True).start()
        
    except Exception as thread_error:
        logging.error(f"üí• THREAD CREATION ERROR: Failed to create notification thread")
        logging.error(f"üîç Thread error details:")
        logging.error(f"   - Notification ID: {notification_id}")
        logging.error(f"   - User ID: {user_id}")
        logging.error(f"   - Stage: {stage}")
        logging.error(f"   - Error type: {type(thread_error).__name__}")
        logging.error(f"   - Error message: {str(thread_error)}")
        
        # Log the full traceback for debugging
        import traceback
        logging.error(f"üîç Thread creation traceback:")
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                logging.error(f"   {line}")

# üî• MINIMAL ADDITION: Helper function to check notification system health
def get_notification_system_health():
    """Get basic notification system health info (minimal addition)"""
    
    active_threads = [t for t in threading.enumerate() if 'PeopleOpsNotification' in t.name]
    
    health_info = {
        'timestamp': datetime.now().isoformat(),
        'active_notification_threads': len(active_threads),
        'thread_details': []
    }
    
    for thread in active_threads:
        thread_info = {
            'name': thread.name,
            'alive': thread.is_alive(),
            'daemon': thread.daemon
        }
        
        # Add notification metadata if available
        if hasattr(thread, '_notification_data'):
            thread_info.update(thread._notification_data)
            thread_info['age_seconds'] = time.time() - thread._notification_data.get('created_at', time.time())
        
        health_info['thread_details'].append(thread_info)
    
    return health_info

# ======================================================
#           Gemini AI Integration
# ======================================================

@dataclass
class PeopleOpsChatResponse:
    content: str
    model: str
    api_key_used: str
    usage: Dict[str, Any]
    finish_reason: str
    response_time: float
    timestamp: float
    token_count: int

def convert_messages_to_gemini_format(messages: List[Dict[str, str]]) -> List[Dict]:
    """Convert messages to Gemini API format"""
    contents = []
    
    for msg in messages:
        role = msg["role"]
        content = msg["content"]
        
        if role in ["user", "human"]:
            if contents and contents[-1]["role"] == "user":
                contents[-1]["parts"].append({"text": content})
            else:
                contents.append({
                    "role": "user",
                    "parts": [{"text": content}]
                })
        elif role in ["assistant", "model", "ai"]:
            contents.append({
                "role": "model",
                "parts": [{"text": content}]
            })
        elif role == "system":
            if contents and contents[-1]["role"] == "user":
                contents[-1]["parts"].insert(0, {"text": f"SYSTEM CONTEXT: {content}\n\n"})
            else:
                contents.append({
                    "role": "user",
                    "parts": [{"text": f"SYSTEM CONTEXT: {content}"}]
                })
    
    return contents

def people_ops_ultra_deep_analysis(
    complete_raw_data: Dict,
    analysis_type: str,
    analysis_requirements: str,
    api_key: str,
    client_id: str = "people_ops_analysis",
    temperature: float = 0.7,
    max_tokens: int = 1000000
) -> PeopleOpsChatResponse:
    """FIXED: Enhanced people & operations analysis with ultra-deep response analysis and detailed logging"""
    
    start_time = time.time()
    request_start_time = None  # Initialize to prevent NameError
    
    logging.info(f"üöÄ [{client_id}] Starting People & Operations Analysis: {analysis_type}")
    logging.info(f"üîç [{client_id}] Input parameters: temp={temperature}, max_tokens={max_tokens}")
    logging.info(f"üîç [{client_id}] API key ending: ...{api_key[-4:]}")
    logging.info(f"üîç [{client_id}] Complete raw data keys: {list(complete_raw_data.keys()) if complete_raw_data else 'No data'}")
    logging.info(f"üîç [{client_id}] Analysis requirements length: {len(analysis_requirements)} characters")
    
    # ENHANCED: Log API key health status at start with comprehensive metrics
    key_health = api_key_health.get(api_key, {})
    if key_health:
        success_rate = key_health.get('success_rate', 1.0)
        current_load = key_health.get('current_load', 0)
        consecutive_failures = key_health.get('consecutive_failures', 0)
        total_requests = key_health.get('total_requests', 0)
        avg_response = statistics.mean(key_health.get('response_times', [0])) if key_health.get('response_times') else 0
        last_503_time = key_health.get('last_503_time')
        
        logging.info(f"üîë [{client_id}] API Key Health at Start: {key_health.get('key_id', 'unknown')} - "
                    f"Failures: {consecutive_failures}, "
                    f"Total Requests: {total_requests}, "
                    f"Success Rate: {success_rate:.2f}, "
                    f"Current Load: {current_load}, "
                    f"Avg Response: {avg_response:.1f}s")
        
        # ENHANCED: Check if key is in cooldown
        if last_503_time:
            cooldown_remaining = 300 - (time.time() - last_503_time)
            if cooldown_remaining > 0:
                logging.warning(f"‚è∞ [{client_id}] API Key in cooldown: {cooldown_remaining:.1f}s remaining")
            else:
                logging.info(f"‚úÖ [{client_id}] API Key cooldown expired, ready for use")
        
        # ENHANCED: Check if key is overloaded
        if current_load > 3:
            logging.warning(f"‚ö†Ô∏è [{client_id}] API Key overloaded: {current_load} concurrent requests")
        
        # ENHANCED: Log overall API ecosystem health
        logging.info(f"üîë [{client_id}] Overall API Key Ecosystem: {get_api_key_status_summary()}")
    else:
        logging.warning(f"‚ö†Ô∏è [{client_id}] No health data available for API key ...{api_key[-4:]}")

    try:
        # ========================================================================
        # STEP 1: TRY VERTEX AI FIRST (PRIMARY METHOD)
        # ========================================================================
        logging.info(f"üîç [{client_id}] Creating prompt for Vertex AI attempt...")

        try:
            enhanced_prompt_for_vertex = create_enhanced_people_ops_analysis_prompt(
                complete_raw_data, analysis_type, analysis_requirements
            )

            # Try Vertex AI first
            vertex_result = try_vertex_ai_people_ops_request(
                enhanced_prompt=enhanced_prompt_for_vertex,
                temperature=temperature,
                max_tokens=max_tokens,
                start_time=start_time
            )

            if vertex_result and vertex_result.get("success"):
                # Vertex AI succeeded - return response
                content = vertex_result["content"]
                total_time = time.time() - start_time

                logging.info(f"‚úÖ [{client_id}] Vertex AI completed successfully")
                logging.info(f"üìä [{client_id}] Response: {len(content)} chars, {len(content.split())} words")
                logging.info(f"‚è±Ô∏è [{client_id}] Total time: {total_time:.2f}s")

                return PeopleOpsChatResponse(
                    content=content,
                    finish_reason='VERTEX_AI_SUCCESS',
                    total_time=total_time,
                    prompt_tokens=vertex_result.get("token_count", 0),
                    completion_tokens=0,
                    total_tokens=vertex_result.get("token_count", 0),
                    model=vertex_result.get("model", "gemini-2.5-pro-vertex")
                )
            else:
                logging.info(f"‚ö†Ô∏è [{client_id}] Vertex AI unavailable, using API keys fallback")

        except Exception as vertex_error:
            logging.warning(f"‚ö†Ô∏è [{client_id}] Vertex AI attempt failed: {str(vertex_error)}")
            logging.info(f"üîÑ [{client_id}] Falling back to API keys")

        # ========================================================================
        # STEP 2: FALLBACK TO API KEYS
        # ========================================================================

        # ENHANCED: Create enhanced prompt with validation
        logging.info(f"üìù [{client_id}] Creating enhanced prompt...")
        prompt_creation_start = time.time()

        try:
            enhanced_prompt = create_enhanced_people_ops_analysis_prompt(
                complete_raw_data, analysis_type, analysis_requirements
            )
            prompt_creation_time = time.time() - prompt_creation_start

            logging.info(f"‚úÖ [{client_id}] Prompt created successfully in {prompt_creation_time:.3f}s")
            logging.info(f"üîç [{client_id}] Prompt length: {len(enhanced_prompt):,} characters")
            logging.info(f"üîç [{client_id}] Prompt word count: ~{len(enhanced_prompt.split()):,} words")

            # ENHANCED: Validate prompt isn't too large
            if len(enhanced_prompt) > 100000:  # 100KB limit
                logging.warning(f"‚ö†Ô∏è [{client_id}] Large prompt detected: {len(enhanced_prompt):,} chars")

        except Exception as prompt_error:
            logging.error(f"‚ùå [{client_id}] Prompt creation failed: {prompt_error}")
            logging.error(f"üîç [{client_id}] Prompt error type: {type(prompt_error).__name__}")
            raise Exception(f"Failed to create analysis prompt: {prompt_error}")

        # ENHANCED: Convert to Gemini format with validation
        logging.info(f"üîÑ [{client_id}] Converting to Gemini format...")
        format_conversion_start = time.time()

        try:
            contents = convert_messages_to_gemini_format([
                {"role": "user", "content": enhanced_prompt}
            ])
            format_conversion_time = time.time() - format_conversion_start

            logging.info(f"‚úÖ [{client_id}] Gemini format conversion successful in {format_conversion_time:.3f}s")
            logging.info(f"üîç [{client_id}] Converted contents length: {len(contents)}")
            logging.info(f"üîç [{client_id}] Contents structure validation: {all('role' in c and 'parts' in c for c in contents)}")

        except Exception as format_error:
            logging.error(f"‚ùå [{client_id}] Gemini format conversion failed: {format_error}")
            raise Exception(f"Failed to convert to Gemini format: {format_error}")

        # ========================================================================

        # ENHANCED: Create enhanced prompt with validation
        logging.info(f"üìù [{client_id}] Creating enhanced prompt...")
        prompt_creation_start = time.time()

        try:
            enhanced_prompt = create_enhanced_people_ops_analysis_prompt(
                complete_raw_data, analysis_type, analysis_requirements
            )
            prompt_creation_time = time.time() - prompt_creation_start

            logging.info(f"‚úÖ [{client_id}] Prompt created successfully in {prompt_creation_time:.3f}s")
            logging.info(f"üîç [{client_id}] Prompt length: {len(enhanced_prompt):,} characters")
            logging.info(f"üîç [{client_id}] Prompt word count: ~{len(enhanced_prompt.split()):,} words")

            # ENHANCED: Validate prompt isn't too large
            if len(enhanced_prompt) > 100000:  # 100KB limit
                logging.warning(f"‚ö†Ô∏è [{client_id}] Large prompt detected: {len(enhanced_prompt):,} chars")

        except Exception as prompt_error:
            logging.error(f"‚ùå [{client_id}] Prompt creation failed: {prompt_error}")
            logging.error(f"üîç [{client_id}] Prompt error type: {type(prompt_error).__name__}")
            raise Exception(f"Failed to create analysis prompt: {prompt_error}")

        # ENHANCED: Convert to Gemini format with validation
        logging.info(f"üîÑ [{client_id}] Converting to Gemini format...")
        format_conversion_start = time.time()

        try:
            contents = convert_messages_to_gemini_format([
                {"role": "user", "content": enhanced_prompt}
            ])
            format_conversion_time = time.time() - format_conversion_start

            logging.info(f"‚úÖ [{client_id}] Gemini format conversion successful in {format_conversion_time:.3f}s")
            logging.info(f"üîç [{client_id}] Converted contents length: {len(contents)}")
            logging.info(f"üîç [{client_id}] Contents structure validation: {all('role' in c and 'parts' in c for c in contents)}")

        except Exception as format_error:
            logging.error(f"‚ùå [{client_id}] Gemini format conversion failed: {format_error}")
            raise Exception(f"Failed to convert to Gemini format: {format_error}")

        # ENHANCED: Production-optimized payload with validation
        logging.info(f"üîß [{client_id}] Creating API payload...")
        payload = {
            "contents": contents,
            "generationConfig": {
                "temperature": temperature,
                "maxOutputTokens": max_tokens,
                "topP": 0.9,
                "topK": 40,
                "candidateCount": 1,
                "stopSequences": [],
                "responseMimeType": "text/plain"
            },
            "safetySettings": [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
            ]
        }
        
        params = {'key': api_key}
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent"
        
        logging.info(f"üåê [{client_id}] Preparing API request to Gemini")
        logging.info(f"üîç [{client_id}] API URL: {url}")
        logging.info(f"üîç [{client_id}] Payload keys: {list(payload.keys())}")
        logging.info(f"üîç [{client_id}] Generation config: {payload['generationConfig']}")
        logging.info(f"üîç [{client_id}] Safety settings count: {len(payload['safetySettings'])}")
        
        # ENHANCED: Request execution with comprehensive monitoring
        logging.info(f"üì§ [{client_id}] Sending request to Gemini API...")
        request_start_time = time.time()
        
        try:
            response = requests.post(
                url,
                json=payload,
                params=params,
                timeout=REQUEST_TIMEOUT
            )
            
            # Calculate response time immediately
            response_time = time.time() - request_start_time
            
            logging.info(f"üì° [{client_id}] Response received from Gemini API")
            logging.info(f"‚è±Ô∏è [{client_id}] Response time: {response_time:.2f}s")
            logging.info(f"üìä [{client_id}] Response status: {response.status_code}")
            logging.info(f"üîç [{client_id}] Response headers: {dict(response.headers)}")
            logging.info(f"üîç [{client_id}] Response size: {len(response.text)} characters")
            
        except requests.exceptions.Timeout:
            response_time = time.time() - request_start_time
            logging.error(f"‚è∞ [{client_id}] Request timed out after {response_time:.2f}s (timeout: {REQUEST_TIMEOUT}s)")
            update_api_key_health(api_key, success=False, error_code="TIMEOUT", response_time=response_time)
            raise Exception(f"Request timed out after {REQUEST_TIMEOUT}s")
            
        except requests.exceptions.ConnectionError as conn_error:
            response_time = time.time() - request_start_time
            logging.error(f"üåê [{client_id}] Connection error after {response_time:.2f}s: {conn_error}")
            update_api_key_health(api_key, success=False, error_code="CONNECTION_ERROR", response_time=response_time)
            raise Exception(f"Connection error: {conn_error}")
            
        except Exception as request_error:
            response_time = time.time() - request_start_time
            logging.error(f"‚ùå [{client_id}] Request error after {response_time:.2f}s: {request_error}")
            update_api_key_health(api_key, success=False, error_code="REQUEST_ERROR", response_time=response_time)
            raise Exception(f"Request error: {request_error}")
        
        # ENHANCED: HTTP Response Processing
        if response.status_code == 200:
            # SUCCESS: Update API key health with response time
            logging.info(f"‚úÖ [{client_id}] HTTP 200 Success - Processing response")
            update_api_key_health(api_key, success=True, response_time=response_time)
            
            # ENHANCED: JSON parsing with detailed validation
            try:
                logging.info(f"üîÑ [{client_id}] Parsing JSON response...")
                json_parse_start = time.time()
                
                data = response.json()
                json_parse_time = time.time() - json_parse_start
                
                logging.info(f"‚úÖ [{client_id}] JSON parsing successful in {json_parse_time:.3f}s")
                logging.info(f"üîç [{client_id}] Response data size: {len(str(data))} characters")
                
            except json.JSONDecodeError as json_error:
                logging.error(f"‚ùå [{client_id}] JSON parsing failed: {json_error}")
                logging.error(f"üîç [{client_id}] Raw response text (first 500 chars): {response.text[:500]}...")
                logging.error(f"üîç [{client_id}] Response content-type: {response.headers.get('content-type', 'Unknown')}")
                
                # JSON parsing failure - update API key health
                update_api_key_health(api_key, success=False, error_code="JSON_PARSE_ERROR", response_time=response_time)
                raise Exception(f"Failed to parse JSON response: {json_error}")
            
            except Exception as parsing_error:
                logging.error(f"‚ùå [{client_id}] Unexpected parsing error: {parsing_error}")
                update_api_key_health(api_key, success=False, error_code="PARSING_ERROR", response_time=response_time)
                raise Exception(f"Unexpected parsing error: {parsing_error}")
            
            # ULTRA DETAILED LOGGING FOR AI RESPONSE
            logging.info(f"üîç [{client_id}] RAW API RESPONSE ANALYSIS:")
            logging.info(f"üîç [{client_id}] Top-level response keys: {list(data.keys())}")
            
            # ENHANCED: Log response metadata
            if 'usageMetadata' in data:
                usage_meta = data['usageMetadata']
                logging.info(f"üìä [{client_id}] Usage metadata: {usage_meta}")
                prompt_tokens = usage_meta.get('promptTokenCount', 0)
                total_tokens = usage_meta.get('totalTokenCount', 0)
                completion_tokens = total_tokens - prompt_tokens
                logging.info(f"üìä [{client_id}] Token breakdown: prompt={prompt_tokens}, completion={completion_tokens}, total={total_tokens}")
            
            if 'modelVersion' in data:
                logging.info(f"ü§ñ [{client_id}] Model version: {data['modelVersion']}")
            
            if 'responseId' in data:
                logging.info(f"üÜî [{client_id}] Response ID: {data['responseId']}")
            
            # CRITICAL FIX: Enhanced candidate validation
            if 'candidates' in data and len(data['candidates']) > 0:
                candidate = data['candidates'][0]
                logging.info(f"üîç [{client_id}] CANDIDATE ANALYSIS:")
                logging.info(f"üîç [{client_id}] Found {len(data['candidates'])} candidate(s)")
                logging.info(f"üîç [{client_id}] Candidate keys: {list(candidate.keys())}")
                logging.info(f"üîç [{client_id}] Candidate structure: {json.dumps(candidate, indent=2, default=str)[:800]}...")
                
                # ENHANCED: Check finish reason with detailed analysis
                finish_reason = candidate.get('finishReason', 'UNKNOWN')
                logging.info(f"üîç [{client_id}] Finish reason: {finish_reason}")
                
                # CRITICAL: Validate finish reason
                if finish_reason == 'SAFETY':
                    logging.error(f"üö® [{client_id}] Content blocked by safety filters")
                    logging.error(f"üîç [{client_id}] Safety ratings: {candidate.get('safetyRatings', 'None')}")
                    update_api_key_health(api_key, success=False, error_code="SAFETY_FILTER", response_time=response_time)
                    raise Exception("Content blocked by safety filters")
                elif finish_reason in ['MAX_TOKENS', 'RECITATION']:
                    logging.warning(f"‚ö†Ô∏è [{client_id}] Response truncated due to: {finish_reason}")
                elif finish_reason != 'STOP':
                    logging.warning(f"‚ö†Ô∏è [{client_id}] Unusual finish reason: {finish_reason}")
                
                # ENHANCED: Check safety ratings
                if 'safetyRatings' in candidate:
                    safety_ratings = candidate['safetyRatings']
                    logging.info(f"üîç [{client_id}] Safety ratings: {safety_ratings}")
                    
                    # Check for blocking
                    blocked_categories = [r for r in safety_ratings if r.get('probability') in ['HIGH', 'MEDIUM']]
                    if blocked_categories:
                        logging.warning(f"‚ö†Ô∏è [{client_id}] Potentially blocked categories: {blocked_categories}")
                
                # CRITICAL FIX: Enhanced content extraction with detailed validation
                content = ""
                extraction_method = "none"
                extraction_start = time.time()
                
                logging.info(f"üîç [{client_id}] CONTENT EXTRACTION ANALYSIS:")
                
                try:
                    # CRITICAL FIX: Method 1 - Standard content extraction with validation
                    if 'content' in candidate and candidate['content'] is not None:
                        content_obj = candidate['content']
                        logging.info(f"üîç [{client_id}] Found content object: {type(content_obj)}")
                        logging.info(f"üîç [{client_id}] Content object keys: {list(content_obj.keys()) if isinstance(content_obj, dict) else 'Not a dict'}")
                        logging.info(f"üîç [{client_id}] Content object preview: {json.dumps(content_obj, indent=2, default=str)[:400]}...")
                        
                        # CRITICAL FIX: Validate content object structure
                        if not isinstance(content_obj, dict):
                            logging.error(f"‚ùå [{client_id}] Content object is not a dictionary: {type(content_obj)}")
                            logging.error(f"üîç [{client_id}] Content object value: {content_obj}")
                            update_api_key_health(api_key, success=False, error_code="INVALID_CONTENT_TYPE", response_time=response_time)
                            raise Exception(f"Content object is not a dictionary: {type(content_obj)}")
                        
                        # CRITICAL FIX: Check for malformed content object
                        if content_obj == {'role': 'model'}:
                            logging.error(f"üö® [{client_id}] MALFORMED RESPONSE: Got metadata instead of content")
                            logging.error(f"üîç [{client_id}] This indicates API key returned incomplete response")
                            logging.error(f"üîç [{client_id}] Full candidate: {json.dumps(candidate, indent=2, default=str)}")
                            update_api_key_health(api_key, success=False, error_code="METADATA_RESPONSE", response_time=response_time)
                            raise Exception("API returned metadata instead of content - key may be corrupted")
                        
                        if 'parts' in content_obj and content_obj['parts']:
                            parts = content_obj['parts']
                            logging.info(f"üîç [{client_id}] Found content.parts: {len(parts)} parts")
                            
                            if len(parts) > 0:
                                first_part = parts[0]
                                logging.info(f"üîç [{client_id}] First part type: {type(first_part)}")
                                logging.info(f"üîç [{client_id}] First part keys: {list(first_part.keys()) if isinstance(first_part, dict) else 'Not a dict'}")
                                logging.info(f"üîç [{client_id}] First part preview: {json.dumps(first_part, indent=2, default=str)[:300]}...")
                                
                                if isinstance(first_part, dict) and 'text' in first_part:
                                    content = first_part['text']
                                    extraction_method = "content.parts[0].text"
                                    logging.info(f"‚úÖ [{client_id}] Extracted via method 1: {len(content)} characters")
                                else:
                                    logging.warning(f"‚ö†Ô∏è [{client_id}] First part has no 'text' field")
                                    logging.warning(f"üîç [{client_id}] First part content: {first_part}")
                            else:
                                logging.warning(f"‚ö†Ô∏è [{client_id}] Parts array is empty")
                        else:
                            logging.warning(f"‚ö†Ô∏è [{client_id}] Content object has no 'parts' field or parts is empty")
                            logging.warning(f"üîç [{client_id}] Content object: {content_obj}")
                            
                            # CRITICAL FIX: Check for alternative content structures
                            if 'text' in content_obj:
                                content = content_obj['text']
                                extraction_method = "content.text"
                                logging.info(f"‚úÖ [{client_id}] Found alternative text field: {len(content)} characters")
                    
                    # CRITICAL FIX: Method 2 - Direct text field with validation
                    if not content and 'text' in candidate:
                        content = candidate['text']
                        extraction_method = "candidate.text"
                        logging.info(f"‚úÖ [{client_id}] Extracted via method 2: {len(content)} characters")
                    
                    # CRITICAL FIX: Method 3 - Search for any text-like fields
                    if not content:
                        logging.warning(f"‚ö†Ô∏è [{client_id}] No content found via standard methods, searching for text fields...")
                        
                        for key, value in candidate.items():
                            if isinstance(value, str) and len(value) > 20:  # Increased minimum length
                                content = value
                                extraction_method = f"candidate.{key}"
                                logging.info(f"‚úÖ [{client_id}] Extracted via method 3 ({key}): {len(content)} characters")
                                break
                            elif isinstance(value, dict):
                                # Search nested dictionaries
                                for nested_key, nested_value in value.items():
                                    if isinstance(nested_value, str) and len(nested_value) > 20:
                                        content = nested_value
                                        extraction_method = f"candidate.{key}.{nested_key}"
                                        logging.info(f"‚úÖ [{client_id}] Extracted via method 3 nested ({key}.{nested_key}): {len(content)} characters")
                                        break
                                if content:
                                    break
                    
                    # CRITICAL FIX: Method 4 - Enhanced fallback with validation
                    if not content:
                        logging.error(f"üö® [{client_id}] NO CONTENT FOUND: All extraction methods failed")
                        logging.error(f"üîç [{client_id}] Candidate debug info:")
                        logging.error(f"   - Candidate type: {type(candidate)}")
                        logging.error(f"   - Candidate keys: {list(candidate.keys()) if isinstance(candidate, dict) else 'Not a dict'}")
                        logging.error(f"   - Candidate repr: {repr(candidate)[:300]}...")
                        
                        # Last resort: string conversion with validation
                        content_obj = candidate.get('content', candidate)
                        content_str = str(content_obj)
                        
                        # CRITICAL FIX: Validate the string conversion isn't just metadata
                        if len(content_str) > 50 and not (content_str.count('{') > 3 and content_str.count('}') > 3):
                            content = content_str
                            extraction_method = "string_conversion_validated"
                            logging.warning(f"‚ö†Ô∏è [{client_id}] Extracted via method 4 (validated): {len(content)} characters")
                        else:
                            logging.error(f"üö® [{client_id}] String conversion also failed or returned metadata")
                            logging.error(f"üîç [{client_id}] String conversion result: {content_str[:200]}...")
                            extraction_method = "failed"
                        
                except Exception as extraction_error:
                    logging.error(f"‚ùå [{client_id}] Content extraction error: {extraction_error}")
                    logging.error(f"üîç [{client_id}] Candidate type: {type(candidate)}")
                    logging.error(f"üîç [{client_id}] Extraction error type: {type(extraction_error).__name__}")
                    
                    # Fallback extraction
                    content = str(candidate)
                    extraction_method = "error_fallback"
                    logging.warning(f"‚ö†Ô∏è [{client_id}] Using error fallback extraction: {len(content)} characters")
                
                extraction_time = time.time() - extraction_start
                
                # ENHANCED: Detailed content validation with comprehensive checks
                logging.info(f"üîç [{client_id}] CONTENT VALIDATION ANALYSIS:")
                logging.info(f"üîç [{client_id}] Extraction method: {extraction_method}")
                logging.info(f"üîç [{client_id}] Extraction time: {extraction_time:.3f}s")
                logging.info(f"üîç [{client_id}] Content type: {type(content)}")
                logging.info(f"üîç [{client_id}] Content length: {len(content) if content else 0}")
                logging.info(f"üîç [{client_id}] Content stripped length: {len(content.strip()) if content else 0}")
                logging.info(f"üîç [{client_id}] Content preview (first 300 chars): '{content[:300] if content else 'EMPTY'}'")
                
                # CRITICAL FIX: Enhanced content validation with specific error types
                if not content:
                    logging.error(f"‚ùå [{client_id}] VALIDATION FAILED: Content is None or False")
                    logging.error(f"üîç [{client_id}] Candidate finish reason: {finish_reason}")
                    logging.error(f"üîç [{client_id}] Full candidate debug: {json.dumps(candidate, indent=2, default=str)}")
                    update_api_key_health(api_key, success=False, error_code="NO_CONTENT", response_time=response_time)
                    raise Exception("Content is None - API returned no text")
                    
                elif content.strip() == "":
                    logging.error(f"‚ùå [{client_id}] VALIDATION FAILED: Content is empty string or whitespace only")
                    logging.error(f"üîç [{client_id}] Raw content representation: {repr(content)}")
                    update_api_key_health(api_key, success=False, error_code="EMPTY_CONTENT", response_time=response_time)
                    raise Exception("Content is empty string - API returned whitespace only")
                    
                elif len(content.strip()) < 10:  # ENHANCED: Increased minimum from 5 to 10
                    logging.error(f"‚ùå [{client_id}] VALIDATION FAILED: Content too short: '{content.strip()}'")
                    logging.error(f"üîç [{client_id}] Content length: {len(content.strip())} characters")
                    logging.error(f"üîç [{client_id}] This usually indicates API returned metadata instead of content")
                    update_api_key_health(api_key, success=False, error_code="SHORT_CONTENT", response_time=response_time)
                    raise Exception(f"Content too short ({len(content.strip())} chars): '{content.strip()}'")
                
                # ENHANCED: Check for metadata-only responses
                elif any(metadata_indicator in content.lower() for metadata_indicator in ['role": "model', '"parts":', '"content":']):
                    logging.error(f"üö® [{client_id}] VALIDATION FAILED: Content appears to be metadata")
                    logging.error(f"üîç [{client_id}] Metadata indicators found in content")
                    logging.error(f"üîç [{client_id}] Content: {content[:200]}...")
                    update_api_key_health(api_key, success=False, error_code="METADATA_CONTENT", response_time=response_time)
                    raise Exception("Content appears to be API metadata instead of generated text")
                
                else:
                    # SUCCESS: Content validation passed
                    word_count = len(content.split())
                    logging.info(f"‚úÖ [{client_id}] CONTENT VALIDATION PASSED")
                    logging.info(f"üìä [{client_id}] Content metrics:")
                    logging.info(f"   - Character count: {len(content):,}")
                    logging.info(f"   - Word count: {word_count:,}")
                    logging.info(f"   - Line count: {content.count(chr(10)) + 1}")
                    logging.info(f"   - Extraction method: {extraction_method}")
                    logging.info(f"   - Content quality: {'HIGH' if word_count > 500 else 'MEDIUM' if word_count > 100 else 'LOW'}")
                
                # ENHANCED: Success metrics calculation
                usage = data.get('usageMetadata', {})
                token_count = usage.get('totalTokenCount', 0)
                analysis_time = time.time() - start_time
                
                logging.info(f"üéâ [{client_id}] ANALYSIS COMPLETE - SUCCESS")
                logging.info(f"üìä [{client_id}] Final success metrics:")
                logging.info(f"   - Analysis type: {analysis_type}")
                logging.info(f"   - Total tokens: {token_count:,}")
                logging.info(f"   - Total time: {analysis_time:.2f}s")
                logging.info(f"   - Request time: {response_time:.2f}s")
                logging.info(f"   - Processing time: {(analysis_time - response_time):.2f}s")
                logging.info(f"   - Words generated: {len(content.split()):,}")
                logging.info(f"   - Characters generated: {len(content):,}")
                
                # ENHANCED: Log final API key health status after successful completion
                updated_health = api_key_health.get(api_key, {})
                updated_success_rate = updated_health.get('success_rate', 1.0)
                updated_current_load = updated_health.get('current_load', 0)
                updated_total_requests = updated_health.get('total_requests', 0)
                
                logging.info(f"üîë [{client_id}] FINAL API KEY HEALTH:")
                logging.info(f"   - Key ID: {updated_health.get('key_id', 'unknown')}")
                logging.info(f"   - Status: HEALTHY")
                logging.info(f"   - Consecutive Failures: 0 (reset)")
                logging.info(f"   - Success Rate: {updated_success_rate:.3f}")
                logging.info(f"   - Current Load: {updated_current_load}")
                logging.info(f"   - Total Requests: {updated_total_requests}")
                logging.info(f"   - Last Response Time: {response_time:.2f}s")
                
                # ENHANCED: Create response object with comprehensive metadata
                response_obj = PeopleOpsChatResponse(
                    content=content,
                    model="gemini-2.5-pro",
                    api_key_used=f"{client_id}_key_{api_key[-4:]}",
                    usage=usage,
                    finish_reason=candidate.get('finishReason', 'STOP'),
                    response_time=analysis_time,
                    timestamp=time.time(),
                    token_count=token_count
                )
                
                logging.info(f"‚úÖ [{client_id}] Response object created successfully")
                logging.info(f"üéØ [{client_id}] Returning successful analysis result")
                
                return response_obj
                
            else:
                # CRITICAL ERROR: No candidates in response
                logging.error(f"‚ùå [{client_id}] CRITICAL ERROR: No candidates in response")
                logging.error(f"üîç [{client_id}] Response data: {data}")
                logging.error(f"üîç [{client_id}] Response structure analysis:")
                
                if 'candidates' in data:
                    candidates = data['candidates']
                    logging.error(f"   - Candidates key exists: True")
                    logging.error(f"   - Candidates type: {type(candidates)}")
                    logging.error(f"   - Candidates length: {len(candidates)}")
                    logging.error(f"   - Candidates content: {candidates}")
                else:
                    logging.error(f"   - Candidates key exists: False")
                    logging.error(f"   - Available keys: {list(data.keys())}")
                
                # Check for error indicators in response
                if 'error' in data:
                    error_info = data['error']
                    logging.error(f"üö® [{client_id}] API returned error: {error_info}")
                    update_api_key_health(api_key, success=False, error_code="API_ERROR", response_time=response_time)
                    raise Exception(f"API error: {error_info}")
                
                update_api_key_health(api_key, success=False, error_code="NO_CANDIDATES", response_time=response_time)
                raise Exception("No candidates found in API response")
        
        else:
            # ENHANCED: HTTP ERROR handling with detailed analysis
            error_code = str(response.status_code)
            logging.error(f"‚ùå [{client_id}] HTTP ERROR: {response.status_code}")
            logging.error(f"üîç [{client_id}] Response details:")
            logging.error(f"   - Status code: {response.status_code}")
            logging.error(f"   - Response time: {response_time:.2f}s")
            logging.error(f"   - Content length: {len(response.text)}")
            logging.error(f"   - Content type: {response.headers.get('content-type', 'Unknown')}")
            logging.error(f"üîç [{client_id}] Response text (first 500 chars): {response.text[:500]}...")
            
            # ENHANCED: Special handling for different HTTP error codes
            if response.status_code == 503:
                logging.error(f"üö® [{client_id}] API OVERLOADED (503) - Service temporarily unavailable")
                logging.error(f"üîç [{client_id}] This indicates Google's servers are overloaded")
                logging.error(f"üîß [{client_id}] Marking API key for extended cooldown")
                update_api_key_health(api_key, success=False, error_code="503", response_time=response_time)
                
                # Log current API key ecosystem health
                ecosystem_health = get_enhanced_api_key_status()
                healthy_keys = ecosystem_health.get('healthy_keys', 0)
                logging.warning(f"üîë [{client_id}] API Key Ecosystem Status: {healthy_keys} healthy keys remaining")
                
                if healthy_keys <= 2:
                    logging.error(f"üö® [{client_id}] CRITICAL: Very few healthy API keys remaining!")
                
            elif response.status_code == 429:
                logging.error(f"üö® [{client_id}] RATE LIMITED (429) - Too many requests")
                logging.error(f"üîç [{client_id}] Rate limit headers: {dict(response.headers)}")
                update_api_key_health(api_key, success=False, error_code="429", response_time=response_time)
                
            elif response.status_code in [400, 401, 403]:
                logging.error(f"üö® [{client_id}] CLIENT ERROR ({response.status_code}) - Request or auth issue")
                
                if response.status_code == 400:
                    logging.error(f"üîç [{client_id}] Bad Request - Possible prompt issue")
                    logging.error(f"üîç [{client_id}] Prompt length: {len(enhanced_prompt)} chars")
                elif response.status_code == 401:
                    logging.error(f"üîç [{client_id}] Unauthorized - API key may be invalid")
                elif response.status_code == 403:
                    logging.error(f"üîç [{client_id}] Forbidden - API key may be disabled")
                
                update_api_key_health(api_key, success=False, error_code=error_code, response_time=response_time)
                
            elif response.status_code >= 500:
                logging.error(f"üö® [{client_id}] SERVER ERROR ({response.status_code}) - Google server issue")
                logging.error(f"üîç [{client_id}] This is typically temporary")
                update_api_key_health(api_key, success=False, error_code=error_code, response_time=response_time)
                
            else:
                logging.error(f"üö® [{client_id}] UNKNOWN HTTP ERROR ({response.status_code})")
                update_api_key_health(api_key, success=False, error_code=error_code, response_time=response_time)
            
            # ENHANCED: Log updated API key health after error
            updated_health = api_key_health.get(api_key, {})
            updated_success_rate = updated_health.get('success_rate', 1.0)
            updated_current_load = updated_health.get('current_load', 0)
            updated_failures = updated_health.get('consecutive_failures', 0)
            
            logging.error(f"üîë [{client_id}] UPDATED API KEY HEALTH AFTER ERROR:")
            logging.error(f"   - Key ID: {updated_health.get('key_id', 'unknown')}")
            logging.error(f"   - Consecutive Failures: {updated_failures}")
            logging.error(f"   - Success Rate: {updated_success_rate:.3f}")
            logging.error(f"   - Current Load: {updated_current_load}")
            logging.error(f"   - Error Response Time: {response_time:.2f}s")
            
            # Log ecosystem impact
            ecosystem_summary = get_api_key_status_summary()
            logging.error(f"üîë [{client_id}] API Key Ecosystem Impact: {ecosystem_summary}")
            
            raise Exception(f"HTTP {response.status_code}: {response.text}")
    
    except Exception as e:
        # ENHANCED: Comprehensive error handling with detailed context
        analysis_time = time.time() - start_time
        response_time_safe = time.time() - request_start_time if request_start_time else analysis_time
        
        logging.error(f"‚ùå [{client_id}] PEOPLE & OPS ANALYSIS FAILED")
        logging.error(f"üîç [{client_id}] Error details:")
        logging.error(f"   - Error type: {type(e).__name__}")
        logging.error(f"   - Error message: {str(e)}")
        logging.error(f"   - Analysis time: {analysis_time:.2f}s")
        logging.error(f"   - Request time: {response_time_safe:.2f}s")
        logging.error(f"   - Analysis type: {analysis_type}")
        logging.error(f"   - Client ID: {client_id}")
        
        # ENHANCED: Context logging for debugging
        logging.error(f"üîç [{client_id}] Error context:")
        logging.error(f"   - API key suffix: ...{api_key[-4:]}")
        logging.error(f"   - Temperature: {temperature}")
        logging.error(f"   - Max tokens: {max_tokens}")
        logging.error(f"   - REQUEST_TIMEOUT: {REQUEST_TIMEOUT}s")
        
        # If this exception wasn't already handled above, update API key health
        if api_key in api_key_health:
            current_failures = api_key_health[api_key].get('consecutive_failures', 0)
            
            # Only update if we haven't already updated for HTTP errors
            if "HTTP" not in str(e) and "API error" not in str(e):
                logging.warning(f"üîë [{client_id}] Updating API key health for unhandled exception")
                update_api_key_health(api_key, success=False, error_code="GENERAL_EXCEPTION", response_time=response_time_safe)
            else:
                logging.info(f"üîë [{client_id}] API key health already updated for this error type")
            
            # ENHANCED: Log comprehensive API key health summary on error
            final_health = api_key_health.get(api_key, {})
            final_success_rate = final_health.get('success_rate', 1.0)
            final_current_load = final_health.get('current_load', 0)
            final_failures = final_health.get('consecutive_failures', 0)
            
            logging.error(f"üîë [{client_id}] FINAL API KEY HEALTH AFTER ERROR:")
            logging.error(f"   - Key ID: {final_health.get('key_id', 'unknown')}")
            logging.error(f"   - Consecutive Failures: {final_failures}")
            logging.error(f"   - Success Rate: {final_success_rate:.3f}")
            logging.error(f"   - Current Load: {final_current_load}")
            logging.error(f"   - Key Status: {'FAILED' if final_failures >= 3 else 'DEGRADED' if final_failures > 0 else 'HEALTHY'}")
            
            # Log ecosystem health impact
            ecosystem_status = get_enhanced_api_key_status()
            logging.error(f"üîë [{client_id}] API ECOSYSTEM IMPACT:")
            logging.error(f"   - Healthy keys: {ecosystem_status.get('healthy_keys', 0)}/{ecosystem_status.get('total_keys', 0)}")
            logging.error(f"   - Failed keys: {ecosystem_status.get('failed_keys', 0)}")
            logging.error(f"   - Cooling down: {ecosystem_status.get('cooling_down', 0)}")
            logging.error(f"   - Total load: {ecosystem_status.get('total_load', 0)}")
        else:
            logging.error(f"‚ùå [{client_id}] API key not found in health tracking: ...{api_key[-4:]}")
        
        # ENHANCED: Full traceback logging for debugging
        import traceback
        logging.error(f"üîç [{client_id}] FULL ERROR TRACEBACK:")
        for line_num, line in enumerate(traceback.format_exc().split('\n'), 1):
            if line.strip():
                logging.error(f"   {line_num:02d}: {line}")
        
        # Log additional debugging context
        logging.error(f"üîç [{client_id}] DEBUGGING CONTEXT:")
        logging.error(f"   - Python version: {sys.version}")
        logging.error(f"   - Platform: {platform.system()}")
        logging.error(f"   - Memory usage: {sys.getsizeof(complete_raw_data) if complete_raw_data else 0} bytes")
        logging.error(f"   - Thread ID: {threading.current_thread().ident}")
        logging.error(f"   - Function start time: {datetime.fromtimestamp(start_time).isoformat()}")
        
        raise

def create_enhanced_people_ops_analysis_prompt(complete_raw_data: Dict, analysis_type: str, analysis_requirements: str) -> str:
    """Create 100/100 enhanced analysis prompt with complete Multi-Database Intelligence integration"""
    
    logging.info(f"üéØ Starting enhanced people & ops analysis prompt creation for {analysis_type}")
    
    user_profile = complete_raw_data.get("user_profile", {})
    responses = complete_raw_data.get("responses", [])
    multi_db_intelligence = complete_raw_data.get("multi_database_intelligence", {})
    behavioral_data = complete_raw_data.get("behavioral_analytics", {})
    
    logging.info(f"üìä Data summary: {len(responses)} responses, multi-db: {bool(multi_db_intelligence)}, behavioral: {bool(behavioral_data)}")
    
    # Extract and validate user profile data
    business_name = user_profile.get('business_name', 'Unknown Business')
    username = user_profile.get('username', 'Client')
    
    # Handle industry as both string and list
    industry_raw = user_profile.get('industry', 'Unknown Industry')
    if isinstance(industry_raw, list):
        industry = ", ".join(industry_raw) if industry_raw else 'Unknown Industry'
    else:
        industry = str(industry_raw) if industry_raw else 'Unknown Industry'
    
    team_size = user_profile.get('team_size', 'Unknown')
    biggest_challenge = user_profile.get('biggest_challenge', 'Unknown Challenge')
    business_description = user_profile.get('business_description', 'Not provided')
    location = user_profile.get('location', 'Unknown Location')
    
    logging.info(f"üë§ User profile: {username} at {business_name} ({industry}, {team_size} employees)")
    
    # Get current date and time for Gemini context
    current_datetime = datetime.now()
    current_date_str = current_datetime.strftime('%A, %B %d, %Y')
    current_time_str = current_datetime.strftime('%I:%M %p %Z')

    # üî• DYNAMIC MULTI-DATABASE INTELLIGENCE EXTRACTION WITH LOGGING
    
    # Extract Component Intelligence
    component_data = multi_db_intelligence.get('component_intelligence', {})
    component_responses = component_data.get('responses', {})
    logging.info(f"üîß Component data extracted: {len(component_responses) if isinstance(component_responses, dict) else type(component_responses)} items")
    
    # Extract Profile Intelligence  
    profile_data = multi_db_intelligence.get('profile_intelligence', {})
    profile_responses = profile_data.get('responses', {})
    logging.info(f"üîß Profile data extracted: {len(profile_responses) if isinstance(profile_responses, dict) else type(profile_responses)} items")
    
    # Extract Dream Intelligence
    dream_data = multi_db_intelligence.get('dream_intelligence', {})
    dream_responses = dream_data.get('responses', {})
    logging.info(f"üîß Dream data extracted: {len(dream_responses) if isinstance(dream_responses, dict) else type(dream_responses)} items")
    
    # Extract Growth Intelligence
    growth_data = multi_db_intelligence.get('growth_intelligence', {})
    growth_responses = growth_data.get('responses', {})
    logging.info(f"üîß Growth data extracted: {len(growth_responses) if isinstance(growth_responses, dict) else type(growth_responses)} items")
    
    # Extract Analyst Intelligence
    analyst_data = multi_db_intelligence.get('analyst_intelligence', {})
    analyst_responses = analyst_data.get('responses', {})
    logging.info(f"üîß Analyst data extracted: {len(analyst_responses) if isinstance(analyst_responses, dict) else type(analyst_responses)} items")
    
    # Extract Complete Q&A Data
    complete_qa_data = multi_db_intelligence.get('complete_qa_data', {})
    qa_engine_data = complete_qa_data.get('complete_qa_data', {})
    qa_pairs_count = complete_qa_data.get('token_tracking', {}).get('qa_pairs_count', 0)
    logging.info(f"üîß Q&A data extracted: {qa_pairs_count} total pairs from {len(qa_engine_data) if isinstance(qa_engine_data, dict) else type(qa_engine_data)} engines")

    user_context = f"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üè¢ WORLD-CLASS ORGANIZATIONAL INTELLIGENCE ANALYSIS FRAMEWORK üè¢
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìÖ ANALYSIS CONTEXT:
- Analysis Date: {current_date_str}
- Analysis Time: {current_time_str}
- Report Generation: Evidence-based organizational intelligence with validated methodologies

üë§ CLIENT PROFILE:
- Full Name: {username}
- Business Name: {business_name}
- Industry: {industry}
- Team Size: {team_size} employees
- Location: {location}
- Primary Challenge: {biggest_challenge}
- Business Description: {business_description}

üéØ ANALYSIS OBJECTIVE:
Generate a comprehensive organizational analysis for {username}, founder/leader of {business_name}, 
integrating multi-database intelligence across validated business frameworks to address {biggest_challenge} 
with evidence-based recommendations and quantified confidence levels.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üß† COMPREHENSIVE MULTI-DATABASE INTELLIGENCE INTEGRATION üß†
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìä COMPONENT ENGINE INTELLIGENCE:
Business Phase: {component_data.get('business_phase', 'Not Available')} - {component_data.get('phase_label', 'Not Available')}
Assessment Type: {component_data.get('assessment_type', 'Not Available')}
Data Available: {'Yes' if component_data.get('data_available', False) else 'No'}
Response Count: {len(component_responses) if isinstance(component_responses, dict) else 0} component responses

COMPONENT RESPONSES FOR ORGANIZATIONAL ANALYSIS:
{format_component_responses_for_analysis(component_responses)}

üß¨ BUSINESS DNA PROFILE INTELLIGENCE:
Assessment Type: {profile_data.get('assessment_type', 'Not Available')}
Created: {profile_data.get('created_at', 'Not Available')}
Data Available: {'Yes' if profile_data.get('data_available', False) else 'No'}
Response Count: {len(profile_responses) if isinstance(profile_responses, dict) else 0} personality responses

PERSONALITY PROFILE FOR LEADERSHIP ANALYSIS:
{format_profile_responses_for_analysis(profile_responses)}

üí´ DREAM & VISION INTELLIGENCE:
Assessment Type: {dream_data.get('assessment_type', 'Not Available')}
Created: {dream_data.get('created_at', 'Not Available')}
Data Available: {'Yes' if dream_data.get('data_available', False) else 'No'}
Response Count: {len(dream_responses) if isinstance(dream_responses, dict) else 0} vision responses

VISION & ASPIRATION DATA FOR STRATEGIC ALIGNMENT:
{format_dream_responses_for_analysis(dream_responses)}

üöÄ GROWTH ENGINE INTELLIGENCE:
Assessment Type: {growth_data.get('assessment_type', 'Not Available')}
Created: {growth_data.get('created_at', 'Not Available')}
Data Available: {'Yes' if growth_data.get('data_available', False) else 'No'}
Response Count: {len(growth_responses) if isinstance(growth_responses, dict) else 0} growth responses

GROWTH PATTERNS FOR SCALING STRATEGY:
{format_growth_responses_for_analysis(growth_responses)}

üß† BEHAVIORAL INTELLIGENCE (ANALYST ENGINE):
Data Available: {'Yes' if analyst_data.get('data_available', False) else 'No'}
Response Count: {len(analyst_responses) if isinstance(analyst_responses, dict) else 0} behavioral responses

BEHAVIORAL PATTERNS FOR IMPLEMENTATION:
{format_analyst_responses_for_analysis(analyst_responses)}

üìä CROSS-ENGINE Q&A INTELLIGENCE:
Total Q&A Pairs: {qa_pairs_count}
Engines with Data: {list(qa_engine_data.keys()) if isinstance(qa_engine_data, dict) and qa_engine_data else 'None'}
Token Tracking: {complete_qa_data.get('token_tracking', {})}

CROSS-ENGINE RESPONSE PATTERNS:
{format_cross_engine_qa_for_analysis(qa_engine_data)}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìù PEOPLE & OPERATIONS ASSESSMENT RESPONSES ANALYSIS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

{format_people_ops_assessment_responses(responses)}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üß† BEHAVIORAL ANALYTICS INTEGRATION
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

{format_people_ops_behavioral_data(behavioral_data)}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üéØ MANDATORY MULTI-DATABASE CORRELATION ANALYSIS üéØ
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CRITICAL REQUIREMENTS: You must analyze and integrate ALL the above multi-database intelligence:

1. **Component-People Correlation**: How does their business phase and operational maturity affect people strategy?

2. **Personality-Leadership Integration**: How do their personality traits from the Business DNA profile inform leadership development?

3. **Vision-Reality Gap Analysis**: How do their dreams/aspirations align with current organizational capabilities?

4. **Growth-People Constraint Analysis**: How do growth engine insights reveal people-related bottlenecks?

5. **Behavioral-Implementation Alignment**: How do behavioral patterns affect change management and implementation?

6. **Cross-Engine Pattern Recognition**: What consistent themes emerge across all assessment engines?

MANDATORY DELIVERABLES:
- Specific correlations between at least 3 different engine data sources
- Integration of personality traits with operational preferences  
- Alignment of vision goals with practical implementation steps
- Cross-validation of insights using multiple data sources
- Identification of contradictions and resolution strategies
- Quantified confidence levels for all major recommendations

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üî¨ METHODOLOGICAL REQUIREMENTS FOR 100/100 ANALYSIS QUALITY üî¨
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

**EVIDENCE-BASED INTEGRATION REQUIREMENTS:**
- Every recommendation must reference specific data from the multi-database intelligence above
- Cross-correlate findings across Component, Profile, Dream, Growth, and Analyst engines
- Use actual Q&A response patterns to validate insights
- Identify synergies and contradictions between different data sources
- Provide implementation strategies that account for all personality and behavioral factors

**MANDATORY CROSS-REFERENCING:**
- Leadership recommendations must integrate personality profile data
- Team architecture must consider business phase and growth constraints
- Culture strategy must align with vision aspirations and behavioral patterns
- Operational changes must factor in personality traits and risk tolerance
- Implementation timeline must match behavioral decision-making patterns

This comprehensive framework ensures world-class organizational analysis quality through rigorous methodology, 
evidence-based recommendations, and complete integration of all available multi-database intelligence 
while maintaining practical implementation focus and measurable outcomes.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""
    
    # Combine all sections
    final_prompt = user_context
    
    # Log final prompt statistics
    prompt_length = len(final_prompt)
    prompt_word_count = len(final_prompt.split())
    
    logging.info(f"‚úÖ Enhanced people & ops analysis prompt completed with dynamic multi-DB integration")
    logging.info(f"üìä Final prompt statistics:")
    logging.info(f"   - Total characters: {prompt_length:,}")
    logging.info(f"   - Total words: {prompt_word_count:,}")
    logging.info(f"   - User: {username} at {business_name}")
    logging.info(f"   - Multi-DB engines integrated: {len([d for d in [component_data, profile_data, dream_data, growth_data, analyst_data] if d.get('data_available')])}")
    
    return final_prompt

# üî• FIXED MULTI-DATABASE FORMATTING FUNCTIONS WITH COMPREHENSIVE ERROR HANDLING

import json
import logging
from typing import Dict, Any, Union
import traceback
import time

def format_component_responses_for_analysis(component_responses: Union[Dict, str, None]) -> str:
    """FIXED: Dynamically format component responses for people ops analysis with robust error handling"""
    
    function_start_time = time.time()
    logging.info(f"üîß COMPONENT FORMATTER: Starting format_component_responses_for_analysis")
    logging.info(f"üìä Input type: {type(component_responses)}")
    logging.info(f"üìä Input value preview: {str(component_responses)[:100] if component_responses else 'None'}...")
    
    try:
        # CRITICAL FIX 1: Handle None/empty input
        if component_responses is None:
            logging.info(f"‚ÑπÔ∏è COMPONENT FORMATTER: Input is None")
            return "No component assessment data available for organizational foundation analysis."
        
        # CRITICAL FIX 2: Handle string input (JSON parsing)
        if isinstance(component_responses, str):
            logging.warning(f"‚ö†Ô∏è COMPONENT FORMATTER: Input is string, attempting JSON parse")
            logging.warning(f"üîç String length: {len(component_responses)} characters")
            logging.warning(f"üîç String preview: {component_responses[:200]}...")
            
            if not component_responses.strip():
                logging.warning(f"‚ö†Ô∏è COMPONENT FORMATTER: Empty string input")
                return "Component assessment data is empty."
            
            try:
                component_responses = json.loads(component_responses)
                logging.info(f"‚úÖ COMPONENT FORMATTER: JSON parsing successful")
                logging.info(f"üìä Parsed type: {type(component_responses)}")
            except json.JSONDecodeError as json_error:
                logging.error(f"‚ùå COMPONENT FORMATTER: JSON parsing failed: {json_error}")
                logging.error(f"üîç JSON error position: {json_error.pos if hasattr(json_error, 'pos') else 'Unknown'}")
                return f"Component assessment data (invalid JSON): {component_responses[:500]}..."
            except Exception as parse_error:
                logging.error(f"‚ùå COMPONENT FORMATTER: Unexpected parsing error: {parse_error}")
                return f"Component assessment data (parse error): {str(component_responses)[:500]}..."
        
        # CRITICAL FIX 3: Validate parsed data is dictionary
        if not isinstance(component_responses, dict):
            logging.error(f"‚ùå COMPONENT FORMATTER: Data is not a dictionary after parsing")
            logging.error(f"üîç Final type: {type(component_responses)}")
            logging.error(f"üîç Final value: {component_responses}")
            return f"Component assessment data (wrong type {type(component_responses).__name__}): {str(component_responses)[:500]}..."
        
        # CRITICAL FIX 4: Handle empty dictionary
        if not component_responses:
            logging.info(f"‚ÑπÔ∏è COMPONENT FORMATTER: Empty dictionary input")
            return "No component assessment data available for organizational foundation analysis."
        
        logging.info(f"‚úÖ COMPONENT FORMATTER: Input validation passed")
        logging.info(f"üìä Dictionary keys: {list(component_responses.keys())}")
        logging.info(f"üìä Dictionary size: {len(component_responses)} items")
        
        # Format responses with detailed error handling
        formatted_responses = []
        successful_formats = 0
        failed_formats = 0
        
        for question_id, response_data in component_responses.items():
            try:
                logging.debug(f"üîç COMPONENT FORMATTER: Processing question_id: {question_id}")
                logging.debug(f"üîç Response data type: {type(response_data)}")
                
                # Safe data extraction
                if isinstance(response_data, dict):
                    answer = response_data.get('answer', 'No answer')
                    section = response_data.get('section', 'Unknown Section')
                    weight = response_data.get('weight', 'Unknown')
                    metadata = response_data.get('metadata', {})
                elif isinstance(response_data, str):
                    answer = response_data
                    section = 'Unknown Section'
                    weight = 'Unknown'
                    metadata = {}
                else:
                    answer = str(response_data)
                    section = 'Unknown Section'
                    weight = 'Unknown'
                    metadata = {}
                
                formatted_response = f"""
Component Question ID: {question_id}
Section: {section} (Weight: {weight})
Response: {answer}
Metadata: {metadata}
---"""
                
                formatted_responses.append(formatted_response)
                successful_formats += 1
                logging.debug(f"‚úÖ COMPONENT FORMATTER: Successfully formatted question {question_id}")
                
            except Exception as format_error:
                failed_formats += 1
                logging.error(f"‚ùå COMPONENT FORMATTER: Error formatting question {question_id}: {format_error}")
                logging.error(f"üîç Question data: {response_data}")
                
                # Add fallback format
                fallback_format = f"""
Component Question ID: {question_id}
Section: Error Processing
Response: Format error - {str(format_error)}
Metadata: {{'error': True, 'original_data': str(response_data)}}
---"""
                formatted_responses.append(fallback_format)
        
        function_time = time.time() - function_start_time
        logging.info(f"üéâ COMPONENT FORMATTER: Completed successfully")
        logging.info(f"üìä Processing results:")
        logging.info(f"   - Total items: {len(component_responses)}")
        logging.info(f"   - Successfully formatted: {successful_formats}")
        logging.info(f"   - Failed to format: {failed_formats}")
        logging.info(f"   - Processing time: {function_time:.3f}s")
        output_text = '\n'.join(formatted_responses)
        logging.info(f"   - Output length: {len(output_text)} characters")
        
        return '\n'.join(formatted_responses)
        
    except Exception as e:
        function_time = time.time() - function_start_time
        logging.error(f"üí• COMPONENT FORMATTER: Critical error after {function_time:.3f}s")
        logging.error(f"‚ùå Error type: {type(e).__name__}")
        logging.error(f"‚ùå Error message: {str(e)}")
        logging.error(f"üîç Input type: {type(component_responses)}")
        logging.error(f"üîç Input preview: {str(component_responses)[:100] if component_responses else 'None'}")
        
        # Log full traceback
        logging.error(f"üîç COMPONENT FORMATTER: Full traceback:")
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                logging.error(f"   {line}")
        
        return f"ERROR: Component assessment formatting failed - {str(e)}"

def format_profile_responses_for_analysis(profile_responses: Union[Dict, str, None]) -> str:
    """FIXED: Dynamically format personality profile responses with robust error handling"""
    
    function_start_time = time.time()
    logging.info(f"üîß PROFILE FORMATTER: Starting format_profile_responses_for_analysis")
    logging.info(f"üìä Input type: {type(profile_responses)}")
    logging.info(f"üìä Input value preview: {str(profile_responses)[:100] if profile_responses else 'None'}...")
    
    try:
        # Handle None/empty input
        if profile_responses is None:
            logging.info(f"‚ÑπÔ∏è PROFILE FORMATTER: Input is None")
            return "No personality profile data available for leadership style analysis."
        
        # Handle string input (JSON parsing)
        if isinstance(profile_responses, str):
            logging.warning(f"‚ö†Ô∏è PROFILE FORMATTER: Input is string, attempting JSON parse")
            logging.warning(f"üîç String length: {len(profile_responses)} characters")
            
            if not profile_responses.strip():
                logging.warning(f"‚ö†Ô∏è PROFILE FORMATTER: Empty string input")
                return "Personality profile data is empty."
            
            try:
                profile_responses = json.loads(profile_responses)
                logging.info(f"‚úÖ PROFILE FORMATTER: JSON parsing successful")
            except json.JSONDecodeError as json_error:
                logging.error(f"‚ùå PROFILE FORMATTER: JSON parsing failed: {json_error}")
                return f"Personality profile data (invalid JSON): {profile_responses[:500]}..."
            except Exception as parse_error:
                logging.error(f"‚ùå PROFILE FORMATTER: Unexpected parsing error: {parse_error}")
                return f"Personality profile data (parse error): {str(profile_responses)[:500]}..."
        
        # Validate parsed data
        if not isinstance(profile_responses, dict):
            logging.error(f"‚ùå PROFILE FORMATTER: Data is not a dictionary after parsing")
            return f"Personality profile data (wrong type {type(profile_responses).__name__}): {str(profile_responses)[:500]}..."
        
        if not profile_responses:
            logging.info(f"‚ÑπÔ∏è PROFILE FORMATTER: Empty dictionary input")
            return "No personality profile data available for leadership style analysis."
        
        logging.info(f"‚úÖ PROFILE FORMATTER: Input validation passed")
        logging.info(f"üìä Dictionary keys: {list(profile_responses.keys())}")
        
        # Format responses
        formatted_responses = []
        successful_formats = 0
        failed_formats = 0
        
        for question_id, response_data in profile_responses.items():
            try:
                logging.debug(f"üîç PROFILE FORMATTER: Processing question_id: {question_id}")
                
                # Safe data extraction
                if isinstance(response_data, dict):
                    answer = response_data.get('answer', 'No answer')
                    section = response_data.get('section', 'Unknown Section')
                    weight = response_data.get('weight', 'Unknown')
                    question_text = response_data.get('question_text', 'No question text')
                else:
                    answer = str(response_data)
                    section = 'Unknown Section'
                    weight = 'Unknown'
                    question_text = 'No question text'
                
                formatted_response = f"""
Profile Question: {question_text}
Question ID: {question_id}
Section: {section} (Weight: {weight})
Response: {answer}
---"""
                
                formatted_responses.append(formatted_response)
                successful_formats += 1
                
            except Exception as format_error:
                failed_formats += 1
                logging.error(f"‚ùå PROFILE FORMATTER: Error formatting question {question_id}: {format_error}")
                
                fallback_format = f"""
Profile Question: Error Processing
Question ID: {question_id}
Section: Error Processing
Response: Format error - {str(format_error)}
---"""
                formatted_responses.append(fallback_format)
        
        function_time = time.time() - function_start_time
        logging.info(f"üéâ PROFILE FORMATTER: Completed successfully in {function_time:.3f}s")
        logging.info(f"üìä Processed {successful_formats}/{len(profile_responses)} items successfully")
        
        return '\n'.join(formatted_responses)
        
    except Exception as e:
        function_time = time.time() - function_start_time
        logging.error(f"üí• PROFILE FORMATTER: Critical error after {function_time:.3f}s: {str(e)}")
        return f"ERROR: Personality profile formatting failed - {str(e)}"

def format_dream_responses_for_analysis(dream_responses: Union[Dict, str, None]) -> str:
    """FIXED: Dynamically format dream/vision responses with robust error handling"""
    
    function_start_time = time.time()
    logging.info(f"üîß DREAM FORMATTER: Starting format_dream_responses_for_analysis")
    logging.info(f"üìä Input type: {type(dream_responses)}")
    
    try:
        # Handle None/empty input
        if dream_responses is None:
            logging.info(f"‚ÑπÔ∏è DREAM FORMATTER: Input is None")
            return "No vision/aspiration data available for strategic alignment analysis."
        
        # Handle string input
        if isinstance(dream_responses, str):
            logging.warning(f"‚ö†Ô∏è DREAM FORMATTER: Input is string, attempting JSON parse")
            
            if not dream_responses.strip():
                return "Vision/aspiration data is empty."
            
            try:
                dream_responses = json.loads(dream_responses)
                logging.info(f"‚úÖ DREAM FORMATTER: JSON parsing successful")
            except json.JSONDecodeError as json_error:
                logging.error(f"‚ùå DREAM FORMATTER: JSON parsing failed: {json_error}")
                return f"Vision/aspiration data (invalid JSON): {dream_responses[:500]}..."
        
        # Validate data
        if not isinstance(dream_responses, dict) or not dream_responses:
            logging.error(f"‚ùå DREAM FORMATTER: Invalid data type or empty")
            return "No vision/aspiration data available for strategic alignment analysis."
        
        logging.info(f"‚úÖ DREAM FORMATTER: Processing {len(dream_responses)} items")
        
        formatted_responses = []
        for question_id, response_data in dream_responses.items():
            try:
                if isinstance(response_data, dict):
                    answer = response_data.get('answer', 'No answer')
                    response_text = response_data.get('response_text', '')
                    section = response_data.get('section', 'Unknown Section')
                    question_text = response_data.get('question_text', 'No question text')
                else:
                    answer = str(response_data)
                    response_text = ''
                    section = 'Unknown Section'
                    question_text = 'No question text'
                
                formatted_response = f"""
Vision Question: {question_text}
Question ID: {question_id}
Section: {section}
Selected Answer: {answer}
Detailed Response: {response_text}
---"""
                
                formatted_responses.append(formatted_response)
                
            except Exception as format_error:
                logging.error(f"‚ùå DREAM FORMATTER: Error formatting {question_id}: {format_error}")
                formatted_responses.append(f"Vision Question ID: {question_id} - Format Error: {str(format_error)}\n---")
        
        function_time = time.time() - function_start_time
        logging.info(f"üéâ DREAM FORMATTER: Completed in {function_time:.3f}s")
        
        return '\n'.join(formatted_responses)
        
    except Exception as e:
        function_time = time.time() - function_start_time
        logging.error(f"üí• DREAM FORMATTER: Critical error after {function_time:.3f}s: {str(e)}")
        return f"ERROR: Dream/vision formatting failed - {str(e)}"

def format_growth_responses_for_analysis(growth_responses: Union[Dict, str, None]) -> str:
    """FIXED: Dynamically format growth engine responses with robust error handling"""
    
    function_start_time = time.time()
    logging.info(f"üîß GROWTH FORMATTER: Starting format_growth_responses_for_analysis")
    logging.info(f"üìä Input type: {type(growth_responses)}")
    
    try:
        if growth_responses is None:
            logging.info(f"‚ÑπÔ∏è GROWTH FORMATTER: Input is None")
            return "No growth constraint data available for scaling strategy analysis."
        
        if isinstance(growth_responses, str):
            logging.warning(f"‚ö†Ô∏è GROWTH FORMATTER: Input is string, attempting JSON parse")
            
            if not growth_responses.strip():
                return "Growth constraint data is empty."
            
            try:
                growth_responses = json.loads(growth_responses)
                logging.info(f"‚úÖ GROWTH FORMATTER: JSON parsing successful")
            except json.JSONDecodeError as json_error:
                logging.error(f"‚ùå GROWTH FORMATTER: JSON parsing failed: {json_error}")
                return f"Growth constraint data (invalid JSON): {growth_responses[:500]}..."
        
        if not isinstance(growth_responses, dict) or not growth_responses:
            logging.error(f"‚ùå GROWTH FORMATTER: Invalid data type or empty")
            return "No growth constraint data available for scaling strategy analysis."
        
        logging.info(f"‚úÖ GROWTH FORMATTER: Processing {len(growth_responses)} items")
        
        formatted_responses = []
        for question_id, response_data in growth_responses.items():
            try:
                if isinstance(response_data, dict):
                    answer = response_data.get('answer', 'No answer')
                    response_text = response_data.get('response_text', '')
                    section = response_data.get('section', 'Unknown Section')
                    question_text = response_data.get('question_text', 'No question text')
                else:
                    answer = str(response_data)
                    response_text = ''
                    section = 'Unknown Section'
                    question_text = 'No question text'
                
                formatted_response = f"""
Growth Question: {question_text}
Question ID: {question_id}
Section: {section}
Selected Answer: {answer}
Detailed Response: {response_text}
---"""
                
                formatted_responses.append(formatted_response)
                
            except Exception as format_error:
                logging.error(f"‚ùå GROWTH FORMATTER: Error formatting {question_id}: {format_error}")
                formatted_responses.append(f"Growth Question ID: {question_id} - Format Error: {str(format_error)}\n---")
        
        function_time = time.time() - function_start_time
        logging.info(f"üéâ GROWTH FORMATTER: Completed in {function_time:.3f}s")
        
        return '\n'.join(formatted_responses)
        
    except Exception as e:
        function_time = time.time() - function_start_time
        logging.error(f"üí• GROWTH FORMATTER: Critical error after {function_time:.3f}s: {str(e)}")
        return f"ERROR: Growth engine formatting failed - {str(e)}"

def format_analyst_responses_for_analysis(analyst_responses: Union[Dict, str, None]) -> str:
    """FIXED: Dynamically format behavioral analyst responses with robust error handling"""
    
    function_start_time = time.time()
    logging.info(f"üîß ANALYST FORMATTER: Starting format_analyst_responses_for_analysis")
    logging.info(f"üìä Input type: {type(analyst_responses)}")
    
    try:
        if analyst_responses is None:
            logging.info(f"‚ÑπÔ∏è ANALYST FORMATTER: Input is None")
            return "No behavioral intelligence data available for implementation analysis."
        
        if isinstance(analyst_responses, str):
            logging.warning(f"‚ö†Ô∏è ANALYST FORMATTER: Input is string, attempting JSON parse")
            
            if not analyst_responses.strip():
                return "Behavioral intelligence data is empty."
            
            try:
                analyst_responses = json.loads(analyst_responses)
                logging.info(f"‚úÖ ANALYST FORMATTER: JSON parsing successful")
            except json.JSONDecodeError as json_error:
                logging.error(f"‚ùå ANALYST FORMATTER: JSON parsing failed: {json_error}")
                return f"Behavioral intelligence data (invalid JSON): {analyst_responses[:500]}..."
        
        if not isinstance(analyst_responses, dict) or not analyst_responses:
            logging.error(f"‚ùå ANALYST FORMATTER: Invalid data type or empty")
            return "No behavioral intelligence data available for implementation analysis."
        
        logging.info(f"‚úÖ ANALYST FORMATTER: Processing {len(analyst_responses)} items")
        
        formatted_responses = []
        for question_id, response_data in analyst_responses.items():
            try:
                if isinstance(response_data, dict):
                    answer = response_data.get('answer', 'No answer')
                    response_text = response_data.get('response_text', '')
                    section = response_data.get('section', 'Unknown Section')
                    metadata = response_data.get('metadata', {})
                else:
                    answer = str(response_data)
                    response_text = ''
                    section = 'Unknown Section'
                    metadata = {}
                
                formatted_response = f"""
Behavioral Question ID: {question_id}
Section: {section}
Response: {answer}
Additional Text: {response_text}
Analysis Metadata: {metadata}
---"""
                
                formatted_responses.append(formatted_response)
                
            except Exception as format_error:
                logging.error(f"‚ùå ANALYST FORMATTER: Error formatting {question_id}: {format_error}")
                formatted_responses.append(f"Behavioral Question ID: {question_id} - Format Error: {str(format_error)}\n---")
        
        function_time = time.time() - function_start_time
        logging.info(f"üéâ ANALYST FORMATTER: Completed in {function_time:.3f}s")
        
        return '\n'.join(formatted_responses)
        
    except Exception as e:
        function_time = time.time() - function_start_time
        logging.error(f"üí• ANALYST FORMATTER: Critical error after {function_time:.3f}s: {str(e)}")
        return f"ERROR: Behavioral analyst formatting failed - {str(e)}"

def format_cross_engine_qa_for_analysis(qa_engine_data: Union[Dict, str, None]) -> str:
    """FIXED: Dynamically format cross-engine Q&A patterns with robust error handling"""
    
    function_start_time = time.time()
    logging.info(f"üîß QA FORMATTER: Starting format_cross_engine_qa_for_analysis")
    logging.info(f"üìä Input type: {type(qa_engine_data)}")
    
    try:
        if qa_engine_data is None:
            logging.info(f"‚ÑπÔ∏è QA FORMATTER: Input is None")
            return "No cross-engine Q&A data available for pattern analysis."
        
        if isinstance(qa_engine_data, str):
            logging.warning(f"‚ö†Ô∏è QA FORMATTER: Input is string, attempting JSON parse")
            
            if not qa_engine_data.strip():
                return "Cross-engine Q&A data is empty."
            
            try:
                qa_engine_data = json.loads(qa_engine_data)
                logging.info(f"‚úÖ QA FORMATTER: JSON parsing successful")
            except json.JSONDecodeError as json_error:
                logging.error(f"‚ùå QA FORMATTER: JSON parsing failed: {json_error}")
                return f"Cross-engine Q&A data (invalid JSON): {qa_engine_data[:500]}..."
        
        if not isinstance(qa_engine_data, dict) or not qa_engine_data:
            logging.error(f"‚ùå QA FORMATTER: Invalid data type or empty")
            return "No cross-engine Q&A data available for pattern analysis."
        
        logging.info(f"‚úÖ QA FORMATTER: Processing {len(qa_engine_data)} engines")
        
        formatted_patterns = []
        engines_processed = 0
        
        for engine_name, qa_pairs in qa_engine_data.items():
            try:
                if not qa_pairs:
                    logging.debug(f"‚ö†Ô∏è QA FORMATTER: Engine {engine_name} has no Q&A pairs")
                    continue
                
                logging.debug(f"üîç QA FORMATTER: Processing engine {engine_name} with {len(qa_pairs)} Q&A pairs")
                
                formatted_patterns.append(f"""
{engine_name.upper()} ENGINE Q&A PATTERNS:
Total Q&A Pairs: {len(qa_pairs)}

Sample Questions & Responses:""")
                
                # Show first 3 Q&A pairs from each engine
                pairs_shown = 0
                for i, qa_pair in enumerate(qa_pairs[:3]):
                    try:
                        question = qa_pair.get('question', 'No question')
                        response = qa_pair.get('response', 'No response')
                        
                        formatted_patterns.append(f"""
Q{i+1}: {question}
A{i+1}: {response}
""")
                        pairs_shown += 1
                        
                    except Exception as pair_error:
                        logging.error(f"‚ùå QA FORMATTER: Error formatting Q&A pair {i}: {pair_error}")
                        formatted_patterns.append(f"Q{i+1}: Error formatting Q&A pair - {str(pair_error)}\n")
                
                if len(qa_pairs) > 3:
                    formatted_patterns.append(f"... and {len(qa_pairs) - 3} more Q&A pairs from {engine_name}")
                
                formatted_patterns.append("---")
                engines_processed += 1
                
            except Exception as engine_error:
                logging.error(f"‚ùå QA FORMATTER: Error processing engine {engine_name}: {engine_error}")
                formatted_patterns.append(f"Engine {engine_name}: Format Error - {str(engine_error)}\n---")
        
        function_time = time.time() - function_start_time
        logging.info(f"üéâ QA FORMATTER: Completed in {function_time:.3f}s")
        logging.info(f"üìä Processed {engines_processed}/{len(qa_engine_data)} engines successfully")
        
        return '\n'.join(formatted_patterns)
        
    except Exception as e:
        function_time = time.time() - function_start_time
        logging.error(f"üí• QA FORMATTER: Critical error after {function_time:.3f}s: {str(e)}")
        return f"ERROR: Cross-engine Q&A formatting failed - {str(e)}"

def format_multi_database_intelligence(multi_db_intelligence: Dict) -> str:
    """Format multi-database intelligence for people & operations analysis"""
    if not multi_db_intelligence:
        return "Multi-Database Intelligence: Not available - using people & ops responses only"
    
    formatted = []
    
    # Component Intelligence
    component_data = multi_db_intelligence.get('component_intelligence', {})
    if component_data:
        phase = component_data.get('business_phase', 'Unknown')
        phase_label = component_data.get('phase_label', 'Unknown')
        responses_count = len(component_data.get('responses', {})) if isinstance(component_data.get('responses', {}), dict) else 0
        formatted.append(f"üìä Component Intelligence: Business Phase {phase} ({phase_label}) - {responses_count} component responses")
    
    # Business DNA Profile
    profile_data = multi_db_intelligence.get('profile_intelligence', {})
    if profile_data:
        response_count = len(profile_data.get('responses', {})) if isinstance(profile_data.get('responses', {}), dict) else 0
        formatted.append(f"üß¨ Business DNA Profile: {response_count} personality responses available for leadership customization")
    
    # Dream Analysis
    dream_data = multi_db_intelligence.get('dream_intelligence', {})
    if dream_data:
        dream_count = len(dream_data.get('responses', {})) if isinstance(dream_data.get('responses', {}), dict) else 0
        formatted.append(f"üí´ Dream Analysis: {dream_count} aspiration responses for organizational alignment")
    
    # Growth Intelligence
    growth_data = multi_db_intelligence.get('growth_intelligence', {})
    if growth_data:
        growth_count = len(growth_data.get('responses', {})) if isinstance(growth_data.get('responses', {}), dict) else 0
        formatted.append(f"üöÄ Growth Analysis: {growth_count} growth responses for scaling alignment")
    
    # Behavioral Intelligence
    analyst_data = multi_db_intelligence.get('analyst_intelligence', {})
    if analyst_data:
        behavioral_count = len(analyst_data.get('responses', {})) if isinstance(analyst_data.get('responses', {}), dict) else 0
        formatted.append(f"üß† Behavioral Intelligence: {behavioral_count} behavioral responses for implementation customization")
    
    if not formatted:
        return "Multi-Database Intelligence: Extraction in progress - people & ops analysis will use available data sources"
    
    return "\n".join(formatted)

def format_people_ops_behavioral_data(behavioral_data: Dict) -> str:
    """Format behavioral data for people & operations analysis"""
    if not behavioral_data:
        return "No behavioral data available for people & ops analysis"
    
    formatted = []
    
    # People & ops-specific behavioral analysis
    if 'leadership_decision_patterns' in behavioral_data:
        patterns = behavioral_data['leadership_decision_patterns']
        formatted.append(f"üéØ Leadership Decision Patterns: {patterns.get('pattern_type', 'Unknown')} leadership style")
    
    # Mouse behavior analysis for people & ops
    mouse_data = behavioral_data.get('mouse_behavior', {})
    if mouse_data:
        total_movements = mouse_data.get('total_movements', 0)
        avg_speed = mouse_data.get('average_speed', 0)
        formatted.append(f"üñ±Ô∏è Organizational Engagement: {total_movements} interactions, {avg_speed:.1f} avg speed - indicates {_analyze_people_ops_engagement_level(total_movements, avg_speed)}")
    
    # Keyboard behavior analysis for people & ops
    keyboard_data = behavioral_data.get('keyboard_behavior', {})
    if keyboard_data:
        total_keystrokes = keyboard_data.get('total_keystrokes', 0)
        backspace_count = keyboard_data.get('backspace_count', 0)
        revision_ratio = (backspace_count / max(total_keystrokes, 1)) * 100
        formatted.append(f"‚å®Ô∏è Leadership Thoughtfulness: {revision_ratio:.1f}% revision rate - indicates {_analyze_people_ops_thoughtfulness(revision_ratio)}")
    
    return "\n".join(formatted) if formatted else "Behavioral analysis available for organizational implementation customization"

def _analyze_people_ops_engagement_level(movements: int, speed: float) -> str:
    """Analyze engagement level for people & ops context"""
    if movements > 500 and speed > 10:
        return "high engagement with organizational opportunities"
    elif movements > 200:
        return "moderate engagement with strategic people thinking"
    else:
        return "focused, deliberate organizational consideration"

def _analyze_people_ops_thoughtfulness(revision_ratio: float) -> str:
    """Analyze thoughtfulness for people & ops implementation"""
    if revision_ratio > 15:
        return "highly considered organizational responses - detailed implementation recommended"
    elif revision_ratio > 8:
        return "thoughtful people & ops analysis - systematic implementation approach"
    else:
        return "decisive organizational thinking - rapid implementation capability"

def format_people_ops_assessment_responses(responses):
    """Format people & operations assessment responses for analysis"""
    if not responses:
        return "No people & operations assessment responses available"
    
    formatted = []
    formatted.append("=== ULTRA-DEEP PEOPLE & OPERATIONS RESPONSE ANALYSIS ===")
    formatted.append("PRIORITY: Analyze what the client actually said/selected in each people & ops response\n")
    
    for response in responses:
        question_id = response.get('question_id', 'Unknown')
        question_text = response.get('question_text', 'Unknown question')
        response_data = response.get('response_data', {})
        
        formatted.append(f"\n### PEOPLE & OPERATIONS QUESTION {question_id} ###")
        formatted.append(f"QUESTION: {question_text}")
        
        # Detailed response analysis for people & ops
        if isinstance(response_data, dict):
            if 'selected_option' in response_data:
                selected = response_data['selected_option']
                formatted.append(f"RESPONSE TYPE: Organizational Selection")
                formatted.append(f"CLIENT SELECTED: \"{selected}\"")
                formatted.append(f"PEOPLE & OPS ANALYSIS INSTRUCTION: Analyze what this organizational choice reveals about their leadership preferences and team management opportunities")
            elif 'selected_options' in response_data:  # Multiple selections
                selected_list = response_data['selected_options']
                formatted.append(f"RESPONSE TYPE: Multiple Organizational Selections")
                formatted.append(f"CLIENT SELECTED: {selected_list}")
                formatted.append(f"PEOPLE & OPS ANALYSIS INSTRUCTION: Analyze the combination of organizational choices and their leadership implications")
            elif 'response_text' in response_data:
                text = response_data['response_text']
                word_count = response_data.get('word_count', 0)
                formatted.append(f"RESPONSE TYPE: Organizational Text Response")
                formatted.append(f"CLIENT WROTE: \"{text}\"")
                formatted.append(f"RESPONSE LENGTH: {word_count} words")
                formatted.append(f"PEOPLE & OPS ANALYSIS INSTRUCTION: Analyze the content for leadership insights and organizational opportunities")
            elif 'slider_value' in response_data:
                value = response_data['slider_value']
                formatted.append(f"RESPONSE TYPE: Organizational Rating")
                formatted.append(f"CLIENT RATED: {value}")
                formatted.append(f"PEOPLE & OPS ANALYSIS INSTRUCTION: Analyze the rating level for organizational capability assessment")
        
        formatted.append("---")
    
    return "\n".join(formatted)

# ======================================================
#           Database Functions
# ======================================================

def setup_people_ops_logging():
    """Set up logging for people & operations engine"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    log_file = log_dir / f"people_ops_engine_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_format = logging.Formatter('%(asctime)s - PEOPLE & OPS ENGINE %(levelname)s - %(message)s')
    console_handler.setFormatter(console_format)
    
    # File handler
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_format = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(funcName)s:%(lineno)d - %(message)s')
    file_handler.setFormatter(file_format)
    
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)
    
    logging.info(f"People & Operations Engine Logging Initialized: {log_file}")
    return logger

def get_people_ops_connection():
    """Get connection to people & operations database"""
    try:
        conn = psycopg2.connect(
            host=PEOPLE_OPS_DB_CONFIG["host"],
            dbname=PEOPLE_OPS_DB_CONFIG["database"],
            user=PEOPLE_OPS_DB_CONFIG["user"],
            password=PEOPLE_OPS_DB_CONFIG["password"],
            port=PEOPLE_OPS_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"People & ops database connection error: {str(e)}")
        raise

def get_component_connection():
    """Get connection to component database"""
    try:
        conn = psycopg2.connect(
            host=COMPONENT_DB_CONFIG["host"],
            dbname=COMPONENT_DB_CONFIG["database"],
            user=COMPONENT_DB_CONFIG["user"],
            password=COMPONENT_DB_CONFIG["password"],
            port=COMPONENT_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"Component database connection error: {str(e)}")
        raise

def get_profile_connection():
    """Get connection to profile database"""
    try:
        conn = psycopg2.connect(
            host=PROFILE_DB_CONFIG["host"],
            dbname=PROFILE_DB_CONFIG["database"],
            user=PROFILE_DB_CONFIG["user"],
            password=PROFILE_DB_CONFIG["password"],
            port=PROFILE_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"Profile database connection error: {str(e)}")
        raise

def get_dream_connection():
    """Get connection to dream database"""
    try:
        conn = psycopg2.connect(
            host=DREAM_DB_CONFIG["host"],
            dbname=DREAM_DB_CONFIG["database"],
            user=DREAM_DB_CONFIG["user"],
            password=DREAM_DB_CONFIG["password"],
            port=DREAM_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"Dream database connection error: {str(e)}")
        raise

def get_growth_connection():
    """Get connection to growth database"""
    try:
        conn = psycopg2.connect(
            host=GROWTH_DB_CONFIG["host"],
            dbname=GROWTH_DB_CONFIG["database"],
            user=GROWTH_DB_CONFIG["user"],
            password=GROWTH_DB_CONFIG["password"],
            port=GROWTH_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"Growth database connection error: {str(e)}")
        raise

def get_analyst_connection():
    """Get connection to analyst database"""
    try:
        conn = psycopg2.connect(
            host=ANALYST_DB_CONFIG["host"],
            dbname=ANALYST_DB_CONFIG["database"],
            user=ANALYST_DB_CONFIG["user"],
            password=ANALYST_DB_CONFIG["password"],
            port=ANALYST_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"Analyst database connection error: {str(e)}")
        raise

def get_user_connection():
    """Get connection to user database"""
    try:
        conn = psycopg2.connect(
            host=USER_DB_CONFIG["host"],
            dbname=USER_DB_CONFIG["database"],
            user=USER_DB_CONFIG["user"],
            password=USER_DB_CONFIG["password"],
            port=USER_DB_CONFIG["port"]
        )
        conn.autocommit = True
        return conn
    except Exception as e:
        logging.error(f"User database connection error: {str(e)}")
        raise

def get_azure_container_name(user_id: str) -> str:
    """Get Azure container name for user"""
    conn = None
    try:
        conn = psycopg2.connect(
            host=ONBOARDING_DB_HOST,
            dbname=ONBOARDING_DB_NAME,
            user=ONBOARDING_DB_USER,
            password=ONBOARDING_DB_PASSWORD,
            port=ONBOARDING_DB_PORT
        )
        conn.autocommit = True
        
        with conn.cursor() as cur:
            sql = """
                SELECT azure_container_name
                FROM client_onboarding
                WHERE client_id = %s
                LIMIT 1
            """
            cur.execute(sql, (user_id,))
            row = cur.fetchone()
            if not row:
                logging.warning(f"No container found for user_id={user_id}, using default container 'unified-clients-prod'")
                return "unified-clients-prod"

            container_name = row[0]
            logging.info(f"Found container for user_id={user_id}: {container_name}")
            return container_name

    except Exception as e:
        logging.error(f"Error retrieving container from DB: {str(e)}")
        return "unified-clients-prod"

    finally:
        if conn:
            conn.close()

def get_client_folder_name(user_id: str) -> str:
    """
    Get the client's folder name from database.
    Returns folder_name like '666-tim' from client_onboarding table.
    This ensures people ops reports go to: {container}/{client_folder}/the people and operations engine report/
    """
    conn = None
    try:
        conn = psycopg2.connect(
            host=ONBOARDING_DB_HOST,
            dbname=ONBOARDING_DB_NAME,
            user=ONBOARDING_DB_USER,
            password=ONBOARDING_DB_PASSWORD,
            port=ONBOARDING_DB_PORT
        )
        conn.autocommit = True

        with conn.cursor() as cur:
            sql = """
                SELECT folder_name
                FROM client_onboarding
                WHERE client_id = %s
                LIMIT 1
            """
            cur.execute(sql, (user_id,))
            row = cur.fetchone()
            if not row:
                logging.warning(f"No folder_name found for user_id={user_id}, using client_id as fallback")
                return user_id

            folder_name = row[0]
            logging.info(f"Found folder_name for user_id={user_id}: {folder_name}")
            return folder_name

    except Exception as e:
        logging.error(f"Error retrieving folder_name from DB: {str(e)}")
        return user_id  # Fallback to client_id

    finally:
        if conn:
            conn.close()

async def get_user_profile_data(user_id: str):
    """Get user profile data using connection pool - FIXED DATA TYPE ISSUE"""
    try:
        logging.info(f"Getting user profile data for user_id={user_id}")
        pool = await get_db_pool(USER_DB_CONFIG)
        
        async with pool.acquire() as conn:
            sql = """
                SELECT 
                    id, email, username, password, remember_me_token,
                    created_at, updated_at, is_email_verified, client_id,
                    business_name, contact_name, phone_number, ppr_id,
                    company_url, last_name, abn, archive, personal_bio, 
                    location, profile_image_url, skills, interests, 
                    last_login_at, achievements, provider, provider_id, 
                    login_count, last_login_provider, industry, team_size, 
                    business_description, biggest_challenge
                FROM users
                WHERE id = $1 OR client_id = $1
                LIMIT 1
            """
            
            # üî• FIX: Convert string user_id to integer for database query
            try:
                user_id_int = int(user_id)
                logging.info(f"üî¢ Converted user_id '{user_id}' to integer {user_id_int}")
                row = await conn.fetchrow(sql, user_id_int)
            except ValueError:
                # If user_id is not a valid integer, try as string with client_id only
                logging.warning(f"‚ö†Ô∏è user_id '{user_id}' is not an integer, trying as client_id string")
                sql_string = """
                    SELECT 
                        id, email, username, password, remember_me_token,
                        created_at, updated_at, is_email_verified, client_id,
                        business_name, contact_name, phone_number, ppr_id,
                        company_url, last_name, abn, archive, personal_bio, 
                        location, profile_image_url, skills, interests, 
                        last_login_at, achievements, provider, provider_id, 
                        login_count, last_login_provider, industry, team_size, 
                        business_description, biggest_challenge
                    FROM users
                    WHERE client_id = $1
                    LIMIT 1
                """
                row = await conn.fetchrow(sql_string, user_id)
            
            if not row:
                logging.warning(f"No user found for user_id={user_id}")
                return None
            
            # Convert asyncpg Record to dict
            user_data = dict(row)
            
            # Convert datetime objects to ISO format
            for key, value in user_data.items():
                if hasattr(value, 'isoformat'):
                    user_data[key] = value.isoformat()
            
            logging.info(f"Found user profile data for user_id={user_id}")
            return user_data
            
    except Exception as e:
        logging.error(f"Error getting user profile data: {str(e)}")
        logging.error(f"üîç Error context: user_id='{user_id}', type={type(user_id)}")
        return None

async def extract_complete_qa_data_for_user(user_id: str) -> Dict:
    """Extract ALL question-answer pairs from all engines for a specific user - ENHANCED VERSION"""
    
    logging.info(f"üéØ Starting complete Q&A extraction for user_id={user_id}")
    
    # All databases - extract everything for this user
    target_databases = [
        ("BACKABLE-PROFILE-ENGINE", "profile_responses", "profile_engine"),
        ("BACKABLE-THE-ANALYST", "analyst_responses", "analyst_engine"), 
        ("BACKABLE-THE-GROWTH-ENGINE", "growth_responses", "growth_engine"),
        ("BACKABLE-COMPONENT-ENGINE", "component_responses", "component_engine"),
        ("BACKABLE-DREAM-ANALYZER", "dream_responses", "dream_engine")
    ]
    
    qa_intelligence = {
        "user_id": user_id,
        "extraction_timestamp": datetime.now().isoformat(),
        "extraction_method": "complete_qa_pairs_all_engines",
        "target_tokens": "up_to_48k",
        "complete_qa_data": {
            "profile_engine": [],
            "analyst_engine": [],
            "growth_engine": [],
            "component_engine": [],
            "dream_engine": []
        },
        "cross_engine_insights": {},
        "token_tracking": {
            "by_engine": {},
            "total_tokens": 0,
            "qa_pairs_count": 0
        }
    }
    
    logging.info(f"üìã Extracting ALL question_text + response_data pairs for user {user_id}")
    logging.info(f"üî• NO FILTERING - Getting everything for comprehensive analysis")
    
    total_tokens = 0
    total_qa_pairs = 0
    
    for db_name, responses_table, engine_key in target_databases:
        logging.info(f"\nüìä Processing {db_name} for user {user_id}...")
        
        engine_tokens = 0
        engine_qa_pairs = 0
        
        try:
            # Get database connection using connection pool
            if "PROFILE" in db_name:
                pool = await get_db_pool(PROFILE_DB_CONFIG)
            elif "ANALYST" in db_name:
                pool = await get_db_pool(ANALYST_DB_CONFIG)
            elif "GROWTH" in db_name:
                pool = await get_db_pool(GROWTH_DB_CONFIG)
            elif "COMPONENT" in db_name:
                pool = await get_db_pool(COMPONENT_DB_CONFIG)
            elif "DREAM" in db_name:
                pool = await get_db_pool(DREAM_DB_CONFIG)
            else:
                logging.warning(f"‚ö†Ô∏è Unknown database: {db_name}, skipping...")
                continue
                
            async with pool.acquire() as conn:
                try:
                    # Extract ALL question_text and response_data for this user
                    query = f"""
                        SELECT question_text, response_data
                        FROM {responses_table} 
                        WHERE user_id = $1
                          AND question_text IS NOT NULL
                          AND response_data IS NOT NULL
                        ORDER BY answered_at DESC
                    """
                    
                    results = await conn.fetch(query, user_id)
                    
                    for row in results:
                        question_text = row[0]
                        response_data = row[1]
                        
                        # Clean the response data
                        cleaned_response = clean_response_data(response_data)
                        
                        if cleaned_response:
                            qa_pair = {
                                "question": question_text,
                                "response": cleaned_response
                            }
                            
                            # Calculate tokens for this Q&A pair
                            qa_tokens = estimate_tokens(json.dumps(qa_pair))
                            
                            # Check token budget - use 46K of 50K budget (leave room for overhead)
                            if total_tokens + qa_tokens > 46000:
                                logging.warning(f"   ‚ö†Ô∏è  Approaching 50K token limit, stopping extraction")
                                break
                            
                            qa_intelligence["complete_qa_data"][engine_key].append(qa_pair)
                            
                            engine_tokens += qa_tokens
                            total_tokens += qa_tokens
                            engine_qa_pairs += 1
                            total_qa_pairs += 1
                            
                            # Show first 80 chars of response for preview
                            response_preview = str(cleaned_response)[:80] + "..." if len(str(cleaned_response)) > 80 else str(cleaned_response)
                            logging.debug(f"   ‚úÖ Q&A: {response_preview}")
                
                except Exception as e:
                    logging.error(f"   ‚ùå Error with {responses_table}: {e}")
            
            qa_intelligence["token_tracking"]["by_engine"][engine_key] = {
                "tokens": engine_tokens,
                "qa_pairs": engine_qa_pairs
            }
            
            logging.info(f"   ‚úÖ {db_name}: {engine_qa_pairs} Q&A pairs, {engine_tokens:,} tokens")
            
        except Exception as e:
            logging.error(f"   ‚ùå Database connection failed for {db_name}: {e}")
    
    # Final calculations
    json_overhead = int(total_tokens * 0.15)  # 15% overhead for clean JSON
    final_tokens = total_tokens + json_overhead
    
    qa_intelligence["token_tracking"]["total_tokens"] = final_tokens
    qa_intelligence["token_tracking"]["qa_pairs_count"] = total_qa_pairs
    qa_intelligence["token_tracking"]["json_overhead"] = json_overhead
    qa_intelligence["token_tracking"]["efficiency_score"] = total_qa_pairs / max(final_tokens, 1) * 1000
    
    logging.info(f"\nüéØ COMPLETE EXTRACTION FINISHED for user {user_id}")
    logging.info(f"Q&A Pairs: {total_qa_pairs}")
    logging.info(f"Total Tokens: {final_tokens:,}")
    logging.info(f"Token Budget Used: {(final_tokens/50000)*100:.1f}% of 50K")
    logging.info(f"Efficiency: {qa_intelligence['token_tracking']['efficiency_score']:.1f} Q&A pairs per 1000 tokens")
    logging.info(f"Remaining Budget: {50000 - final_tokens:,} tokens")
    
    return qa_intelligence

def estimate_tokens(text):
    """Estimate token count (roughly 4 characters per token)"""
    return len(str(text)) // 4 if text else 0

def clean_response_data(response_data):
    """Clean response data to keep only essential information"""
    if not response_data:
        return None
    
    if isinstance(response_data, dict):
        # For slider values - keep the core scores
        if 'slider_values' in response_data:
            return response_data['slider_values']
        
        # For selections - keep the selected option
        if 'selected_option' in response_data:
            return response_data['selected_option']
        
        # For arrays/lists in response
        if 'selected_options' in response_data:
            return response_data['selected_options']
        
        # For text responses
        if 'text_response' in response_data:
            return response_data['text_response']
        
        # For response values
        if 'response_value' in response_data:
            return response_data['response_value']
        
        # Keep only essential keys, skip metadata
        essential_keys = ['value', 'label', 'text', 'score', 'rating', 'selection', 'answer']
        cleaned = {}
        for key, value in response_data.items():
            if any(essential in key.lower() for essential in essential_keys):
                cleaned[key] = value
        
        return cleaned if cleaned else response_data
    
    elif isinstance(response_data, list):
        # Keep lists as-is but limit to 10 items
        return response_data[:10]
    
    elif isinstance(response_data, str):
        # Keep text but limit length for very long responses
        return response_data[:500] if len(response_data) > 500 else response_data
    
    return response_data

async def get_multi_database_intelligence(user_id: str) -> Dict:
    """Get intelligence from all available databases using connection pools - ENHANCED FOR PEOPLE & OPS"""
    logging.info(f"üîç Extracting multi-database intelligence for user_id={user_id}")
    
    intelligence = {
        'user_id': user_id,
        'component_intelligence': {},
        'profile_intelligence': {},
        'dream_intelligence': {},
        'growth_intelligence': {},
        'analyst_intelligence': {},
        'complete_qa_data': {},  # NEW: Complete Q&A data from all engines
        'extraction_timestamp': datetime.now().isoformat(),
        'data_sources_available': []
    }
    
    # üî• NEW: Extract complete Q&A data from all engines
    try:
        logging.info(f"üéØ Extracting complete Q&A data from all engines for user {user_id}")
        complete_qa_data = await extract_complete_qa_data_for_user(user_id)
        intelligence['complete_qa_data'] = complete_qa_data
        logging.info(f"‚úÖ Complete Q&A extraction successful: {complete_qa_data.get('token_tracking', {}).get('qa_pairs_count', 0)} total Q&A pairs")
    except Exception as e:
        logging.error(f"‚ùå Error extracting complete Q&A data: {str(e)}")
        intelligence['complete_qa_data'] = {'error': str(e), 'qa_pairs_count': 0}
    
    # Component Intelligence
    try:
        pool = await get_db_pool(COMPONENT_DB_CONFIG)
        async with pool.acquire() as conn:
            sql = """
                SELECT 
                    ca.phase, ca.phase_label, ca.assessment_type,
                    jsonb_object_agg(cr.question_id, 
                        jsonb_build_object(
                            'answer', cr.response_data->>'selected_option',
                            'weight', cr.weight,
                            'section', cr.section,
                            'metadata', cr.metadata
                        )
                    ) as responses
                FROM component_responses cr
                JOIN component_assessments ca ON cr.user_id = ca.user_id
                WHERE cr.user_id = $1
                GROUP BY ca.phase, ca.phase_label, ca.assessment_type
            """
            result = await conn.fetchrow(sql, user_id)
            
            if result:
                intelligence['component_intelligence'] = {
                    'business_phase': result[0],
                    'phase_label': result[1],
                    'assessment_type': result[2],
                    'responses': result[3] or {},
                    'data_available': True
                }
                intelligence['data_sources_available'].append('component')
                logging.info(f"‚úÖ Component intelligence extracted: Phase {result[0]} ({result[1]})")
            else:
                intelligence['component_intelligence'] = {'data_available': False}
                logging.info(f"‚ö†Ô∏è No component data found for user {user_id}")
        
    except Exception as e:
        logging.error(f"‚ùå Error extracting component intelligence: {str(e)}")
        intelligence['component_intelligence'] = {'data_available': False, 'error': str(e)}
    
    # Profile Intelligence (Business DNA)
    try:
        pool = await get_db_pool(PROFILE_DB_CONFIG)
        async with pool.acquire() as conn:
            sql = """
                SELECT 
                    pa.assessment_type, pa.created_at,
                    COALESCE(jsonb_object_agg(
                        CASE WHEN pr.question_id IS NOT NULL THEN pr.question_id END,
                        CASE WHEN pr.question_id IS NOT NULL THEN
                            jsonb_build_object(
                                'answer', pr.response_data->>'selected_option',
                                'weight', pr.weight,
                                'section', pr.section,
                                'question_text', pr.question_text
                            )
                        END
                    ) FILTER (WHERE pr.question_id IS NOT NULL), '{}'::jsonb) as responses
                FROM profile_assessments pa
                LEFT JOIN profile_responses pr ON pr.user_id = pa.user_id
                WHERE pa.user_id = $1
                GROUP BY pa.assessment_type, pa.created_at
            """
            result = await conn.fetchrow(sql, user_id)
            
            if result and result[2] and result[2] != {}:
                intelligence['profile_intelligence'] = {
                    'assessment_type': result[0],
                    'created_at': result[1].isoformat() if result[1] else None,
                    'responses': result[2],
                    'data_available': True,
                    'response_count': len(result[2])
                }
                intelligence['data_sources_available'].append('profile')
                logging.info(f"‚úÖ Profile intelligence extracted: {len(result[2])} responses")
            else:
                intelligence['profile_intelligence'] = {'data_available': False}
                logging.info(f"‚ö†Ô∏è No profile data found for user {user_id}")
        
    except Exception as e:
        logging.error(f"‚ùå Error extracting profile intelligence: {str(e)}")
        intelligence['profile_intelligence'] = {'data_available': False, 'error': str(e)}
    
    # Dream Intelligence
    try:
        pool = await get_db_pool(DREAM_DB_CONFIG)
        async with pool.acquire() as conn:
            sql = """
                SELECT 
                    da.assessment_type, da.created_at,
                    jsonb_object_agg(dr.question_id, 
                        jsonb_build_object(
                            'answer', dr.response_data->>'selected_option',
                            'response_text', dr.response_data->>'response_text',
                            'section', dr.section,
                            'question_text', dr.question_text
                        )
                    ) as responses
                FROM dream_responses dr
                JOIN dream_assessments da ON dr.user_id = da.user_id
                WHERE dr.user_id = $1
                GROUP BY da.assessment_type, da.created_at
            """
            result = await conn.fetchrow(sql, user_id)
            
            if result:
                intelligence['dream_intelligence'] = {
                    'assessment_type': result[0],
                    'created_at': result[1].isoformat() if result[1] else None,
                    'responses': result[2] or {},
                    'data_available': True,
                    'response_count': len(result[2] or {})
                }
                intelligence['data_sources_available'].append('dream')
                logging.info(f"‚úÖ Dream intelligence extracted: {len(result[2] or {})} responses")
            else:
                intelligence['dream_intelligence'] = {'data_available': False}
                logging.info(f"‚ö†Ô∏è No dream data found for user {user_id}")
        
    except Exception as e:
        logging.error(f"‚ùå Error extracting dream intelligence: {str(e)}")
        intelligence['dream_intelligence'] = {'data_available': False, 'error': str(e)}
    
    # Growth Intelligence
    try:
        pool = await get_db_pool(GROWTH_DB_CONFIG)
        async with pool.acquire() as conn:
            sql = """
                SELECT 
                    ga.assessment_type, ga.created_at,
                    jsonb_object_agg(gr.question_id, 
                        jsonb_build_object(
                            'answer', gr.response_data->>'selected_option',
                            'response_text', gr.response_data->>'response_text',
                            'section', gr.section,
                            'question_text', gr.question_text
                        )
                    ) as responses
                FROM growth_responses gr
                JOIN growth_assessments ga ON gr.user_id = ga.user_id
                WHERE gr.user_id = $1
                GROUP BY ga.assessment_type, ga.created_at
            """
            result = await conn.fetchrow(sql, user_id)
            
            if result:
                intelligence['growth_intelligence'] = {
                    'assessment_type': result[0],
                    'created_at': result[1].isoformat() if result[1] else None,
                    'responses': result[2] or {},
                    'data_available': True,
                    'response_count': len(result[2] or {})
                }
                intelligence['data_sources_available'].append('growth')
                logging.info(f"‚úÖ Growth intelligence extracted: {len(result[2] or {})} responses")
            else:
                intelligence['growth_intelligence'] = {'data_available': False}
                logging.info(f"‚ö†Ô∏è No growth data found for user {user_id}")
        
    except Exception as e:
        logging.error(f"‚ùå Error extracting growth intelligence: {str(e)}")
        intelligence['growth_intelligence'] = {'data_available': False, 'error': str(e)}
    
    # Analyst Intelligence (Behavioral)
    try:
        pool = await get_db_pool(ANALYST_DB_CONFIG)
        async with pool.acquire() as conn:
            sql = """
                SELECT 
                    jsonb_object_agg(ar.question_id, 
                        jsonb_build_object(
                            'answer', ar.response_data->>'selected_option',
                            'response_text', ar.response_data->>'response_text',
                            'section', ar.section,
                            'metadata', ar.metadata
                        )
                    ) as responses
                FROM analyst_responses ar
                WHERE ar.user_id = $1
                GROUP BY ar.user_id
            """
            result = await conn.fetchrow(sql, user_id)
            
            if result and result[0]:
                intelligence['analyst_intelligence'] = {
                    'responses': result[0],
                    'data_available': True,
                    'response_count': len(result[0])
                }
                intelligence['data_sources_available'].append('analyst')
                logging.info(f"‚úÖ Analyst intelligence extracted: {len(result[0])} responses")
            else:
                intelligence['analyst_intelligence'] = {'data_available': False}
                logging.info(f"‚ö†Ô∏è No analyst data found for user {user_id}")
        
    except Exception as e:
        logging.error(f"‚ùå Error extracting analyst intelligence: {str(e)}")
        intelligence['analyst_intelligence'] = {'data_available': False, 'error': str(e)}
    
    logging.info(f"üéØ Multi-database intelligence extraction complete: {len(intelligence['data_sources_available'])} sources available")
    return intelligence

def create_people_ops_tables(conn):
    """Create necessary people & operations tables"""
    try:
        with conn.cursor() as cur:
            # Create people_ops_assessments table
            cur.execute("""
                CREATE TABLE IF NOT EXISTS people_ops_assessments (
                    id SERIAL PRIMARY KEY,
                    user_id VARCHAR(255) UNIQUE NOT NULL,
                    assessment_type VARCHAR(100) NOT NULL,
                    version VARCHAR(20) NOT NULL,
                    created_at TIMESTAMPTZ,
                    last_updated TIMESTAMPTZ,
                    timezone VARCHAR(100),
                    session_metadata JSONB,
                    device_fingerprint JSONB,
                    progress_tracking JSONB,
                    completion_flags JSONB,
                    raw_data JSONB,
                    multi_database_intelligence JSONB,
                    created_timestamp TIMESTAMPTZ DEFAULT NOW()
                )
            """)
            
            # Create people_ops_responses table
            cur.execute("""
                CREATE TABLE IF NOT EXISTS people_ops_responses (
                    id SERIAL PRIMARY KEY,
                    assessment_id INTEGER REFERENCES people_ops_assessments(id),
                    user_id VARCHAR(255) NOT NULL,
                    question_id VARCHAR(50) NOT NULL,
                    section VARCHAR(100) NOT NULL,
                    question_type VARCHAR(50),
                    question_text TEXT,
                    response_format VARCHAR(50),
                    response_data JSONB,
                    all_options JSONB,
                    metadata JSONB,
                    weight VARCHAR(20),
                    answered_at TIMESTAMPTZ,
                    last_modified_at TIMESTAMPTZ,
                    created_timestamp TIMESTAMPTZ DEFAULT NOW(),
                    UNIQUE(assessment_id, question_id)
                )
            """)
            
            # Create people_ops_behavioral_analytics table
            cur.execute("""
                CREATE TABLE IF NOT EXISTS people_ops_behavioral_analytics (
                    id SERIAL PRIMARY KEY,
                    assessment_id INTEGER REFERENCES people_ops_assessments(id) UNIQUE,
                    user_id VARCHAR(255) NOT NULL,
                    mouse_behavior JSONB,
                    keyboard_behavior JSONB,
                    attention_patterns JSONB,
                    decision_making_style JSONB,
                    leadership_decision_patterns JSONB,
                    created_at TIMESTAMPTZ,
                    created_timestamp TIMESTAMPTZ DEFAULT NOW()
                )
            """)
            
            # Create people_ops_reports table
            cur.execute("""
                CREATE TABLE IF NOT EXISTS people_ops_reports (
                    id SERIAL PRIMARY KEY,
                    report_id VARCHAR(255) UNIQUE NOT NULL,
                    user_id VARCHAR(255) NOT NULL,
                    assessment_id INTEGER REFERENCES people_ops_assessments(id),
                    report_type VARCHAR(100) NOT NULL,
                    status VARCHAR(50) NOT NULL,
                    azure_container VARCHAR(255),
                    blob_paths JSONB,
                    chunk_count INTEGER,
                    generation_metadata JSONB,
                    created_at TIMESTAMPTZ DEFAULT NOW(),
                    completed_at TIMESTAMPTZ,
                    indexer_job_id VARCHAR(255),
                    indexer_status VARCHAR(50),
                    indexer_triggered_at TIMESTAMPTZ,
                    indexer_completed_at TIMESTAMPTZ,
                    indexer_error_message TEXT,
                    indexer_retry_count INTEGER DEFAULT 0,
                    multi_database_integration JSONB
                )
            """)
            
            # Create indexes
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_assessments_user_id ON people_ops_assessments(user_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_responses_user_id ON people_ops_responses(user_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_responses_section ON people_ops_responses(section)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_user_id ON people_ops_reports(user_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_report_id ON people_ops_reports(report_id)")
            
            # Create indexer indexes
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_indexer_job_id ON people_ops_reports(indexer_job_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_people_ops_reports_indexer_status ON people_ops_reports(indexer_status)")
            
        logging.info("‚úÖ People & Operations engine tables created successfully")
        
    except Exception as e:
        logging.error(f"‚ùå Error creating people & ops tables: {str(e)}")
        raise

def ensure_people_ops_tables_exist():
    """Ensure people & operations tables exist on startup - CRITICAL FIX"""
    conn = None
    try:
        logging.info("üîß Ensuring People & Operations database tables exist...")
        
        conn = get_people_ops_connection()
        
        # Create tables if they don't exist
        create_people_ops_tables(conn)
        
        # Verify tables were created by checking if they exist
        with conn.cursor() as cur:
            cur.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name IN ('people_ops_assessments', 'people_ops_responses', 'people_ops_behavioral_analytics', 'people_ops_reports')
            """)
            existing_tables = [row[0] for row in cur.fetchall()]
            
            logging.info(f"‚úÖ Verified People & Operations tables exist: {existing_tables}")
            
            if len(existing_tables) >= 4:
                logging.info("‚úÖ All People & Operations engine tables are ready")
                return True
            else:
                missing_tables = ['people_ops_assessments', 'people_ops_responses', 'people_ops_behavioral_analytics', 'people_ops_reports']
                missing = [t for t in missing_tables if t not in existing_tables]
                logging.error(f"‚ùå Missing People & Operations tables: {missing}")
                return False
        
    except Exception as e:
        logging.error(f"‚ùå Error ensuring People & Operations tables exist: {str(e)}")
        return False
    finally:
        if conn:
            conn.close()


def store_people_ops_assessment(user_id: str, assessment_data: Dict, include_multi_db: bool = False):
    """Store people & operations assessment data with optional multi-database intelligence and detailed logging"""
    conn = None
    start_time = time.time()
    
    try:
        logging.info(f"üíæ Starting people & ops assessment storage")
        logging.info(f"üìä Storage parameters:")
        logging.info(f"   - User ID: {user_id}")
        logging.info(f"   - Include multi-DB: {include_multi_db}")
        logging.info(f"   - Assessment data size: {len(str(assessment_data))} characters")
        logging.info(f"   - Assessment keys: {list(assessment_data.keys()) if assessment_data else 'No data'}")
        
        # Validate input data
        if not user_id:
            raise ValueError("user_id is required and cannot be empty")
        
        if not assessment_data:
            raise ValueError("assessment_data is required and cannot be empty")
        
        # Log data structure analysis
        responses = assessment_data.get("responses", [])
        assessment_metadata = assessment_data.get("assessment_metadata", {})
        comprehensive_metadata = assessment_data.get("comprehensive_metadata", {})
        
        logging.info(f"üìã Data structure analysis:")
        logging.info(f"   - Responses: {len(responses)} items")
        logging.info(f"   - Assessment metadata keys: {list(assessment_metadata.keys()) if assessment_metadata else 'None'}")
        logging.info(f"   - Comprehensive metadata keys: {list(comprehensive_metadata.keys()) if comprehensive_metadata else 'None'}")
        
        # Get database connection with detailed logging
        logging.info(f"üîó Establishing database connection...")
        connection_start = time.time()
        
        conn = get_people_ops_connection()
        connection_time = time.time() - connection_start
        
        logging.info(f"‚úÖ Database connection established in {connection_time:.3f}s")
        logging.info(f"üîç Connection details: {type(conn).__name__}")
        
        # Create/verify tables
        logging.info(f"üìã Creating/verifying database tables...")
        table_creation_start = time.time()
        
        create_people_ops_tables(conn)
        table_creation_time = time.time() - table_creation_start
        
        logging.info(f"‚úÖ Tables verified/created in {table_creation_time:.3f}s")

        # FIX 1: SIMPLIFIED Multi-database intelligence handling
        multi_db_intelligence = {}
        multi_db_fetch_time = 0
        
        if include_multi_db:
            logging.info(f"üß† Fetching multi-database intelligence...")
            multi_db_start = time.time()
            
            try:
                # FIX 2: Use the existing event loop or create new one properly
                try:
                    # Check if we're in an async context
                    current_loop = asyncio.get_running_loop()
                    # If we get here, we're already in async context - this shouldn't happen in sync function
                    logging.warning(f"‚ö†Ô∏è Already in async context - this indicates improper function usage")
                    # Skip multi-DB to avoid conflicts
                    multi_db_intelligence = {}
                except RuntimeError:
                    # No running loop - safe to create new one
                    logging.debug(f"üîÑ No running loop, creating new one for multi-DB fetch")
                    
                    # FIX 3: Proper event loop handling
                    if platform.system() == 'Windows':
                        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
                    
                    # Create and use new event loop
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    
                    try:
                        multi_db_intelligence = loop.run_until_complete(
                            get_multi_database_intelligence(user_id)
                        )
                        
                        multi_db_fetch_time = time.time() - multi_db_start
                        
                        # Analyze fetched intelligence
                        data_sources = multi_db_intelligence.get('data_sources_available', [])
                        qa_pairs_count = multi_db_intelligence.get('complete_qa_data', {}).get('token_tracking', {}).get('qa_pairs_count', 0)
                        logging.info(f"‚úÖ Multi-database intelligence fetched in {multi_db_fetch_time:.3f}s")
                        logging.info(f"üß† Intelligence summary:")
                        logging.info(f"   - Data sources available: {len(data_sources)}")
                        logging.info(f"   - Sources: {', '.join(data_sources) if data_sources else 'None'}")
                        logging.info(f"   - Total Q&A pairs: {qa_pairs_count}")
                        logging.info(f"   - Intelligence data size: {len(str(multi_db_intelligence))} characters")
                        
                    except Exception as loop_error:
                        multi_db_fetch_time = time.time() - multi_db_start
                        logging.warning(f"‚ö†Ô∏è Error in event loop execution: {str(loop_error)}")
                        multi_db_intelligence = {}
                    finally:
                        # FIX 4: Proper loop cleanup
                        try:
                            # Cancel any pending tasks
                            pending = asyncio.all_tasks(loop)
                            if pending:
                                logging.debug(f"üîÑ Cancelling {len(pending)} pending tasks")
                                for task in pending:
                                    task.cancel()
                                
                                # Wait briefly for cancellation
                                try:
                                    loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))
                                except Exception:
                                    pass
                            
                            loop.close()
                            logging.debug(f"üîÑ Event loop closed successfully")
                        except Exception as cleanup_error:
                            logging.warning(f"‚ö†Ô∏è Event loop cleanup error: {cleanup_error}")
                        finally:
                            # Reset event loop
                            try:
                                asyncio.set_event_loop(None)
                            except Exception:
                                pass
                    
            except Exception as e:
                multi_db_fetch_time = time.time() - multi_db_start
                logging.warning(f"‚ö†Ô∏è Failed to fetch multi-database intelligence after {multi_db_fetch_time:.3f}s: {str(e)}")
                logging.warning(f"üîç Multi-DB error type: {type(e).__name__}")
                logging.warning(f"üîç Continuing without multi-DB intelligence...")
                multi_db_intelligence = {}
        else:
            logging.info(f"‚ÑπÔ∏è Multi-database intelligence not requested, skipping")

        # Begin database transaction with detailed logging
        logging.info(f"üìù Starting database transaction...")
        transaction_start = time.time()
        
        with conn.cursor() as cur:
            logging.debug(f"‚úÖ Database cursor acquired")
            
            # Prepare assessment metadata with safety checks
            logging.info(f"üîß Preparing assessment metadata...")
            
            assessment_type = assessment_metadata.get("assessment_type", "people_operations_strategy")
            version = assessment_metadata.get("version", "1.0")
            created_at = assessment_metadata.get("created_at")
            last_updated = assessment_metadata.get("last_updated")
            timezone = assessment_metadata.get("timezone", "UTC")
            
            # Enhanced metadata preparation with validation
            session_metadata = assessment_metadata.get("session_metadata", {})
            device_fingerprint = assessment_metadata.get("device_fingerprint", {})
            progress_tracking = assessment_data.get("progress_tracking", {})
            completion_flags = assessment_data.get("completion_flags", {})
            
            logging.info(f"üìä Assessment metadata prepared:")
            logging.info(f"   - Type: {assessment_type}")
            logging.info(f"   - Version: {version}")
            logging.info(f"   - Timezone: {timezone}")
            logging.info(f"   - Session metadata: {len(session_metadata)} items")
            logging.info(f"   - Device fingerprint: {len(device_fingerprint)} items")
            logging.info(f"   - Progress tracking: {len(progress_tracking)} items")
            logging.info(f"   - Completion flags: {len(completion_flags)} items")
            
            # FIX 5: Safer JSON serialization with error handling
            try:
                session_metadata_json = json.dumps(session_metadata, default=str)
                device_fingerprint_json = json.dumps(device_fingerprint, default=str)
                progress_tracking_json = json.dumps(progress_tracking, default=str)
                completion_flags_json = json.dumps(completion_flags, default=str)
                raw_data_json = json.dumps(assessment_data, default=str)
                multi_db_intelligence_json = json.dumps(multi_db_intelligence, default=str)
                
                logging.debug(f"‚úÖ JSON serialization successful")
                logging.debug(f"   - Raw data JSON size: {len(raw_data_json)} characters")
                logging.debug(f"   - Multi-DB JSON size: {len(multi_db_intelligence_json)} characters")
                
            except Exception as json_error:
                logging.error(f"‚ùå JSON serialization error: {json_error}")
                logging.error(f"üîç Problematic data types:")
                logging.error(f"   - Session metadata type: {type(session_metadata)}")
                logging.error(f"   - Device fingerprint type: {type(device_fingerprint)}")
                logging.error(f"   - Progress tracking type: {type(progress_tracking)}")
                raise ValueError(f"Failed to serialize data to JSON: {json_error}")

            # Execute main assessment insert/update
            logging.info(f"üìù Executing main assessment SQL...")
            sql_start = time.time()
            
            sql = """
                INSERT INTO people_ops_assessments (
                    user_id, assessment_type, version, created_at, last_updated,
                    timezone, session_metadata, device_fingerprint,
                    progress_tracking, completion_flags, raw_data, multi_database_intelligence
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                ) ON CONFLICT (user_id) DO UPDATE SET
                    last_updated              = EXCLUDED.last_updated,
                    session_metadata          = EXCLUDED.session_metadata,
                    progress_tracking         = EXCLUDED.progress_tracking,
                    completion_flags          = EXCLUDED.completion_flags,
                    raw_data                  = EXCLUDED.raw_data,
                    multi_database_intelligence = CASE 
                        WHEN %s = true THEN EXCLUDED.multi_database_intelligence 
                        ELSE people_ops_assessments.multi_database_intelligence 
                    END
                RETURNING id
            """

            try:
                cur.execute(sql, (
                    user_id,
                    assessment_type,
                    version,
                    created_at,
                    last_updated,
                    timezone,
                    session_metadata_json,
                    device_fingerprint_json,
                    progress_tracking_json,
                    completion_flags_json,
                    raw_data_json,
                    multi_db_intelligence_json,
                    include_multi_db  # For the CASE statement
                ))
                
                assessment_id_row = cur.fetchone()
                assessment_id = assessment_id_row[0] if assessment_id_row else None
                
                sql_time = time.time() - sql_start
                logging.info(f"‚úÖ Main assessment SQL executed in {sql_time:.3f}s")
                logging.info(f"üìä Assessment ID: {assessment_id}")
                
                if not assessment_id:
                    raise Exception("Failed to get assessment_id from database - no row returned")
                    
            except Exception as sql_error:
                sql_time = time.time() - sql_start
                logging.error(f"‚ùå Main assessment SQL failed after {sql_time:.3f}s: {sql_error}")
                logging.error(f"üîç SQL parameters:")
                logging.error(f"   - user_id: {user_id}")
                logging.error(f"   - assessment_type: {assessment_type}")
                logging.error(f"   - version: {version}")
                logging.error(f"   - include_multi_db: {include_multi_db}")
                raise

            # Store responses with detailed logging
            responses_start = time.time()
            successful_responses = 0
            failed_responses = 0
            
            if responses:
                logging.info(f"üìù Storing {len(responses)} responses...")
                
                response_sql = """
                    INSERT INTO people_ops_responses (
                        assessment_id, user_id, question_id, section, question_type,
                        question_text, response_format, response_data, all_options,
                        metadata, weight, answered_at, last_modified_at
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                    ) ON CONFLICT (assessment_id, question_id) DO UPDATE SET
                        response_data    = EXCLUDED.response_data,
                        metadata         = EXCLUDED.metadata,
                        last_modified_at = EXCLUDED.last_modified_at
                """

                for i, response in enumerate(responses):
                    try:
                        question_id = response.get("question_id", f"unknown_{i}")
                        section = response.get("section", "Unknown")
                        
                        logging.debug(f"üìù Storing response {i+1}/{len(responses)}: {question_id} ({section})")
                        
                        # Validate and prepare response data
                        response_data = response.get("response_data", {})
                        all_options = response.get("all_options", [])
                        metadata = response.get("metadata", {})
                        
                        # FIX 6: Safer JSON encoding with default=str
                        try:
                            response_data_json = json.dumps(response_data, default=str)
                            all_options_json = json.dumps(all_options, default=str)
                            metadata_json = json.dumps(metadata, default=str)
                        except Exception as response_json_error:
                            logging.error(f"‚ùå JSON encoding error for response {question_id}: {response_json_error}")
                            failed_responses += 1
                            continue
                        
                        cur.execute(response_sql, (
                            assessment_id,
                            user_id,
                            question_id,
                            section,
                            response.get("question_type"),
                            response.get("question_text"),
                            response.get("response_format"),
                            response_data_json,
                            all_options_json,
                            metadata_json,
                            response.get("weight", "medium"),
                            response.get("answered_at"),
                            response.get("last_modified_at")
                        ))
                        
                        successful_responses += 1
                        
                    except Exception as response_error:
                        failed_responses += 1
                        logging.error(f"‚ùå Error storing response {i+1} ({response.get('question_id', 'unknown')}): {response_error}")
                        continue  # Continue with other responses
                
                responses_time = time.time() - responses_start
                logging.info(f"‚úÖ Response storage completed in {responses_time:.3f}s")
                logging.info(f"üìä Response results: {successful_responses} successful, {failed_responses} failed")
                
                if failed_responses > 0 and successful_responses == 0:
                    logging.error(f"‚ùå All responses failed to store!")
                elif failed_responses > 0:
                    logging.warning(f"‚ö†Ô∏è Some responses failed to store: {failed_responses}/{len(responses)}")
            else:
                logging.info(f"‚ÑπÔ∏è No responses to store")

            # FIX 7: Simplified behavioral analytics with better error handling
            behavioral_start = time.time()
            behavioral_data = assessment_data.get("comprehensive_metadata", {}).get("behavioral_analytics", {})

            if behavioral_data:
                logging.info(f"üß† Processing behavioral analytics...")
                logging.info(f"üìä Behavioral data keys: {list(behavioral_data.keys())}")
                
                try:
                    # Analyze leadership decision patterns
                    logging.debug(f"üîß Analyzing leadership decision patterns...")
                    pattern_analysis_start = time.time()
                    
                    leadership_patterns = analyze_people_ops_decision_patterns(behavioral_data, responses)
                    pattern_analysis_time = time.time() - pattern_analysis_start
                    
                    logging.info(f"‚úÖ Leadership pattern analysis completed in {pattern_analysis_time:.3f}s")
                    logging.info(f"üìä Pattern results: {list(leadership_patterns.keys()) if leadership_patterns else 'None'}")
                    
                    # Store behavioral analytics
                    behavior_sql = """
                        INSERT INTO people_ops_behavioral_analytics (
                            assessment_id, user_id, mouse_behavior, keyboard_behavior,
                            attention_patterns, decision_making_style,
                            leadership_decision_patterns, created_at
                        ) VALUES (
                            %s, %s, %s, %s, %s, %s, %s, %s
                        ) ON CONFLICT (assessment_id) DO UPDATE SET
                            mouse_behavior           = EXCLUDED.mouse_behavior,
                            keyboard_behavior        = EXCLUDED.keyboard_behavior,
                            attention_patterns       = EXCLUDED.attention_patterns,
                            decision_making_style    = EXCLUDED.decision_making_style,
                            leadership_decision_patterns = EXCLUDED.leadership_decision_patterns
                    """

                    # Prepare behavioral data with safety
                    mouse_behavior = behavioral_data.get("mouse_behavior", {})
                    keyboard_behavior = behavioral_data.get("keyboard_behavior", {})
                    attention_patterns = behavioral_data.get("attention_patterns", {})
                    decision_making_style = behavioral_data.get("decision_making_style", {})
                    
                    logging.debug(f"üß† Behavioral data breakdown:")
                    logging.debug(f"   - Mouse behavior: {len(mouse_behavior)} items")
                    logging.debug(f"   - Keyboard behavior: {len(keyboard_behavior)} items")
                    logging.debug(f"   - Attention patterns: {len(attention_patterns)} items")
                    logging.debug(f"   - Decision making: {len(decision_making_style)} items")
                    logging.debug(f"   - Leadership patterns: {len(leadership_patterns)} items")

                    # FIX 8: Use default=str for safer JSON encoding
                    cur.execute(behavior_sql, (
                        assessment_id,
                        user_id,
                        json.dumps(mouse_behavior, default=str),
                        json.dumps(keyboard_behavior, default=str),
                        json.dumps(attention_patterns, default=str),
                        json.dumps(decision_making_style, default=str),
                        json.dumps(leadership_patterns, default=str),
                        datetime.now().isoformat()  # FIX 9: Use datetime.now() instead of utcnow()
                    ))
                    
                    behavioral_time = time.time() - behavioral_start
                    logging.info(f"‚úÖ Behavioral analytics stored in {behavioral_time:.3f}s")
                    
                except Exception as behavioral_error:
                    behavioral_time = time.time() - behavioral_start
                    logging.error(f"‚ùå Error storing behavioral analytics after {behavioral_time:.3f}s: {behavioral_error}")
                    logging.error(f"üîç Behavioral error type: {type(behavioral_error).__name__}")
                    logging.warning(f"‚ö†Ô∏è Continuing without behavioral analytics...")
                    # Don't fail the entire operation for behavioral data
            else:
                logging.info(f"‚ÑπÔ∏è No behavioral analytics data to store")
        
        # Calculate final timing
        total_time = time.time() - start_time
        transaction_time = time.time() - transaction_start
        
        logging.info(f"üéâ People & ops assessment storage completed successfully!")
        logging.info(f"üìä STORAGE PERFORMANCE SUMMARY:")
        logging.info(f"   - Total time: {total_time:.3f}s")
        logging.info(f"   - Connection time: {connection_time:.3f}s")
        logging.info(f"   - Table creation: {table_creation_time:.3f}s")
        logging.info(f"   - Multi-DB fetch: {multi_db_fetch_time:.3f}s")
        logging.info(f"   - Transaction time: {transaction_time:.3f}s")
        logging.info(f"   - Assessment ID: {assessment_id}")
        logging.info(f"   - Responses stored: {successful_responses}")
        logging.info(f"   - Multi-DB sources: {len(multi_db_intelligence.get('data_sources_available', []))}")
        
        return assessment_id

    except Exception as e:
        total_time = time.time() - start_time
        logging.error(f"‚ùå People & ops assessment storage failed after {total_time:.3f}s")
        logging.error(f"üîç Error details:")
        logging.error(f"   - Error type: {type(e).__name__}")
        logging.error(f"   - Error message: {str(e)}")
        logging.error(f"   - User ID: {user_id}")
        logging.error(f"   - Include multi-DB: {include_multi_db}")
        logging.error(f"   - Assessment data size: {len(str(assessment_data)) if assessment_data else 0} chars")
        
        # Log the full traceback for debugging
        import traceback
        logging.error(f"üîç Full traceback:")
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                logging.error(f"   {line}")
        
        raise

    finally:
        if conn:
            try:
                conn.close()
                logging.debug(f"üîó Database connection closed")
            except Exception as close_error:
                logging.warning(f"‚ö†Ô∏è Error closing connection: {close_error}")

async def cleanup_corrupted_pools():
    """Clean up any corrupted connection pools - Python 3.10 compatible"""
    global _connection_pools
    
    corrupted_pools = []
    
    for db_key, pool in _connection_pools.copy().items():
        try:
            # PYTHON 3.10 COMPATIBLE: Use asyncio.wait_for instead of asyncio.timeout
            async def pool_test():
                async with pool.acquire() as test_conn:
                    await test_conn.execute('SELECT 1')
            
            await asyncio.wait_for(pool_test(), timeout=2.0)
        except Exception:
            corrupted_pools.append(db_key)
    
    for db_key in corrupted_pools:
        logging.warning(f"üóëÔ∏è Cleaning up corrupted pool: {db_key}")
        try:
            pool = _connection_pools.pop(db_key, None)
            if pool and not pool.is_closing():
                await pool.close()
        except Exception as e:
            logging.error(f"‚ùå Error cleaning pool {db_key}: {e}")
    
    logging.info(f"üßπ Cleaned up {len(corrupted_pools)} corrupted pools")

def analyze_people_ops_decision_patterns(behavioral_data: Dict, responses: List[Dict]) -> Dict:
    """Analyze people & operations-specific decision patterns with AI enhancement when possible"""
    
    logging.info("üß† Starting people & ops decision pattern analysis")
    logging.info(f"üìä Input data: behavioral_data keys: {list(behavioral_data.keys()) if behavioral_data else 'None'}")
    logging.info(f"üìä Input data: {len(responses)} responses to analyze")
    
    patterns = {
        'leadership_style': 'unknown',
        'team_preference': 'unknown',
        'decision_speed': 'unknown',
        'organizational_thinking': 'unknown',
        'confidence_score': 0.0,
        'analysis_method': 'heuristic'
    }
    
    try:
        # PHASE 1: Basic heuristic analysis (same as before - fast fallback)
        mouse_data = behavioral_data.get('mouse_behavior', {})
        if mouse_data:
            total_movements = mouse_data.get('total_movements', 0)
            avg_speed = mouse_data.get('average_speed', 0)
            
            if total_movements > 1000 and avg_speed > 15:
                patterns['decision_speed'] = 'fast_decisive'
                patterns['leadership_style'] = 'directive_leadership'
                patterns['confidence_score'] += 0.3
            elif total_movements > 500:
                patterns['decision_speed'] = 'moderate_analytical'
                patterns['leadership_style'] = 'collaborative_leadership'
                patterns['confidence_score'] += 0.2
            else:
                patterns['decision_speed'] = 'deliberate_cautious'
                patterns['leadership_style'] = 'supportive_leadership'
                patterns['confidence_score'] += 0.2
        
        keyboard_data = behavioral_data.get('keyboard_behavior', {})
        if keyboard_data:
            backspace_count = keyboard_data.get('backspace_count', 0)
            total_keystrokes = keyboard_data.get('total_keystrokes', 0)
            revision_ratio = (backspace_count / max(total_keystrokes, 1)) * 100
            
            if revision_ratio > 20:
                patterns['organizational_thinking'] = 'highly_systematic'
                patterns['team_preference'] = 'structured_teams'
            elif revision_ratio > 10:
                patterns['organizational_thinking'] = 'balanced_systematic'
                patterns['team_preference'] = 'flexible_teams'
            else:
                patterns['organizational_thinking'] = 'intuitive_adaptive'
                patterns['team_preference'] = 'dynamic_teams'
        
        # Basic response analysis
        people_ops_responses = [r for r in responses if any(keyword in r.get('section', '').lower() 
                               for keyword in ['people', 'leadership', 'team', 'culture', 'organization'])]
        
        if people_ops_responses:
            directive_count = 0
            collaborative_count = 0
            
            for response in people_ops_responses:
                selected = str(response.get('response_data', {}).get('selected_option', '')).lower()
                
                if any(word in selected for word in ['direct', 'control', 'manage', 'command', 'authority', 'decisive']):
                    directive_count += 1
                elif any(word in selected for word in ['collaborate', 'team', 'together', 'consensus', 'participate']):
                    collaborative_count += 1
            
            if directive_count > collaborative_count:
                patterns['leadership_style'] = 'directive_leadership'
            elif collaborative_count > directive_count:
                patterns['leadership_style'] = 'collaborative_leadership'
            else:
                patterns['leadership_style'] = 'balanced_leadership'
        
        # PHASE 2: Try AI enhancement if we have spare API keys
        try:
            api_health = get_enhanced_api_key_status() if 'get_enhanced_api_key_status' in globals() else {'healthy_keys': 5}
            healthy_keys = api_health.get('healthy_keys', 5)
            
            # Only use AI if plenty of healthy keys AND we got some basic patterns
            if healthy_keys >= 7 and patterns['leadership_style'] != 'unknown':
                logging.info("ü§ñ Attempting AI enhancement with Gemini...")
                
                spare_api_key = get_smart_api_key(99, 0) if 'get_smart_api_key' in globals() else GEMINI_API_KEYS[0]
                
                # Create concise AI prompt
                prompt = f"""
                Analyze this leadership pattern data and provide enhanced insights:
                
                BEHAVIORAL METRICS:
                - Mouse activity: {mouse_data.get('total_movements', 0)} movements, {mouse_data.get('average_speed', 0)} avg speed
                - Keyboard revision ratio: {((keyboard_data.get('backspace_count', 0) / max(keyboard_data.get('total_keystrokes', 1), 1)) * 100):.1f}%
                
                CURRENT ANALYSIS:
                - Leadership style: {patterns['leadership_style']}
                - Decision speed: {patterns['decision_speed']}
                - Team preference: {patterns['team_preference']}
                
                SAMPLE RESPONSES:
                {chr(10).join([f"Q: {r.get('question_text', 'Unknown')[:80]}... A: {str(r.get('response_data', {}).get('selected_option', 'No answer'))[:60]}..." for r in people_ops_responses[:3]])}
                
                Provide JSON response:
                {{
                    "refined_leadership_style": "directive_leadership|collaborative_leadership|balanced_leadership|transformational_leadership",
                    "confidence_level": 0.0-1.0,
                    "leadership_insight": "One sentence insight about their leadership approach",
                    "team_structure_recommendation": "structured|flexible|dynamic|hybrid"
                }}
                """
                
                # Call Gemini API
                response = requests.post(
                    f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent",
                    params={'key': spare_api_key},
                    json={
                        "contents": [{"role": "user", "parts": [{"text": prompt}]}],
                        "generationConfig": {
                            "temperature": 0.3,
                            "maxOutputTokens": 300,
                            "candidateCount": 1
                        }
                    },
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data['candidates'][0]['content']['parts'][0]['text']
                    
                    # Parse AI response
                    import json
                    ai_result = json.loads(content.strip())
                    
                    # Apply AI enhancements
                    patterns['leadership_style'] = ai_result.get('refined_leadership_style', patterns['leadership_style'])
                    patterns['confidence_score'] = ai_result.get('confidence_level', patterns['confidence_score'])
                    patterns['leadership_insight'] = ai_result.get('leadership_insight', '')
                    patterns['team_preference'] = ai_result.get('team_structure_recommendation', patterns['team_preference'])
                    patterns['analysis_method'] = 'ai_enhanced'
                    
                    # Update API key health
                    update_api_key_health(spare_api_key, success=True, response_time=1.0)
                    
                    logging.info("‚úÖ AI enhancement successful - using refined analysis")
                else:
                    raise Exception(f"API returned {response.status_code}")
                    
            else:
                logging.info(f"‚ö° Using heuristic analysis only (healthy keys: {healthy_keys}/10)")
                
        except Exception as ai_error:
            logging.warning(f"‚ö†Ô∏è AI enhancement failed, using heuristic results: {ai_error}")
            # Update API key health if we have the key
            if 'spare_api_key' in locals() and 'update_api_key_health' in globals():
                update_api_key_health(spare_api_key, success=False, error_code="AI_ANALYSIS_ERROR")
        
        # Add metadata
        patterns['analysis_timestamp'] = datetime.now().isoformat()
        patterns['analysis_metadata'] = {
            'responses_analyzed': len(responses) if responses else 0,
            'people_ops_responses_found': len(people_ops_responses) if 'people_ops_responses' in locals() else 0,
            'behavioral_data_available': bool(behavioral_data),
            'mouse_data_available': bool(behavioral_data.get('mouse_behavior')) if behavioral_data else False,
            'keyboard_data_available': bool(behavioral_data.get('keyboard_behavior')) if behavioral_data else False
        }
        
        logging.info("‚úÖ People & ops decision pattern analysis completed successfully")
        logging.info(f"üéØ Final patterns: {patterns}")
        
    except ZeroDivisionError as e:
        logging.error(f"üî¢ Division by zero in people & ops decision patterns: {str(e)}")
        patterns['error'] = f"Division by zero prevented: {str(e)}"
        patterns['error_type'] = 'division_by_zero'
    except AttributeError as e:
        logging.error(f"üîç Attribute error in people & ops decision patterns: {str(e)}")
        patterns['error'] = f"Data type error: {str(e)}"
        patterns['error_type'] = 'attribute_error'
    except Exception as e:
        logging.error(f"‚ùå Unexpected error analyzing people & ops decision patterns: {str(e)}")
        patterns['error'] = str(e)
        patterns['error_type'] = type(e).__name__
    
    return patterns

def store_people_ops_report_metadata(report_id: str, user_id: str, assessment_id: int, chunk_count: int, 
                                    container_name: str, generation_metadata: Dict):
    """Store people & operations report metadata"""
    conn = None
    try:
        conn = get_people_ops_connection()
        
        with conn.cursor() as cur:
            sql = """
                INSERT INTO people_ops_reports (
                    report_id, user_id, assessment_id, report_type, status,
                    azure_container, chunk_count, generation_metadata, completed_at,
                    multi_database_integration
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                ) ON CONFLICT (report_id) DO UPDATE SET
                    status = EXCLUDED.status,
                    chunk_count = EXCLUDED.chunk_count,
                    generation_metadata = EXCLUDED.generation_metadata,
                    completed_at = EXCLUDED.completed_at,
                    multi_database_integration = EXCLUDED.multi_database_integration
            """
            
            multi_db_info = {
                'integration_enabled': True,
                'data_sources_used': generation_metadata.get('data_sources_used', []),
                'intelligence_correlation': generation_metadata.get('intelligence_correlation', {}),
                'total_intelligence_sources': generation_metadata.get('total_intelligence_sources', 0),
                'complete_qa_pairs': generation_metadata.get('complete_qa_pairs', 0)
            }
            
            cur.execute(sql, (
                report_id,
                user_id,
                assessment_id,
                "comprehensive_people_operations_strategy",
                "completed",
                container_name,
                chunk_count,
                json.dumps(generation_metadata),
                datetime.now(),
                json.dumps(multi_db_info)
            ))
        
        logging.info(f"Stored people & ops report metadata for report_id={report_id}")
        
    except Exception as e:
        logging.error(f"Error storing people & ops report metadata: {str(e)}")
        raise
    finally:
        if conn:
            conn.close()

# ======================================================
#           People & Operations Report Generation
# ======================================================

def get_people_ops_report_sections():
    """Define people & operations-specific report sections"""
    return {
        "executive_summary": {
   "title": "People & Operations Executive Summary",
   "word_target": 800,
   "analysis_requirements": """
   ULTRA-COMPREHENSIVE 100/100 EXECUTIVE SUMMARY - COMPLETE MULTI-DATABASE INTELLIGENCE INTEGRATION
   **EVERY QUESTION MAPPED WITH FULL ML & STATISTICAL ANALYSIS**

   === SECTION 1: ORGANIZATIONAL READINESS INTELLIGENCE (200 words) ===

   **COMPLETE DATA SOURCE INTEGRATION:**

   **PEOPLE & OPERATIONS ASSESSMENT - FULL MAPPING:**
   - P&O 1.1 (Role Reality): "Crystal Clear" vs "Mostly Defined" vs "Fluid & Functional" vs "All Hands, All Tasks"
   - P&O 1.2 (Key-Person Risk Matrix): Strategic Planning/Sales & Client Relations/Operations/Finance & Admin/Technical Expertise/Product Development (Low‚ÜíHigh Risk)
   - P&O 1.3 (Holiday Behavior Test): "Command Centre Mode" vs "Scheduled Check-ins" vs "Emergency Only" vs "Daily Pulse Check" vs "Airplane Mode" vs "What Business?"
   - P&O 2.1 (Leadership Self-Rating): Still developing‚ÜíConfident and effective slider
   - P&O 2.2 (Team Perception): Need development‚ÜíExceptional leader slider
   - P&O 2.3 (Leadership Challenge Tournament): 6 battle rounds identifying primary leadership development priority
   - P&O 2.4 (Leadership Depth): No leadership depth‚ÜíStrong leadership multiple levels
   - P&O 3.1 (Revenue Responsibility): Clear Revenue Champions vs Shared Revenue Responsibility vs Owner-Dependent Revenue vs Revenue Responsibility Confusion
   - P&O 3.2 (Reporting Clarity Matrix): Reporting Structure/Individual Accountability/Performance Expectations/Decision Authority (Unclear‚ÜíCrystal Clear)
   - P&O 4.1 (People Systems Matrix): Hiring Process/Onboarding System/Performance Management/OH&S Procedures/Exit Process (Ad hoc‚ÜíHighly Systematic)
   - P&O 5.1 (Engagement Level): Disengaged‚ÜíHighly engaged slider
   - P&O 5.2 (Decision-Making Effectiveness): "Efficient Decisions" vs "Occasional Delays" vs "Frequent Bottlenecks" vs "Decision Struggles"
   - P&O 5.3 (Knowledge Flow): "Documented Systems" + "Cross-Training Culture" + "Information Silos" + "Individual Knowledge" + "Collaboration Tools"
   - P&O 6.1 (Warning Signs): "Sudden Departure" + "Workplace Conflict" + "Compliance Issues" + "Performance Impact" + "Client Relationship Loss" + "Delivery Failures"
   - P&O 7.1 (Performance Limiters): "Recruitment Struggles" + "Skills Gaps" + "Leadership Capacity" + "Retention Issues" + "Culture Challenges" + "System Failures"
   - P&O 7.2 (Talent Development): Systematic Development vs Informal Opportunities vs Reactive Approach vs No Structured Approach
   - P&O 8.1 (Operational Systems Matrix): SOPs/Quality Control/Workflow Management/Data Management/Technology Integration (Ad hoc‚ÜíHighly Systematic)
   - P&O 8.2 (Management Tools): "Project Management" + "CRM Systems" + "Financial Software" + "Communication Platforms" + "Document Management" + "Analytics & Reporting"
   - P&O 8.3 (Critical Business Tools): Free text tech stack analysis
   - P&O 8.4 (Systems Alignment): Completely misaligned‚ÜíPerfectly aligned with business goals
   - P&O 9.1 (Biggest Challenge): Free text people/leadership challenge
   - P&O 9.2 (Transformation Need): Free text organizational improvement

   **PROFILE ASSESSMENT - COMPLETE MAPPING:**
   - Profile 1 (Dinner Party Selection): "The Visionaries" + "The Builders" + "The Connectors" + "The Storytellers" + "The Innovators" + "The Wise Ones" + "The Catalysts" + "The Protectors"
   - Profile 2 (Networking Archetype): "The Sniper" vs "The Constellation" vs "The Pollinator" vs "The Storyteller" vs "The Detective" vs "The Host"
   - Profile 3 (Energy Conversations): "The Vision Quest" + "The Execution Engine" + "The Human Element" + "The Market Game" + "The Innovation Lab" + "The Wisdom Circle"
   - Profile 4 (Business Relationship Role): "The Sage" vs "The Catalyst" vs "The Bridge" vs "The Igniter" vs "The Anchor" vs "The Creator"
   - Profile 5 (Communication Superpower): Ask questions vs Tell stories vs Create environments vs See patterns vs Translate vision vs Help believe
   - Profile 6 (Help Instinct): Connect with perfect person vs Share experience story vs Ask thinking questions vs Brainstorm together vs Send resources vs Invite group conversation
   - Profile 7 (Brain Excitement Ranking): Breakthrough case studies/Future trends/Psychology of success/Innovation deep-dives/Leadership philosophies/Market disruption/Operational excellence/Cross-industry insights
   - Profile 8 (Learning Experience): "The Conference High" vs "The Deep Dive" vs "The Coffee Conversation" vs "The Mastermind" vs "The Study Hall" vs "The Immersion"
   - Profile 9 (Curiosity Topics): Psychology of decision-making + Building cultures + Technology changes + Global perspectives + Purpose and profit + Systems thinking + Art of influence + Sustainable business
   - Profile 10 (Surprise Insight): Free text personal insight
   - Profile 11 (Energy Restoration): Physical movement + Creative expression + Deep conversations + Learning new + Quiet solitude + Adventure + Service + Cultural experiences
   - Profile 12 (Perfect Weekend): "The Mountain Retreat" vs "The Creative Workshop" vs "The Family Sanctuary" vs "The Cultural Adventure" vs "The Physical Challenge" vs "The Learning Retreat"
   - Profile 13 (Outside Influences): Sports/Arts/Travel/Science/History/Family/Health/Community influence on business thinking
   - Profile 14 (Peak Business Pride): Lives impacted/Innovation brought/Culture created/Financial freedom/Problems solved/People developed/Example set/Legacy continued
   - Profile 15 (Inspiration Sources): Entrepreneurs with legacy + Purpose/meaning events + Profit/impact convergence + Mastery mentors + Diverse perspectives + Cultural approaches + Mission discussions + Deep motivations
   - Profile 16 (Business Leader Choice): Free text leader + question to ask
   - Profile 17 (Relationship Change): Free text transformative relationship/connection
   - Profile 18 (Connection Desires): Visionary leaders + Cross-industry innovators + International entrepreneurs + Purpose-driven leaders + Scaling experts + Industry veterans + Peer entrepreneurs + Community builders
   - Profile 20 (Member Profile Choice): "I'll Craft My Own Story" vs "Let AI Be My Storyteller"
   - Profile 21 (Opportunity Approach): First in line vs Selective curator vs Research mode vs Community validator vs Timing optimizer vs Value maximizer
   - Profile 22 (Misunderstood Operation): Free text operational misunderstanding

   **DREAM ANALYSIS - COMPLETE MAPPING:**
   - Dream 1 (3-Year Vision Smile): The freedom/The team/The impact/The recognition/The abundance/The legacy
   - Dream 2 (Family Pride): Free text accomplishment pride
   - Dream 3 (Deepest Aspiration): Freedom vs Impact vs Mastery vs Legacy vs Abundance vs Adventure
   - Dream 4 (Team Size): Number input including self
   - Dream 5 (Annual Revenue): $0-50K to $10M+ slider
   - Dream 6 (Business Feeling): "Swimmer in Deep Water" vs "Master Craftsperson" vs "Navigator in Fog" vs "Phoenix" vs "Archer" vs "Balancing Act"
   - Dream 7 (Current Situation): Growing/stable/optimistic vs Facing challenges/need momentum
   - Dream 8 (Night Worry): "Finding & Keeping Right Clients" vs "Managing Growth Without Control" vs "Building Vision-Sharing Team" vs "Financial Stress and Uncertainty"
   - Dream 9 (Biggest Frustration): Free text current frustration
   - Dream 10 (Target Revenue): Same/2x/3-5x/5-10x/10x+ current slider
   - Dream 11 (Success Definition): "Steady Sustainable Growth" vs "Market Leadership Position" vs "Freedom & Life Integration"
   - Dream 12 (Peak Role Vision): The Craftsperson vs The Conductor vs The Architect vs The Sage vs The Pioneer vs The Builder
   - Dream 13 (Five-Year Pride): Free text proudest accomplishment
   - Dream 14 (Big Decision Approach): The Researcher vs The Collaborator vs The Consensus Builder vs The Intuitive vs The Systematic
   - Dream 15 (Uncertainty Approach): Act quickly and adjust vs Plan thoroughly before moves
   - Dream 16 (Learning Preference): Stories/Examples vs Frameworks/Systems vs Data/Analysis vs Conversation/Coaching vs Experimentation
   - Dream 17 (Current Rating Sliders): Confidence in direction/Stress levels/Excitement level (1-10 scales)
   - Dream 18 (Work Preferences): Clear Action Plans + Strategic Frameworks + Real Success Stories + Data-Driven Insights + Quick Wins + Long-term Vision
   - Dream 19 (Partnership Hope): Clarity vs Confidence vs Capability vs Connection vs Acceleration vs Transformation
   - Dream 20 (Partnership Values): Understands Vision/Challenges Thinking/Practical Solutions/Available When Needed/Relevant Experience/Focuses on Success/Keeps Simple/Believes in Potential
   - Dream 21 (Commitment Level): Curious vs Engaged vs Determined vs Obsessed vs All-In
   - Dream 22 (Secret Dream): Free text biggest undisclosed business dream

   **GROWTH ASSESSMENT - COMPLETE MAPPING:**
   - Growth 1 (Business Truth): "Market Demand" vs "Capacity Limits" vs "Cash Flow Timing" vs "Team Limitations" vs "Systems Breakdown" vs "Market Competition" vs "Regulatory/Compliance" vs "Location Constraints" vs "Content at Current Size" vs "Something Else"
   - Growth 2 (Business Evolution): "Start-Up Infancy" vs "Early Traction" vs "Adolescence" vs "Growing Pains" vs "Prime Time" vs "Stable Momentum" vs "Expansion Mode" vs "Plateau/Drift"
   - Growth 3 (Lead Generation Rating): Poor‚ÜíExcellent slider + metrics (normal week sales count + average sale value)
   - Growth 4 (Lead Methods): Digital Marketing/Referrals/Networking/Content/Partners/Customer Programs/Traditional/Fixed Client Base/Location/Contracts/Don't Actively Seek + effectiveness ranking + growth desire
   - Growth 5 (Lead Frustration): "Feast or Famine" vs "Quality Issues" vs "Conversion Problems" vs "Time Intensive" vs "Channel Confusion" vs "Follow-up Failure" vs "Little Interest"
   - Growth 6 (Revenue Patterns): Yes predictable vs No consistent + Daily/Weekly/Monthly/Seasonal/Annual patterns + strongest/weakest quarters + low period management
   - Growth 7 (Revenue Trend): Declining‚ÜíRapid Growth (30%+) slider
   - Growth 8 (Sales Process Matrix): Lead Generation/Lead Qualification/Client Engagement/Proposal Process/Closing Deals/After-Sales (Struggling‚ÜíExcellent)
   - Growth 9 (Strategic Focus): "Penetration" vs "Development" vs "New Product" vs "Diversification"
   - Growth 10 (Growth Activities): Strategic Partnerships + Capability Building + Operational Efficiency + Premium Positioning + Franchise/Licensing + Sponsorships + Advertising + Succession Preparation + None
   - Growth 11 (Growth Barriers Tournament): 22-round elimination tournament of barriers
   - Growth 12 (Next Big Leap Need): "Better Systems" vs "More Capital" vs "Stronger Team" vs "Marketing Mastery" vs "Operational Excellence" vs "Strategic Clarity"
   - Growth 13 (Digital Capabilities Matrix): CRM Systems/Business Automation/Data Analytics/E-commerce/Remote Operations/AI (Not Using‚ÜíPerfect)
   - Growth 14 (Secret Weapon): "Experience Edge" vs "Relationship Power" vs "Innovation Leader" vs "Service Excellence" vs "Niche Mastery" vs "Value Engineering" vs "Something Unique"
   - Growth 15 (Unlimited Resources): Free text growth approach change
   - Growth 16 (Untapped Opportunity): Free text growth opportunity

   **ANALYST ASSESSMENT - COMPLETE MAPPING:**
   
   **Mind Expansion 1: Business Snapshot**
   - Analyst 1 (Information Flow): "Mountain Stream" vs "City Water System" vs "Leaky Garden Hose" vs "Ocean Current"
   - Analyst 2 (Business Processes): In heads vs Some documented vs Well documented vs Consistently executed vs Continuously improved
   - Analyst 3 (Challenge Response): Major disruption vs Moderate struggle vs Quick adaptation vs Smooth handling vs Found opportunity
   - Analyst 4 (Team Dynamic): "Scramble Mode" vs "Steady State" vs "High Performance"
   - Analyst 5 (Ownership Structure): Individual vs Partnership vs Family vs Investor-backed vs Cooperative
   - Analyst 6 (Fix One Thing): Free text operational issue
   - Analyst 6-11 (Deep Dive): System Reliability/Quality Control/Resource Utilization/Adaptability Speed sliders + Operational Excellence vs Competitors + Crisis Response Assessment

   **Mind Expansion 2: Money Matters**
   - Analyst Financial 1 (Financial Situation): Cash Flow/Profit Margins/Planning Horizon paired comparisons
   - Analyst Financial 2 (Financial Approach): Big Goals+Reactive vs Big Goals+Proactive vs Conservative+Reactive vs Conservative+Proactive
   - Analyst Financial 3 (Financial Setup): "Calculator App" vs "Dashboard" vs "Mission Control" vs "War Room" vs "Crystal Ball"
   - Analyst Financial 4 (Revenue Trends): Down 20%‚ÜíUp 50%+ slider
   - Analyst Financial 5-10 (Deep Dive): Profit margins current/target, Cash flow predictability, Financial planning horizon, Performance ratings, Recognition level, Revenue growth validation

   **Mind Expansion 3: Team Dynamics**
   - Analyst Team 1 (Decision Making): Individual vs Guided consultation vs Collaborative vs Consensus vs Delegated authority
   - Analyst Team 2 (Business Absence Test): Need constant contact vs Handle most things vs Run with questions vs Operate smoothly vs Thrive independently
   - Analyst Team 3 (Delegation Reality): Multiple times daily vs Daily vs Several weekly vs Occasionally vs Rarely
   - Analyst Team 4 (Team Structure): "Solo Leader" vs "Coordinated Team" vs "Mentor & Learners" vs "Specialized Team" vs "Self-Managing Team"
   - Analyst Team 5 (Leadership Focus): Control details + Developing others + Clear expectations + Direction/freedom balance + Systems without me + Sustainable culture
   - Analyst Team 6-9 (Deep Dive): Delegation effectiveness matrix, Leadership capabilities, Decision evolution, Management philosophy

   **Mind Expansion 4: Growth Reality**
   - Analyst Growth 1 (Growth Challenges): "Pipeline Problems" vs "Capacity Limits" vs "Quality vs Speed" vs "Resource Constraints" vs "Market Saturation"
   - Analyst Growth 2 (Customer Acquisition): Lead Generation/Conversion Rate/Customer Retention/Referrals this vs that progression
   - Analyst Growth 3 (Growth Style): "Steady Builder" vs "Strategic Planner" vs "Collaborative Grower" vs "Rapid Expander" vs "Adaptive Transformer" vs "Market Leader"
   - Analyst Growth 4 (Innovation Approach): React to requests vs Follow trends vs Strategic development vs Lead innovation vs Category creation
   - Analyst Growth 5 (Opportunity Management): React as come vs Loose evaluation vs Systematic process vs Strategic filter vs Proactive creation
   - Analyst Growth 10 (Revenue Trajectory): Last/This/Next/3 years/5 years revenue targets
   - Analyst Growth Deep Dive: Customer acquisition effectiveness, Competitive excellence, Growth validation

   **Mind Expansion 5: Market Position**
   - Analyst Market 1 (Customer Relationships): "They do the job" vs "They're reliable" vs "They understand us" vs "Part of our success" vs "Can't imagine without them"
   - Analyst Market 2 (Lead Sources): Word-of-mouth/Online search/Social media/Industry events/Strategic partnerships/Direct outreach/Repeat business/Location/Contracts
   - Analyst Market 3 (Competitive Position): Commodity choice vs Reliable option vs Preferred provider vs Market leader vs Category creator
   - Analyst Market 4 (Industry Change): Very slowly vs Gradually vs Moderately vs Rapidly vs Constantly
   - Analyst Market 5 (Network Role): "Focused Specialist" vs "Adaptable Partner" vs "Network Connector" vs "Trusted Advisor" vs "Industry Pioneer"
   - Analyst Market Deep Dive: Brand/reputation strength, Network position, Market intelligence

   **Mind Expansion 6: Future Vision**
   - Analyst Vision 1 (Strategic Planning): Minimal vs Basic annual vs Regular reviews vs Comprehensive vs Advanced frameworks
   - Analyst Vision 2 (Time Allocation): Operational‚ÜíStrategic slider
   - Analyst Vision 3 (Business Value): Profitability/Revenue growth/Customer base/IP/Owner-independent systems/Management team/Brand/Partnerships ranking
   - Analyst Vision 4 (Exit Thinking): Not considered vs Vague ideas vs General direction vs Well-defined vs Active preparation
   - Analyst Vision Deep Dive: Business dependency, Strategic execution, Wealth-building activities, Energy investment, Planning evolution

   **Mind Expansion 7: Strategic Clarity**
   - Analyst Clarity 1 (Energy Check): Significantly more vs Somewhat more vs Same vs Slightly less vs Much less motivated
   - Analyst Clarity 2 (Biggest Challenge): Same as onboarding vs Something else + free text
   - Analyst Clarity 3 (Clarity Needs): Strategic direction + Operational efficiency + Financial planning + Team development + Market positioning + Work-life balance + Business value/exit
   - Analyst Clarity 4 (Key Insight): Free text business wisdom
   - Analyst Clarity Deep Dive: Personal leadership development, Time allocation evolution

   **COMPONENT ASSESSMENT - COMPLETE MAPPING:**
   
   **Foundation to Challenger (Phases 0-2) - 29 Questions:**
   - Component F1 (Business Strategy Documentation): Written Strategy vs General Direction vs Mental Framework
   - Component F2 (Key Business Numbers): Know Exactly vs Know Roughly vs Not Sure (profit margin knowledge)
   - Component F3 (Personal Achievement Strategy): Clear Plan vs Some Development vs Accidental Growth
   - Component F4 (Sales Process Implementation): Systematic Follow-up vs Personal Response vs Informal Approach
   - Component F5 (Growth Numbers Tracking): Comprehensive vs Inconsistent vs Limited measurement
   - Component F6 (Ideal Client Understanding): Clear Profiles vs General Understanding vs Serve Anyone
   - Component F7 (Comprehensive Sales Strategy): Comprehensive vs Basic vs Ad Hoc
   - Component F8 (Effective Sales Funnels): Well-Designed vs Basic vs No Systematic
   - Component F9 (Financial Knowledge & Data): Comprehensive Data vs Basic Review vs Gut Feel Decision
   - Component F10 (Financial Infrastructure): Solid Systems vs Basic Systems vs Minimal Infrastructure
   - Component F11 (Financial Compliance): Properly Managed vs Some Gaps vs Catch-Up Mode
   - Component F12 (Work Coordination): Strategic Support vs Some Help vs Solo Push
   - Component F13 (Support Network Infrastructure): Established Network vs Informal Connections vs Figure It Out
   - Component F14 (Organization & Priority): Clear Framework vs Weighing Options vs Reactive Mode
   - Component F15 (Business Role Clarity): Crystal Clear vs Generally Clear vs Often Unclear
   - Component F16 (Business Organization Systems): Systematic Storage vs Some Organization vs Hunt and Search
   - Component F17 (Foundation for Success): Excited & Ready vs Excited but Worried vs Overwhelmed
   - Component F18 (Reporting Systems): Comprehensive vs Basic vs Limited Capabilities
   - Component F19 (Meeting Effectiveness): Structured & Productive vs Good Conversations vs Hit or Miss
   - Component F20 (Tailored Client Approach): Tailored vs General vs Same for All
   - Component F21 (Client Data Collection): Comprehensive Feedback vs General Feedback vs Hope They're Happy
   - Component F22 (System Gap Identification): Clear View vs Some Awareness vs Unclear Needs
   - Component F23 (Business Data Management): Data-Driven Analysis vs Mixed Approach vs Experience & Intuition
   - Component F24 (Personal Success Definition): Very Clear vs Generally Clear vs Unclear Definition
   - Component F25 (Leadership Identity Development): Clear Identity vs Developing Style vs Unclear Identity
   - Component F26 (Skill Development Program): Active Development vs Some Development vs Accidental Development
   - Component F27 (Stress & Control Reality Check): Rarely Stressed vs Sometimes Stressful vs Frequently Overwhelmed
   - Component F28 (Business Independence Test): Business Continues vs Some Issues vs Serious Problems
   - Component F29 (Growth Confidence Check): Excited & Confident vs Excited but Nervous vs Panic Mode
   - Component F30-F34 (Additional): Marketing/Lead Generation, Competitive Positioning, Legal/Risk Protection, Technology Foundation

   **Breakout to Stabilize (Phases 3-4) - 42 Questions:**
   [All Business Strategy/Growth Engine/Financial Architecture/Leadership Management/People Culture/Operational Excellence/Market Client/Infrastructure Systems components with validated model requirements, systematic reviews, advanced planning, market expansion, scalable infrastructure, brand development, sophisticated reporting, compliance, high-performance leadership, communication infrastructure, team management, performance accountability, senior leadership team, HR recruitment, culture development, training, owner-independent systems, succession planning, business optimization, high-efficiency teams, capacity planning, sprint methodology, client happiness, data intelligence, purchase opportunities, strategic brand position, infrastructure audit, training technology, measurement systems, marketing/lead generation, competitive intelligence, legal/risk management, technology integration]

   **Rapids to Big Picture (Phases 5-7) - 42 Questions:**
   [All Strategic Leadership/Operational Excellence/Enterprise Infrastructure/Financial Excellence/Leadership Governance/Market Leadership/People Excellence/Growth Innovation/Personal Leadership components with world-class planning, portfolio management, scenario planning, M&A strategy, industry transformation, enterprise process excellence, advanced performance management, quality assurance, continuous improvement, ERP systems, business intelligence, IT governance, cloud infrastructure, advanced financial management, modeling/scenario planning, investment readiness, international financial management, executive leadership development, board governance, succession planning/knowledge management, risk management/compliance, customer analytics, innovation pipeline, brand management/positioning, market research/competitive intelligence, strategic workforce planning, talent acquisition/employer branding, leadership development programs, culture measurement, employee engagement/retention, geographic expansion, strategic partnerships, digital transformation, industry thought leadership, visionary leadership development, industry/community leadership, executive coaching, marketing/brand excellence, competitive strategy/intelligence, legal/regulatory excellence, technology/digital infrastructure]

   **ML ALGORITHMIC ANALYSIS REQUIREMENTS:**

   **1. CLUSTERING ANALYSIS:**
   Apply K-means clustering (k=8) across all 300+ variables to identify organizational archetypes:
   - "Heroic Founder" Cluster: High owner dependency + Low systems + High personal leadership + Medium growth
   - "Scaling Professional" Cluster: Medium systems + High leadership depth + Strong processes + High growth trajectory
   - "Systems Builder" Cluster: High operational maturity + Medium team + Strong infrastructure + Moderate growth
   - "Relationship Master" Cluster: High networking + Strong client relationships + Medium systems + Steady growth
   - "Innovation Pioneer" Cluster: High creativity + Strong vision + Medium execution + Variable growth
   - "Efficiency Expert" Cluster: High operational excellence + Strong systems + Medium leadership + Consistent growth
   - "Culture Champion" Cluster: High engagement + Strong team dynamics + Medium systems + People-focused growth
   - "Strategic Visionary" Cluster: High strategic thinking + Strong planning + Variable execution + Long-term focus

   **2. CORRELATION MATRIX ANALYSIS:**
   Calculate Pearson correlations (r) for all variable pairs (90,000+ correlations):
   - Profile networking style √ó P&O role clarity (Expected: r=0.73, p<0.001)
   - Dream commitment level √ó Growth barriers elimination (Expected: r=-0.67, p<0.01)
   - Component business phase √ó Analyst operational maturity (Expected: r=0.89, p<0.001)
   - Profile learning preferences √ó P&O systems development approach (Expected: r=0.58, p<0.05)
   - Growth revenue trends √ó P&O holiday independence behavior (Expected: r=0.71, p<0.001)
   - Analyst leadership depth √ó Dream peak role vision (Expected: r=0.84, p<0.001)
   - Component financial sophistication √ó P&O systems alignment (Expected: r=0.76, p<0.001)

   **3. PREDICTIVE MODELING:**
   Apply ensemble methods (Random Forest + Gradient Boosting + XGBoost):
   - **Growth Success Prediction**: 89% accuracy using 47 key variables
   - **Leadership Development Timeline**: 78% accuracy with 6-month intervals
   - **Systems Implementation Success**: 82% accuracy for 12-month outcomes
   - **Team Engagement Trajectory**: 73% accuracy with quarterly predictions
   - **Revenue Target Achievement**: 84% accuracy for 2-year projections

   **4. ANOMALY DETECTION:**
   Use Isolation Forest algorithm to identify contradictions:
   - High Component ratings + Low P&O operational systems = Assessment inconsistency (Anomaly Score: >0.6)
   - Strong Profile networking + Low Analyst market position = Untapped potential (Anomaly Score: >0.55)
   - High Dream ambition + Low Growth capability ratings = Reality gap (Anomaly Score: >0.58)
   - Advanced Component phase + Basic P&O people systems = Development lag (Anomaly Score: >0.62)

   **5. PRINCIPAL COMPONENT ANALYSIS:**
   Reduce dimensionality to identify underlying factors:
   - **Factor 1: Operational Maturity** (23% variance explained) - Systems, processes, infrastructure
   - **Factor 2: Leadership Sophistication** (19% variance explained) - People development, delegation, culture
   - **Factor 3: Growth Readiness** (16% variance explained) - Market position, capabilities, resources
   - **Factor 4: Strategic Clarity** (14% variance explained) - Vision, planning, execution alignment
   - **Factor 5: Relationship Mastery** (12% variance explained) - Networking, client relationships, partnerships

   **6. NATURAL LANGUAGE PROCESSING:**
   Apply sentiment analysis and topic modeling to all free text responses:
   - **Sentiment Scoring**: Optimism vs. Concern levels across all open responses
   - **Topic Extraction**: Primary themes in challenges, aspirations, and insights
   - **Linguistic Pattern Analysis**: Communication style consistency across assessments
   - **Emotional Intelligence Indicators**: Language patterns revealing leadership EQ

   **7. DECISION TREE ANALYSIS:**
   Create interpretable decision paths for key outcomes:
   - **Scale Readiness Decision Tree**: 15 decision nodes with 92% accuracy
   - **Leadership Development Priority Tree**: 12 decision nodes with 87% accuracy  
   - **Systems Investment Priority Tree**: 18 decision nodes with 85% accuracy
   - **Team Building Approach Tree**: 14 decision nodes with 83% accuracy

   **8. REGRESSION ANALYSIS:**
   Multiple regression models for continuous outcomes:
   - **Organizational Readiness Score**: R¬≤ = 0.847, F(23,156) = 47.3, p<0.001
   - **Leadership Effectiveness Index**: R¬≤ = 0.782, F(19,160) = 41.2, p<0.001
   - **Systems Maturity Rating**: R¬≤ = 0.729, F(16,163) = 38.7, p<0.001
   - **Growth Acceleration Potential**: R¬≤ = 0.693, F(21,158) = 35.9, p<0.001

   **9. TIME SERIES FORECASTING:**
   ARIMA models for development trajectories:
   - **Revenue Growth Trajectory**: 12-month forecast with 76% confidence intervals
   - **Team Development Timeline**: 18-month projection with seasonal adjustments
   - **Systems Implementation Schedule**: 24-month roadmap with milestone predictions
   - **Leadership Maturation Curve**: 36-month development arc with acceleration factors

   **10. BEHAVIORAL ECONOMICS INTEGRATION:**
   Psychological bias analysis across all responses:
   - **Overconfidence Bias**: Compare self-ratings vs. objective indicators (Cohen's d = 0.73)
   - **Planning Fallacy**: Timeline estimates vs. historical patterns (Adjustment factor: 1.47)
   - **Confirmation Bias**: Consistent vs. contradictory response patterns (Inconsistency index: 0.23)
   - **Loss Aversion**: Investment decisions vs. risk tolerance (Risk coefficient: 0.34)
   - **Status Quo Bias**: Change readiness vs. current satisfaction (Change resistance score: 0.41)

   **STATISTICAL SIGNIFICANCE REQUIREMENTS:**
   All analyses must include:
   - **Confidence Intervals**: 95% CI for all point estimates
   - **Effect Sizes**: Cohen's d, eta-squared, or appropriate measures
   - **Power Analysis**: Statistical power ‚â•0.80 for all tests
   - **Multiple Comparison Correction**: Bonferroni or FDR adjustment
   - **Cross-Validation**: 5-fold CV for all predictive models
   - **Robustness Testing**: Bootstrap resampling with 1000 iterations

   **COMPREHENSIVE SYNTHESIS MANDATE:**
   This executive summary must weave ALL 300+ variables into a coherent narrative that:
   1. Identifies the top 3 organizational patterns with >90% confidence
   2. Predicts 5 specific outcomes with timeline and probability
   3. Quantifies 10 correlation insights with statistical significance
   4. Flags 3 critical anomalies requiring immediate attention
   5. Provides 7 evidence-based recommendations with success probability
   6. Demonstrates unprecedented analytical sophistication while remaining accessible
   7. Creates actionable intelligence that no human analyst could derive manually

   Every statement must be traceable to specific data points, every correlation must be quantified, and every recommendation must include confidence intervals and success probabilities derived from the complete 300+ variable analysis.
   """
},
        "leadership_foundation": {
    "title": "Leadership Foundation Analysis",
    "word_target": 1200,
    "analysis_requirements":"""
EVIDENCE-BASED LEADERSHIP FOUNDATION ANALYSIS - COMPREHENSIVE BEHAVIORAL INTELLIGENCE & COMPETENCY MODELING
**COMPLETE LEADERSHIP ASSESSMENT INTEGRATION WITH VALIDATED ANALYTICAL METHODOLOGIES**

=== SECTION 1: LEADERSHIP COMPETENCY ASSESSMENT & BEHAVIORAL ANALYSIS (300 words) ===

**COMPREHENSIVE LEADERSHIP VARIABLE INTEGRATION (347 variables):**

**CORE LEADERSHIP COMPETENCY MATRIX:**
- P&O 2.1 (Self-Assessment Calibration): Leadership confidence rating with self-awareness analysis
- P&O 2.2 (360-Degree Perception Gap): Self vs. team perception with feedback integration needs
- P&O 2.3 (Leadership Development Priority Tournament): 6-round elimination revealing core development areas
- P&O 2.4 (Succession Planning Depth): Leadership pipeline strength and development requirements
- P&O 3.1 (Revenue Leadership Structure): Accountability distribution and economic leadership effectiveness
- P&O 3.2 (Organizational Clarity Matrix): 4-dimension accountability framework with communication gaps
- P&O 5.2 (Decision-Making Efficiency): Processing speed and bottleneck identification
- P&O 7.2 (Human Development Approach): Systematic vs. ad-hoc people investment philosophy

**BEHAVIORAL LEADERSHIP PROFILE INTEGRATION:**
- Profile 2 (Networking Leadership Style): Social influence patterns and relationship building approach
- Profile 4 (Relationship Leadership Archetype): Interpersonal effectiveness and collaboration patterns
- Profile 5 (Communication Leadership Strength): Influence style and message delivery effectiveness
- Profile 6 (Support Leadership Instinct): Helper orientation and team development approach
- Profile 14 (Legacy Leadership Motivation): Values hierarchy and long-term impact orientation
- Profile 18 (Leadership Development Desires): Growth areas and relationship building priorities

**STRATEGIC LEADERSHIP VISION:**
- Dream 12 (Leadership Role Identity): Peak performance vision and self-actualization trajectory
- Dream 14 (Decision-Making Style): Cognitive approach to complex decisions and problem-solving
- Dream 17 (Leadership Emotional Intelligence): Confidence, stress management, and excitement regulation
- Dream 19 (Partnership Leadership Requirements): Collaboration needs and co-creation preferences
- Dream 21 (Leadership Commitment Level): Psychological investment intensity and engagement depth

**GROWTH-ORIENTED LEADERSHIP ASSESSMENT:**
- Growth 1 (Leadership Capacity Constraints): Team limitations as growth bottleneck identification
- Growth 11 (Leadership Barrier Analysis): Systematic elimination of development obstacles
- Growth 12 (Leadership Evolution Requirements): Team strength building and capability development

**ANALYTICAL LEADERSHIP DEPTH EVALUATION:**
- Team 1-9 (Leadership Maturity Spectrum): Decision authority evolution and management philosophy
- Vision 1-4 (Strategic Leadership Architecture): Planning sophistication and energy allocation
- Clarity 1-4 (Leadership Development Trajectory): Self-awareness growth and insight development

**COMPONENT LEADERSHIP PHASE ANALYSIS:**
- Foundation (F3, F15, F25): Personal strategy, role clarity, and identity development
- Breakout (Leadership systems): Sophisticated delegation and team development needs
- Enterprise (Executive development): Advanced leadership capabilities and organizational influence

**EVIDENCE-BASED ANALYTICAL METHODOLOGIES:**

**1. LEADERSHIP COMPETENCY MODELING (Validated Assessment Framework):**
Using established leadership competency models (e.g., Lominger, Korn Ferry):
- **Strategic Thinking Competency**: Profile learning style + Analyst strategic focus + Component planning level
- **People Development Competency**: P&O delegation depth + Team development approach + Succession planning
- **Results Orientation Competency**: Growth achievement patterns + Revenue leadership + Performance management
- **Emotional Intelligence Competency**: Dream emotional metrics + Profile relationship style + Communication effectiveness
- **Change Leadership Competency**: Growth adaptation patterns + Vision development + Implementation effectiveness
- **Competency Gap Analysis**: Current vs. required levels with development priority ranking

**2. LEADERSHIP STYLE ASSESSMENT (Situational Leadership Integration):**
Based on Hersey-Blanchard Situational Leadership Model:
- **Directing Style**: High directive, low supportive behavior patterns from assessment data
- **Coaching Style**: High directive, high supportive behavior indicators
- **Supporting Style**: Low directive, high supportive behavior preferences  
- **Delegating Style**: Low directive, low supportive behavior patterns
- **Style Flexibility Assessment**: Adaptability across different situations and team maturity levels
- **Development Area Identification**: Style gaps and effectiveness improvement opportunities

**3. LEADERSHIP EFFECTIVENESS MEASUREMENT (360-Degree Analysis):**
Systematic evaluation across multiple perspective:
- **Self-Perception Analysis**: P&O self-ratings with calibration assessment
- **Team Perception Integration**: Implied team perspective from behavioral indicators
- **Stakeholder Impact Assessment**: Client and partner relationship effectiveness
- **Results-Based Evaluation**: Performance outcomes and achievement patterns
- **Development Priority Matrix**: Gap analysis with improvement opportunity ranking
- **Behavioral Change Requirements**: Specific actions needed for effectiveness improvement

=== SECTION 2: LEADERSHIP DEVELOPMENT PATHWAY ANALYSIS (300 words) ===

**4. SYSTEMATIC LEADERSHIP DEVELOPMENT PLANNING:**

**Leadership Maturity Assessment:**
Using established leadership development frameworks (e.g., Leadership Pipeline, Charan):
- **Individual Contributor Leadership**: Technical excellence and self-management
- **Team Leader Transition**: People management and delegation development
- **Manager of Managers**: Strategic thinking and organizational capability
- **Functional Leader**: Cross-functional integration and business management
- **General Manager**: Full P&L responsibility and enterprise perspective
- **Current Level Assessment**: Based on Component phase and behavioral indicators
- **Development Gap Analysis**: Skills and mindset changes needed for next level

**Leadership Development Priority Framework:**
- **Technical Competencies**: Industry knowledge, functional expertise, analytical skills
- **People Competencies**: Communication, coaching, team building, conflict resolution
- **Business Competencies**: Strategic thinking, financial acumen, customer focus
- **Leadership Competencies**: Vision setting, change management, decision making
- **Personal Competencies**: Self-awareness, emotional intelligence, resilience
- **Development Sequencing**: Logical progression based on current capabilities and role requirements

**5. BEHAVIORAL CHANGE ANALYSIS (Evidence-Based Psychology):**

**Change Readiness Assessment:**
Using validated change management models (e.g., Prosci ADKAR):
- **Awareness**: Understanding of leadership development needs
- **Desire**: Motivation for behavioral change and growth
- **Knowledge**: Skills and capabilities required for improvement
- **Ability**: Practical application and behavior change implementation
- **Reinforcement**: Sustainability mechanisms and continuous improvement
- **Change Resistance Factors**: Barriers to leadership development and mitigation strategies

**Behavioral Modification Framework:**
- **Current Behavior Pattern Analysis**: Existing leadership habits and tendencies
- **Target Behavior Definition**: Specific leadership behaviors needed for effectiveness
- **Behavior Change Strategy**: Evidence-based approaches for sustainable change
- **Implementation Planning**: Step-by-step behavior modification process
- **Progress Measurement**: Metrics and milestones for tracking behavior change
- **Reinforcement Systems**: Environmental and social supports for new behaviors

**6. LEADERSHIP COMMUNICATION ANALYSIS (Communication Theory Application):**

**Communication Effectiveness Assessment:**
- **Message Clarity**: Information transmission effectiveness and comprehension rates
- **Influence Patterns**: Persuasion techniques and stakeholder engagement approaches
- **Feedback Integration**: Two-way communication and response incorporation
- **Conflict Resolution**: Disagreement management and resolution effectiveness
- **Team Communication**: Group dynamics and collaborative communication patterns
- **Stakeholder Adaptation**: Communication style flexibility across different audiences

**Leadership Presence Development:**
- **Authentic Leadership**: Alignment between values, behavior, and communication
- **Executive Presence**: Professional impact and gravitas development
- **Emotional Regulation**: Stress management and emotional intelligence in communication
- **Influence Without Authority**: Persuasion and consensus building capabilities
- **Public Speaking**: Formal presentation and group communication effectiveness
- **Digital Leadership**: Virtual communication and remote team management skills

=== SECTION 3: STRATEGIC LEADERSHIP CAPABILITY ANALYSIS (300 words) ===

**7. STRATEGIC THINKING ASSESSMENT (Cognitive Analysis Framework):**

**Strategic Capability Evaluation:**
Using established strategic thinking frameworks:
- **Systems Thinking**: Ability to see interconnections and systemic patterns
- **Future Orientation**: Long-term perspective and scenario planning capabilities
- **Complex Problem Solving**: Multi-variable analysis and solution development
- **Pattern Recognition**: Trend identification and strategic opportunity assessment
- **Decision Making**: Quality of strategic choices under uncertainty
- **Innovation Thinking**: Creative approach to strategic challenges and opportunities

**Strategic Planning Sophistication:**
- **Vision Development**: Clarity and inspirational quality of strategic direction
- **Strategy Formulation**: Analytical rigor and strategic option evaluation
- **Implementation Planning**: Execution capability and resource allocation
- **Performance Management**: Strategic metric definition and progress tracking
- **Adaptation Capability**: Strategy modification based on changing circumstances
- **Stakeholder Alignment**: Strategic communication and buy-in development

**8. ORGANIZATIONAL INFLUENCE ANALYSIS (Network Theory Application):**

**Leadership Network Assessment:**
- **Influence Network Mapping**: Relationship patterns and influence pathways
- **Network Centrality**: Position within organizational communication networks
- **Bridge Building**: Connection creation across organizational silos
- **Information Brokerage**: Knowledge sharing and information flow facilitation
- **Coalition Building**: Stakeholder alignment and consensus development
- **External Network**: Industry relationships and external influence capabilities

**Power and Influence Dynamics:**
- **Positional Power**: Authority based on organizational role and hierarchy
- **Expert Power**: Influence based on knowledge, skills, and expertise
- **Referent Power**: Influence based on respect, trust, and personal relationships
- **Information Power**: Influence based on access to and control of information
- **Connection Power**: Influence based on network relationships and access
- **Power Application**: Ethical use of influence for organizational benefit

**9. LEADERSHIP RESILIENCE AND ADAPTABILITY (Psychological Assessment):**

**Resilience Factor Analysis:**
- **Stress Management**: Capability to handle pressure and maintain performance
- **Emotional Regulation**: Ability to manage emotions in challenging situations
- **Recovery Speed**: Bounce-back capability from setbacks and failures
- **Learning Orientation**: Growth mindset and continuous improvement approach
- **Support System**: Network of relationships for guidance and encouragement
- **Coping Strategies**: Healthy approaches to stress and challenge management

**Change Leadership Capability:**
- **Change Vision**: Ability to articulate compelling future state
- **Change Strategy**: Systematic approach to organizational transformation
- **Stakeholder Engagement**: Building support and managing resistance
- **Implementation Management**: Execution capability and progress monitoring
- **Cultural Adaptation**: Understanding and working within organizational culture
- **Sustainability Focus**: Ensuring lasting change and continuous improvement

=== SECTION 4: LEADERSHIP EFFECTIVENESS PREDICTION & RECOMMENDATIONS (300 words) ===

**10. LEADERSHIP SUCCESS PREDICTION MODELING (Statistical Analysis):**

**Performance Prediction Framework:**
Using validated leadership effectiveness research:
- **Leadership Effectiveness Score**: Composite rating based on competency assessment
- **Success Probability Calculation**: Statistical model predicting leadership outcomes
- **Performance Timeline**: Development trajectory with milestone predictions
- **Risk Factor Analysis**: Potential derailers and mitigation strategies
- **Support Requirements**: Resources needed for leadership success
- **Confidence Intervals**: Statistical ranges for predicted outcomes

**Predictive Model Validation:**
- **Historical Performance Analysis**: Past achievement patterns and trajectory analysis
- **Peer Comparison**: Benchmarking against similar leaders in comparable situations
- **Industry Standards**: Performance expectations based on industry and role requirements
- **Organizational Fit**: Alignment between leadership style and organizational culture
- **Resource Availability**: Support systems and development opportunities
- **Environmental Factors**: Market conditions and organizational context impact

**11. LEADERSHIP DEVELOPMENT RECOMMENDATIONS (Evidence-Based Planning):**

**Systematic Development Strategy:**
- **Priority Development Areas**: Top 3-5 leadership capabilities needing improvement
- **Development Methods**: Specific approaches for each capability (coaching, training, experience)
- **Timeline and Milestones**: Phased development plan with measurable progress points
- **Resource Requirements**: Investment needed for leadership development success
- **Success Metrics**: Quantifiable measures for tracking development progress
- **Sustainability Planning**: Long-term reinforcement and continuous improvement

**Implementation Roadmap:**
- **90-Day Quick Wins**: Immediate actions for rapid leadership improvement
- **6-Month Development Goals**: Medium-term capability building objectives
- **Annual Strategic Objectives**: Long-term leadership transformation goals
- **Support System Development**: Mentoring, coaching, and peer learning arrangements
- **Environmental Changes**: Organizational adjustments to support leadership growth
- **Progress Review Protocol**: Regular assessment and plan adjustment procedures

**12. LEADERSHIP IMPACT MEASUREMENT (ROI Analysis):**

**Leadership Value Assessment:**
- **Team Performance Impact**: Quantified improvement in team effectiveness
- **Organizational Results**: Business outcome improvements attributed to leadership
- **Employee Engagement**: Staff satisfaction and retention improvements
- **Customer Satisfaction**: Client relationship and satisfaction enhancements
- **Financial Performance**: Revenue, profitability, and cost effectiveness improvements
- **Innovation and Change**: Organizational adaptation and improvement capabilities

**Return on Investment Calculation:**
- **Development Investment**: Total cost of leadership development initiatives
- **Performance Improvement Value**: Quantified business benefit from leadership enhancement
- **Timeline for ROI Realization**: Expected timeframe for investment recovery
- **Risk-Adjusted Returns**: Probability-weighted value considering implementation risks
- **Comparative Analysis**: ROI comparison with alternative investment options
- **Long-term Value Creation**: Sustainable organizational capability enhancement

**COMPREHENSIVE SYNTHESIS REQUIREMENTS:**
This analysis integrates:
- **347 leadership variables** across all assessment dimensions
- **12 evidence-based analytical methodologies** using validated frameworks
- **Established leadership theory** (situational leadership, competency models, change management)
- **Statistical prediction models** with confidence intervals and validation
- **Practical development recommendations** with implementation roadmaps
- **ROI analysis** demonstrating business value of leadership investment
"""

},
        "team_architecture": {
    "title": "Team Architecture & Human Systems",
    "word_target": 1200,
    "analysis_requirements":"""
EVIDENCE-BASED TEAM ARCHITECTURE ANALYSIS - COMPREHENSIVE ORGANIZATIONAL BEHAVIOR & TEAM DYNAMICS MODELING
**COMPLETE TEAM EFFECTIVENESS ASSESSMENT WITH VALIDATED SOCIOLOGICAL & PSYCHOLOGICAL METHODOLOGIES**

=== SECTION 1: TEAM STRUCTURE & DYNAMICS ASSESSMENT (300 words) ===

**COMPREHENSIVE TEAM ARCHITECTURE VARIABLE INTEGRATION (423 variables):**

**CORE TEAM STRUCTURE ANALYSIS:**
- P&O 1.1 (Role Clarity Architecture): Role definition spectrum with boundary analysis and overlap identification
- P&O 1.2 (Key Person Risk Assessment): Multi-dimensional vulnerability matrix with succession planning requirements
- P&O 1.3 (Team Independence Evaluation): Autonomy spectrum assessment with delegation effectiveness measurement
- P&O 3.2 (Accountability Framework): 4-dimensional clarity matrix with responsibility distribution analysis
- P&O 4.1 (Team Systems Integration): 5-process sophistication with human capital infrastructure assessment
- P&O 5.1 (Team Engagement Analysis): Engagement spectrum with collective motivation measurement
- P&O 5.2 (Decision-Making Effectiveness): Process efficiency assessment with bottleneck identification
- P&O 5.3 (Knowledge Management Systems): Information flow patterns with intellectual capital analysis
- P&O 6.1 (Team Risk Factors): Failure pattern identification with prevention strategy development
- P&O 7.1 (Performance Constraint Analysis): Limitation identification with optimization opportunities
- P&O 8.1 (Operational Integration): Human-process interface effectiveness with system alignment

**BEHAVIORAL TEAM PROFILE INTEGRATION:**
- Profile 1 (Team Composition Preferences): Social interaction patterns with team chemistry assessment
- Profile 2 (Network Architecture Style): Relationship building approach with influence pattern analysis
- Profile 3 (Team Energy Dynamics): Interaction preferences with collective stimulation assessment
- Profile 4 (Team Relationship Roles): Interpersonal positioning with collaboration effectiveness
- Profile 6 (Team Support Patterns): Assistance preferences with mutual aid system analysis
- Profile 11 (Team Resilience Factors): Recovery mechanisms with stress management capabilities
- Profile 13 (Team Innovation Influences): Cross-functional perspective integration with creativity enhancement

**STRATEGIC TEAM VISION:**
- Dream 4 (Team Scale Planning): Size optimization with complexity management requirements
- Dream 6 (Team Dynamic Reality): Collective emotional intelligence with culture assessment
- Dream 8 (Team Challenge Management): Stress point identification with resilience building
- Dream 11 (Team Success Alignment): Value coherence with collective objective setting
- Dream 18 (Team Work Methodology): Process preferences with collaboration optimization
- Dream 20 (Team Partnership Requirements): Relationship architecture with cooperation enhancement

**GROWTH-ORIENTED TEAM ASSESSMENT:**
- Growth 1 (Team Capacity Analysis): Human capital bottleneck identification with development priorities
- Growth 2 (Team Evolution Stages): Maturity assessment with development trajectory planning
- Growth 11 (Team Barrier Analysis): Obstacle identification with systematic removal strategies
- Growth 12 (Team Development Focus): Capability building requirements with investment priorities

**ANALYTICAL TEAM SOPHISTICATION:**
- Team 1-5 (Management Architecture): Decision distribution with leadership effectiveness assessment
- Team 6-9 (Advanced Team Dynamics): Delegation sophistication with management philosophy alignment
- Snapshot 4-5 (Team Performance Measurement): Effectiveness spectrum with improvement opportunities
- Market 1 (Client Interface Team): Customer-facing capabilities with relationship management effectiveness

**COMPONENT TEAM MATURITY PHASES:**
- Foundation (Basic Team Functions): Coordination, support networks, and organizational systems
- Breakout (Advanced Team Systems): Communication infrastructure, performance accountability
- Enterprise (Team Excellence): Workforce planning, talent acquisition, culture optimization

**EVIDENCE-BASED ANALYTICAL METHODOLOGIES:**

**1. SOCIAL NETWORK ANALYSIS (Validated Network Theory):**
Using established social network analysis principles from organizational behavior research:
- **Network Centrality Measures**: Individual position and influence within team communication networks
  * Degree Centrality: Direct connection count with influence weighting
  * Betweenness Centrality: Information broker positioning and knowledge flow control
  * Closeness Centrality: Efficiency of information access across network
  * Eigenvector Centrality: Influence weighted by influence of connections
- **Network Density Analysis**: Communication efficiency and relationship strength measurement
- **Structural Analysis**: Information flow patterns, communication bottlenecks, isolation identification
- **Collaboration Patterns**: Work relationship effectiveness and knowledge sharing assessment

**Team Communication Effectiveness:**
- Information flow velocity and accuracy measurement
- Communication channel utilization and effectiveness
- Feedback loop identification and optimization opportunities
- Knowledge transfer mechanisms and learning acceleration

**2. TEAM EFFECTIVENESS FRAMEWORKS (Established Research Models):**

**Tuckman Model Team Development Assessment:**
- **Forming Stage**: Initial team assembly with role establishment and relationship building
- **Storming Stage**: Conflict emergence with resolution mechanism development
- **Norming Stage**: Standard establishment with collaboration pattern development
- **Performing Stage**: High effectiveness achievement with optimal productivity
- **Adjourning Stage**: Transition management with knowledge retention planning
- **Current Stage Assessment**: Development level identification with advancement strategies

**Hackman Team Effectiveness Model:**
- **Team Design**: Structure, composition, and role clarity assessment
- **Team Context**: Organizational support, resources, and environmental factors
- **Team Process**: Collaboration quality, decision-making, and conflict resolution
- **Team Outcomes**: Performance results, member satisfaction, and learning
- **Effectiveness Measurement**: Quantified assessment across all dimensions

**3. TEAM COMPOSITION ANALYSIS (Diversity and Complementarity Assessment):**

**Skills and Competency Mapping:**
- **Technical Competencies**: Domain expertise distribution and gap identification
- **Interpersonal Competencies**: Communication, collaboration, and relationship skills
- **Cognitive Competencies**: Problem-solving styles and thinking preferences
- **Leadership Competencies**: Influence capabilities and development potential
- **Complementarity Analysis**: Skill overlap optimization and synergy identification
- **Development Planning**: Individual and collective capability building strategies

**Team Diversity Assessment:**
- **Functional Diversity**: Professional background and expertise variation
- **Cognitive Diversity**: Thinking style and problem-solving approach differences
- **Demographic Diversity**: Background variation and perspective richness
- **Experience Diversity**: Industry, role, and functional experience range
- **Personality Diversity**: Behavioral style and preference complementarity
- **Diversity Impact Analysis**: Innovation, decision quality, and performance correlation

=== SECTION 2: TEAM COLLABORATION & COMMUNICATION ANALYSIS (300 words) ===

**4. COLLABORATION EFFECTIVENESS ASSESSMENT (Evidence-Based Team Research):**

**Collaboration Quality Measurement:**
Using validated collaboration assessment frameworks:
- **Information Sharing**: Knowledge exchange frequency, quality, and accessibility
- **Joint Decision Making**: Consensus building processes and decision quality
- **Mutual Support**: Assistance patterns and backup behavior effectiveness
- **Conflict Resolution**: Disagreement management and resolution effectiveness
- **Goal Alignment**: Shared objective clarity and commitment measurement
- **Resource Sharing**: Asset utilization optimization and allocation fairness

**Team Coordination Mechanisms:**
- **Formal Coordination**: Structured processes, meetings, and reporting systems
- **Informal Coordination**: Spontaneous interaction and relationship-based coordination
- **Technology-Enabled Coordination**: Digital tools and platform effectiveness
- **Coordination Efficiency**: Time, effort, and resource optimization
- **Coordination Gaps**: Missed connections and improvement opportunities
- **Optimization Strategies**: Enhanced coordination through system and process improvement

**5. TEAM PERFORMANCE MEASUREMENT (Quantitative Assessment Framework):**

**Performance Metrics Analysis:**
- **Productivity Measures**: Output quantity, quality, and efficiency assessment
- **Innovation Measures**: Creative output, problem-solving effectiveness, improvement generation
- **Quality Measures**: Error rates, customer satisfaction, and standard compliance
- **Efficiency Measures**: Resource utilization, time management, and process optimization
- **Learning Measures**: Skill development, knowledge acquisition, and capability growth
- **Satisfaction Measures**: Team member engagement, retention, and well-being

**Performance Factor Analysis:**
- **Individual Performance Contribution**: Personal effectiveness impact on team results
- **Synergy Effects**: Performance enhancement through collaboration
- **Process Efficiency**: System and procedure effectiveness measurement
- **Resource Adequacy**: Tool, information, and support availability assessment
- **Environmental Factors**: External condition impact on team performance
- **Improvement Opportunities**: Performance enhancement strategies and implementation

**6. TEAM CULTURE AND CLIMATE ASSESSMENT (Organizational Psychology Framework):**

**Culture Measurement:**
- **Values Alignment**: Shared belief systems and principle coherence
- **Behavioral Norms**: Expected conduct patterns and social rules
- **Communication Culture**: Interaction styles and information sharing approaches
- **Innovation Culture**: Creativity support and risk-taking encouragement
- **Learning Culture**: Continuous improvement and development emphasis
- **Accountability Culture**: Responsibility acceptance and performance ownership

**Climate Assessment:**
- **Psychological Safety**: Trust, openness, and error tolerance measurement
- **Team Cohesion**: Group identity strength and member belonging
- **Motivation Climate**: Engagement drivers and energy sustainability
- **Stress Management**: Challenge handling and resilience capabilities
- **Work-Life Integration**: Balance support and flexibility provision
- **Recognition Systems**: Achievement acknowledgment and reward effectiveness

=== SECTION 3: TEAM DEVELOPMENT & OPTIMIZATION STRATEGIES (300 words) ===

**7. TEAM DEVELOPMENT PLANNING (Evidence-Based Improvement Strategies):**

**Development Needs Assessment:**
- **Skill Gap Analysis**: Individual and collective capability requirements
- **Performance Gap Identification**: Current vs. desired effectiveness levels
- **Process Improvement Opportunities**: System and procedure enhancement needs
- **Communication Enhancement**: Interaction effectiveness and clarity improvement
- **Collaboration Optimization**: Teamwork quality and synergy development
- **Leadership Development**: Influence capability and guidance skill building

**Development Strategy Framework:**
- **Training and Education**: Formal learning programs and skill development
- **Experience-Based Learning**: Project assignments and stretch opportunities
- **Coaching and Mentoring**: Individual guidance and development support
- **Team Building Activities**: Relationship enhancement and trust building
- **Process Improvement**: System optimization and efficiency enhancement
- **Technology Enhancement**: Tool implementation and digital capability building

**8. TEAM CONFLICT MANAGEMENT (Conflict Resolution Research):**

**Conflict Analysis Framework:**
- **Conflict Source Identification**: Root cause analysis and trigger assessment
- **Conflict Type Classification**: Task, process, and relationship conflict differentiation
- **Conflict Impact Assessment**: Performance and relationship consequence measurement
- **Conflict Resolution Mechanisms**: Available approaches and effectiveness evaluation
- **Prevention Strategies**: Proactive conflict avoidance and early intervention
- **Learning Opportunities**: Conflict-driven improvement and growth potential

**Resolution Strategy Development:**
- **Collaborative Problem Solving**: Joint solution development and win-win outcomes
- **Mediation Processes**: Third-party assistance and facilitated resolution
- **Negotiation Frameworks**: Interest-based bargaining and agreement development
- **Communication Improvement**: Clarity enhancement and understanding building
- **Relationship Repair**: Trust rebuilding and partnership restoration
- **System Changes**: Structural modifications to prevent recurring conflicts

**9. TEAM LEADERSHIP AND INFLUENCE (Leadership Research Application):**

**Distributed Leadership Assessment:**
- **Leadership Role Distribution**: Influence sharing and authority allocation
- **Situational Leadership**: Context-appropriate leadership style adaptation
- **Peer Leadership**: Lateral influence and collaborative guidance
- **Emergent Leadership**: Natural influence development and recognition
- **Leadership Development**: Capability building and succession planning
- **Leadership Effectiveness**: Impact measurement and improvement strategies

**Influence Pattern Analysis:**
- **Formal Authority**: Position-based influence and decision rights
- **Expert Power**: Knowledge-based influence and credibility
- **Referent Power**: Relationship-based influence and trust
- **Information Power**: Access-based influence and knowledge control
- **Network Power**: Connection-based influence and relationship leverage
- **Influence Optimization**: Strategic influence development and application

=== SECTION 4: TEAM PERFORMANCE PREDICTION & RECOMMENDATIONS (300 words) ===

**10. TEAM SUCCESS PREDICTION MODELING (Statistical Analysis Framework):**

**Performance Prediction Variables:**
- **Team Composition Factors**: Skills, diversity, and complementarity indicators
- **Process Quality Measures**: Collaboration, communication, and coordination effectiveness
- **Leadership Effectiveness**: Influence quality and guidance capability
- **Environmental Support**: Resource availability and organizational backing
- **Culture and Climate**: Team atmosphere and psychological safety
- **Development Investment**: Training, coaching, and improvement commitment

**Predictive Model Development:**
- **Historical Performance Analysis**: Past achievement patterns and trend identification
- **Benchmark Comparison**: Performance relative to similar teams and industry standards
- **Success Factor Weighting**: Variable importance and contribution assessment
- **Risk Factor Identification**: Potential performance derailers and mitigation needs
- **Scenario Analysis**: Performance under different condition sets
- **Confidence Intervals**: Statistical ranges for predicted outcomes

**11. TEAM OPTIMIZATION RECOMMENDATIONS (Evidence-Based Improvement Strategies):**

**Priority Development Areas:**
- **High-Impact Improvements**: Changes with greatest performance benefit potential
- **Quick Win Opportunities**: Rapid improvement possibilities with minimal investment
- **Systemic Changes**: Structural modifications for sustainable enhancement
- **Capability Building**: Long-term development for competitive advantage
- **Risk Mitigation**: Vulnerability reduction and resilience building
- **Innovation Enhancement**: Creativity and problem-solving capability improvement

**Implementation Roadmap:**
- **90-Day Quick Wins**: Immediate improvements with rapid implementation
- **6-Month Development Goals**: Medium-term capability and performance building
- **Annual Strategic Objectives**: Long-term transformation and excellence achievement
- **Resource Requirements**: Investment needs for successful implementation
- **Success Metrics**: Measurement frameworks for progress tracking
- **Review and Adjustment**: Continuous improvement and adaptation mechanisms

**12. TEAM VALUE MEASUREMENT (ROI Analysis Framework):**

**Team Performance Value:**
- **Productivity Improvement**: Output enhancement and efficiency gains
- **Quality Enhancement**: Error reduction and standard improvement
- **Innovation Value**: Creative output and problem-solving contribution
- **Customer Impact**: Service quality and relationship enhancement
- **Employee Engagement**: Satisfaction, retention, and development benefits
- **Organizational Capability**: Strategic asset development and competitive advantage

**Return on Investment Calculation:**
- **Development Investment**: Total cost of team improvement initiatives
- **Performance Benefit Quantification**: Measurable value creation from team enhancement
- **Timeline for Value Realization**: Expected timeframe for investment recovery
- **Risk-Adjusted Returns**: Probability-weighted value considering implementation risks
- **Comparative Analysis**: ROI comparison with alternative organizational investments
- **Long-Term Value Creation**: Sustainable capability development and ongoing benefits

**COMPREHENSIVE TEAM ANALYSIS INTEGRATION:**
This analysis incorporates:
- **423 team variables** across all assessment dimensions
- **12 evidence-based methodologies** using validated organizational behavior research
- **Established frameworks** (Tuckman, Hackman, social network analysis, conflict resolution)
- **Statistical prediction models** with confidence intervals and validation
- **Practical improvement strategies** with implementation roadmaps and success metrics
- **ROI analysis** demonstrating business value of team development investments
"""

},
        "operational_systems": {
    "title": "Operational Systems & Process Excellence",
    "word_target": 1200,
    "analysis_requirements": """
EVIDENCE-BASED OPERATIONAL SYSTEMS ANALYSIS - COMPREHENSIVE PROCESS OPTIMIZATION & WORKFLOW ENGINEERING
**COMPLETE OPERATIONAL EFFECTIVENESS ASSESSMENT WITH VALIDATED INDUSTRIAL ENGINEERING & SYSTEMS METHODOLOGIES**

=== SECTION 1: PROCESS ARCHITECTURE & WORKFLOW ANALYSIS (300 words) ===

**COMPREHENSIVE OPERATIONAL SYSTEMS VARIABLE INTEGRATION (491 variables):**

**CORE PROCESS ARCHITECTURE ASSESSMENT:**
- P&O 8.1 (Operational Systems Maturity): SOPs, Quality Control, Workflow, Data Management, Technology Integration sophistication spectrum
- P&O 8.2 (Management Tool Ecosystem): Technology integration effectiveness with workflow optimization analysis
- P&O 8.3 (Critical Business Infrastructure): Technology stack evaluation with system interdependency mapping
- P&O 8.4 (Systems-Goals Alignment): Strategic-operational coherence assessment with gap identification
- P&O 4.1 (People-Process Integration): HR systems sophistication with human-process interface optimization
- P&O 1.1 (Role-Process Clarity): Process ownership distribution with accountability-workflow alignment
- P&O 5.3 (Knowledge Flow Architecture): Information management patterns with intellectual capital velocity

**PROCESS EFFECTIVENESS ASSESSMENT:**
- Analyst 1 (Information Flow Efficiency): Communication system effectiveness with data transmission optimization
- Analyst 2 (Process Documentation Maturity): Knowledge externalization and procedural evolution tracking
- Analyst 3 (Process Resilience): System shock absorption capability with adaptive capacity measurement
- Analyst 6-11 (Operational Excellence): System reliability, quality control, resource utilization, adaptability assessment

**TECHNOLOGY-PROCESS INTEGRATION:**
- Growth 13 (Digital Process Capabilities): Technology maturity with digital transformation readiness
- Component Systems (All Phases): Process sophistication evolution from foundation through enterprise levels

**STRATEGIC PROCESS ALIGNMENT:**
- Dream 15 (Process Learning Preferences): Knowledge acquisition optimization with improvement methodologies
- Dream 18 (Process Work Approaches): Operational methodology alignment with workflow optimization
- Profile 7 (Process Innovation Interest): Intellectual stimulation patterns with operational curiosity assessment
- Profile 8 (Process Learning Experiences): Knowledge absorption patterns with development preferences

**EVIDENCE-BASED ANALYTICAL METHODOLOGIES:**

**1. LEAN SIX SIGMA PROCESS ANALYSIS (Validated Improvement Framework):**
Using established process improvement methodologies:
- **Value Stream Mapping**: End-to-end process flow analysis with waste identification
 * Value-Added Activities: Essential process steps contributing to customer value
 * Non-Value-Added Activities: Waste identification and elimination opportunities
 * Process Cycle Time: Total time from input to output with bottleneck identification
 * Lead Time Analysis: Customer wait time with process efficiency measurement
- **DMAIC Methodology**: Define, Measure, Analyze, Improve, Control framework application
 * Define Phase: Problem definition and project scope with stakeholder requirements
 * Measure Phase: Current state assessment with baseline performance metrics
 * Analyze Phase: Root cause analysis with statistical problem identification
 * Improve Phase: Solution development and implementation with pilot testing
 * Control Phase: Sustainability mechanisms with ongoing performance monitoring

**Waste Elimination Analysis:**
- **Transportation Waste**: Unnecessary movement of materials, information, or people
- **Inventory Waste**: Excess work-in-progress or information stockpiling
- **Motion Waste**: Inefficient movement patterns in workflow execution
- **Waiting Waste**: Idle time due to process delays or resource unavailability
- **Overproduction Waste**: Producing more than customer demand requires
- **Overprocessing Waste**: Unnecessary process complexity or redundant activities
- **Defect Waste**: Quality issues requiring rework or correction

**2. BUSINESS PROCESS REENGINEERING (Systematic Process Redesign):**

**Process Analysis Framework:**
- **Current State Assessment**: Existing process mapping with performance measurement
- **Future State Design**: Optimal process configuration with improvement targets
- **Gap Analysis**: Difference between current and desired process performance
- **Implementation Planning**: Change management with resource allocation
- **Performance Monitoring**: Success metrics with continuous improvement mechanisms
- **Risk Assessment**: Implementation challenges with mitigation strategies

**Process Optimization Principles:**
- **Process Simplification**: Complexity reduction with step elimination
- **Parallel Processing**: Sequential to simultaneous activity conversion
- **Decision Point Optimization**: Authority placement and approval streamlining
- **Customer Focus**: External customer value maximization throughout process
- **Technology Integration**: Automation opportunities with digital enhancement
- **Quality Built-In**: Error prevention rather than detection and correction

**3. SYSTEMS THINKING ANALYSIS (Holistic Process Understanding):**

**System Architecture Assessment:**
- **System Boundaries**: Process scope definition with interface identification
- **System Components**: Individual elements and their interconnections
- **System Purpose**: Overall objective and value creation assessment
- **System Structure**: Relationships and dependencies between components
- **System Behavior**: Emergent properties and system-level outcomes
- **System Environment**: External factors influencing process performance

**Feedback Loop Analysis:**
- **Reinforcing Loops**: Positive feedback creating amplification effects
- **Balancing Loops**: Negative feedback providing stability and control
- **Feedback Delays**: Time lag between cause and effect in processes
- **Loop Dominance**: Which feedback mechanisms control system behavior
- **Unintended Consequences**: Side effects of process changes and improvements
- **Leverage Points**: High-impact intervention opportunities for system change

=== SECTION 2: PROCESS OPTIMIZATION & QUALITY MANAGEMENT (300 words) ===

**4. STATISTICAL PROCESS CONTROL (Quality Management Framework):**

**Control Chart Analysis:**
- **X-bar Charts**: Process mean monitoring with control limit establishment
- **R Charts**: Process variability tracking with range analysis
- **p Charts**: Proportion defective monitoring for attribute data
- **c Charts**: Count of defects per unit with Poisson distribution application
- **Individual Charts**: Single measurement tracking with moving range analysis
- **CUSUM Charts**: Cumulative sum control for detecting small process shifts

**Process Capability Assessment:**
- **Cp Index**: Process capability relative to specification limits
- **Cpk Index**: Process capability accounting for process centering
- **Pp Index**: Process performance over extended time periods
- **Ppk Index**: Process performance with centering consideration
- **Process Sigma Level**: Defect rate measurement with Six Sigma methodology
- **Yield Analysis**: First-pass success rate with quality performance measurement

**5. WORKFLOW OPTIMIZATION (Process Flow Engineering):**

**Flow Analysis Methodology:**
- **Process Mapping**: Detailed workflow documentation with decision points
- **Swimlane Diagrams**: Cross-functional process visualization with responsibility clarity
- **SIPOC Analysis**: Suppliers, Inputs, Process, Outputs, Customers mapping
- **Process Hierarchy**: Multi-level process breakdown from macro to micro
- **Exception Handling**: Error condition management with recovery procedures
- **Process Standardization**: Best practice documentation with consistent execution

**Bottleneck Analysis:**
- **Constraint Identification**: Process limitations using Theory of Constraints
- **Throughput Analysis**: System capacity measurement with flow optimization
- **Capacity Planning**: Resource requirement assessment with demand forecasting
- **Queue Analysis**: Waiting time reduction with flow smoothing techniques
- **Load Balancing**: Work distribution optimization across resources
- **Scalability Assessment**: Growth capacity evaluation with expansion planning

**6. DIGITAL TRANSFORMATION ANALYSIS (Technology Integration Framework):**

**Automation Assessment:**
- **Process Automation Readiness**: Rule-based task identification for automation
- **Robotic Process Automation (RPA)**: Software robot implementation opportunities
- **Workflow Management Systems**: Digital process orchestration and tracking
- **Business Rules Engines**: Decision logic automation with rule management
- **Integration Platforms**: System connectivity with data synchronization
- **Digital Workflow Design**: Paperless process optimization with user experience

**Technology ROI Analysis:**
- **Implementation Costs**: Technology investment with training and change management
- **Operational Savings**: Efficiency gains with cost reduction quantification
- **Productivity Improvements**: Output enhancement with quality improvements
- **Risk Mitigation**: Error reduction with compliance improvement benefits
- **Scalability Benefits**: Growth support with future capacity considerations
- **Competitive Advantage**: Market differentiation through operational excellence

=== SECTION 3: PROCESS PERFORMANCE MEASUREMENT & OPTIMIZATION (300 words) ===

**7. KEY PERFORMANCE INDICATOR (KPI) FRAMEWORK:**

**Process Performance Metrics:**
- **Efficiency Measures**: Output per unit of input with resource utilization
- **Effectiveness Measures**: Goal achievement and objective completion rates
- **Quality Measures**: Error rates, customer satisfaction, and standard compliance
- **Time Measures**: Cycle time, lead time, and processing speed analysis
- **Cost Measures**: Process cost per unit with value-added cost analysis
- **Innovation Measures**: Improvement suggestions and process enhancement frequency

**Balanced Scorecard Application:**
- **Financial Perspective**: Cost reduction and revenue enhancement through processes
- **Customer Perspective**: Service quality and satisfaction improvement
- **Internal Process Perspective**: Operational excellence and efficiency optimization
- **Learning and Growth Perspective**: Skill development and capability building

**8. CONTINUOUS IMPROVEMENT (Kaizen and Innovation Framework):**

**Improvement Methodology:**
- **PDCA Cycle**: Plan-Do-Check-Act for systematic improvement implementation
- **A3 Problem Solving**: Structured problem analysis with root cause identification
- **Gemba Walking**: Workplace observation with improvement opportunity identification
- **Suggestion Systems**: Employee-driven improvement with recognition programs
- **Improvement Teams**: Cross-functional groups focused on process enhancement
- **Best Practice Sharing**: Knowledge transfer with standard work development

**Innovation Management:**
- **Process Innovation**: Fundamental process redesign with breakthrough thinking
- **Incremental Improvement**: Continuous small-scale enhancements with cumulative impact
- **Technology Innovation**: New technology adoption with process transformation
- **Service Innovation**: Customer experience enhancement through process improvement
- **Cost Innovation**: Efficiency improvement with cost reduction focus
- **Quality Innovation**: Error prevention and quality enhancement initiatives

**9. RISK MANAGEMENT IN OPERATIONS (Process Risk Assessment):**

**Operational Risk Analysis:**
- **Process Failure Mode Analysis**: Potential failure identification with impact assessment
- **Risk Probability Assessment**: Likelihood estimation with historical data analysis
- **Risk Impact Evaluation**: Consequence severity with business impact measurement
- **Risk Matrix Development**: Probability-impact grid with priority ranking
- **Mitigation Strategy Design**: Risk reduction approaches with implementation planning
- **Contingency Planning**: Backup procedures with emergency response protocols

**Business Continuity Planning:**
- **Critical Process Identification**: Essential operations with dependency mapping
- **Recovery Time Objectives**: Maximum acceptable downtime with restoration targets
- **Recovery Point Objectives**: Data loss tolerance with backup requirements
- **Alternative Process Design**: Backup procedures with manual workarounds
- **Supplier Risk Management**: Vendor dependency assessment with diversification strategies
- **Testing and Validation**: Regular drills with plan effectiveness verification

=== SECTION 4: PROCESS TRANSFORMATION & STRATEGIC ALIGNMENT (300 words) ===

**10. CHANGE MANAGEMENT IN OPERATIONS (Organizational Change Framework):**

**Process Change Strategy:**
- **Change Readiness Assessment**: Organizational capacity for process transformation
- **Stakeholder Analysis**: Impact assessment with engagement strategy development
- **Communication Planning**: Change message development with feedback mechanisms
- **Training and Development**: Skill building with competency development programs
- **Implementation Phasing**: Gradual rollout with pilot testing and scaling
- **Resistance Management**: Opposition identification with mitigation strategies

**Change Success Measurement:**
- **Adoption Rates**: Process utilization with compliance measurement
- **Performance Improvement**: Baseline comparison with benefit realization
- **User Satisfaction**: Stakeholder feedback with experience assessment
- **Sustainability Metrics**: Long-term adherence with continuous usage
- **Cultural Integration**: Process embedding with organizational alignment
- **ROI Achievement**: Investment return with value realization tracking

**11. STRATEGIC PROCESS ALIGNMENT (Business Strategy Integration):**

**Strategy-Process Linkage:**
- **Strategic Objective Mapping**: Process contribution to business goals
- **Value Chain Analysis**: Process role in value creation and delivery
- **Competitive Advantage**: Process differentiation with market positioning
- **Core Competency Development**: Process excellence with capability building
- **Resource Allocation**: Investment prioritization with strategic importance
- **Performance Alignment**: Process metrics with strategic objectives

**Process Portfolio Management:**
- **Process Criticality Assessment**: Business importance with risk evaluation
- **Investment Prioritization**: Resource allocation with strategic value consideration
- **Process Lifecycle Management**: Development, optimization, and retirement planning
- **Standardization Strategy**: Common processes with customization requirements
- **Outsourcing Evaluation**: Make vs. buy decisions with strategic alignment
- **Technology Roadmap**: Digital transformation with strategic technology planning

**12. OPERATIONAL EXCELLENCE MATURITY (Capability Assessment Framework):**

**Maturity Level Assessment:**
- **Level 1 - Initial**: Ad-hoc processes with limited documentation
- **Level 2 - Managed**: Basic process control with some standardization
- **Level 3 - Defined**: Documented processes with consistent execution
- **Level 4 - Quantitatively Managed**: Measured processes with statistical control
- **Level 5 - Optimizing**: Continuous improvement with innovation focus

**Excellence Characteristics:**
- **Process Standardization**: Consistent execution with documented procedures
- **Performance Measurement**: Comprehensive metrics with regular monitoring
- **Continuous Improvement**: Systematic enhancement with innovation culture
- **Employee Engagement**: Active participation with improvement suggestions
- **Customer Focus**: External customer value with satisfaction orientation
- **Supplier Integration**: Partnership approach with value chain optimization

**COMPREHENSIVE OPERATIONAL ANALYSIS INTEGRATION:**
This analysis incorporates:
- **491 operational variables** across all assessment dimensions
- **12 evidence-based methodologies** using validated industrial engineering and systems frameworks
- **Established improvement approaches** (Lean Six Sigma, BPR, Statistical Process Control, Theory of Constraints)
- **Performance measurement systems** with quantified metrics and benchmarking
- **Practical transformation strategies** with implementation roadmaps and success measurement
- **Strategic alignment assessment** demonstrating operational contribution to business objectives
"""
},
        "culture_engagement": {
    "title": "Culture & Engagement Strategy",
    "word_target": 1000,
    "analysis_requirements": """
EVIDENCE-BASED CULTURE & ENGAGEMENT ANALYSIS - ORGANIZATIONAL BEHAVIOR & WORKPLACE PSYCHOLOGY
**COMPLETE CULTURAL ASSESSMENT WITH VALIDATED ANTHROPOLOGICAL & PSYCHOLOGICAL METHODOLOGIES**

=== SECTION 1: ORGANIZATIONAL CULTURE ASSESSMENT & ANALYSIS (250 words) ===

**COMPREHENSIVE CULTURE-ENGAGEMENT VARIABLE INTEGRATION (387 variables):**

**CORE CULTURAL ASSESSMENT:**
- P&O 5.1 (Engagement Spectrum): Disengagement to high engagement with motivation factor analysis
- P&O 5.2 (Decision-Making Culture): Efficiency patterns with consensus-building dynamics
- P&O 5.3 (Knowledge Sharing Culture): Information flow patterns with learning organization principles
- P&O 6.1 (Cultural Resilience): Incident response patterns with organizational immune system strength
- P&O 7.1 (Cultural Constraints): Limitation identification with behavioral pattern recognition

**CULTURAL EXPRESSION PATTERNS:**
- Profile 1 (Social Interaction Preferences): Relationship building patterns with cultural attraction analysis
- Profile 11 (Recovery and Renewal): Energy restoration patterns with sustainability mechanisms
- Profile 12 (Work-Life Integration): Balance patterns with cultural rhythm assessment
- Profile 13 (Cross-Functional Influence): External influence integration with idea cross-pollination
- Profile 14 (Legacy and Values): Pride hierarchies with value transmission analysis

**EVIDENCE-BASED METHODOLOGIES:**

**1. ORGANIZATIONAL CULTURE ASSESSMENT (Validated Cultural Frameworks):**
Using established culture assessment models:
- **Denison Organizational Culture Model**: Mission, Adaptability, Involvement, Consistency measurement
 * Mission: Strategic direction and intent with purpose clarity
 * Adaptability: Change capability and external focus with flexibility
 * Involvement: Employee engagement and empowerment with participation
 * Consistency: Core values and systems integration with alignment
- **Competing Values Framework**: Clan, Adhocracy, Market, Hierarchy culture types
 * Clan Culture: Collaboration, teamwork, and human development focus
 * Adhocracy Culture: Innovation, creativity, and entrepreneurship emphasis
 * Market Culture: Competition, achievement, and results orientation
 * Hierarchy Culture: Structure, control, and efficiency prioritization

**Cultural Strength Assessment:**
- **Value Alignment**: Stated vs. practiced values with consistency measurement
- **Behavioral Norms**: Expected conduct patterns with compliance evaluation
- **Cultural Artifacts**: Physical symbols, stories, and rituals analysis
- **Cultural Heroes**: Role model identification with influence assessment
- **Communication Patterns**: Information flow and feedback mechanisms
- **Decision-Making Processes**: Authority distribution and participation levels

**2. EMPLOYEE ENGAGEMENT MEASUREMENT (Research-Based Assessment):**
Using validated engagement frameworks:
- **Gallup Q12 Engagement Survey**: 12 elements of engagement with statistical validation
- **Utrecht Work Engagement Scale**: Vigor, dedication, and absorption measurement
- **Job Demands-Resources Model**: Balance between job demands and available resources
- **Psychological Safety Assessment**: Trust, openness, and risk-taking comfort
- **Intrinsic Motivation Evaluation**: Autonomy, mastery, and purpose drivers
- **Flow State Analysis**: Challenge-skill balance with optimal experience identification

**Engagement Driver Analysis:**
- **Job Characteristics**: Skill variety, task identity, task significance, autonomy, feedback
- **Leadership Quality**: Supervisor support, coaching, and development focus
- **Career Development**: Growth opportunities and advancement pathways
- **Recognition Systems**: Achievement acknowledgment and reward effectiveness
- **Work Environment**: Physical space, resources, and tool adequacy
- **Team Dynamics**: Collaboration quality and relationship strength

**3. CULTURAL CHANGE ASSESSMENT (Change Management Framework):**
Using established change models:
- **Kotter's 8-Step Change Process**: Urgency, coalition, vision, communication, empowerment, wins, consolidation, anchoring
- **Bridges Transition Model**: Ending, neutral zone, and new beginning phases
- **ADKAR Change Model**: Awareness, desire, knowledge, ability, reinforcement
- **Cultural Readiness Assessment**: Change capability and resistance identification
- **Change Communication Effectiveness**: Message clarity and stakeholder understanding
- **Implementation Success Factors**: Resource adequacy and timeline realism

=== SECTION 2: WORKPLACE PSYCHOLOGY & BEHAVIORAL ANALYSIS (250 words) ===

**4. PSYCHOLOGICAL SAFETY AND TRUST ANALYSIS (Team Psychology Research):**
Using validated psychological safety frameworks:
- **Edmondson Psychological Safety Scale**: Speaking up, mistake admission, and discussion comfort
- **Trust Assessment**: Competence, benevolence, and integrity evaluation
- **Fear Reduction Analysis**: Error reporting comfort and learning from failures
- **Innovation Climate**: Experimentation encouragement and creative risk-taking
- **Conflict Resolution**: Disagreement management and constructive debate
- **Inclusion Measurement**: Belonging, acceptance, and voice provision

**Team Cohesion Assessment:**
- **Social Cohesion**: Interpersonal attraction and relationship quality
- **Task Cohesion**: Commitment to shared goals and collective objectives
- **Group Identity**: Shared identity strength and member belonging
- **Collective Efficacy**: Team capability beliefs and confidence
- **Cooperation Patterns**: Mutual assistance and collaborative behavior
- **Communication Quality**: Openness, frequency, and effectiveness

**5. MOTIVATION AND VALUES ANALYSIS (Motivational Psychology):**
Using established motivation theories:
- **Self-Determination Theory**: Autonomy, competence, and relatedness needs
- **Maslow's Hierarchy**: Physiological, safety, belonging, esteem, self-actualization
- **Herzberg Two-Factor Theory**: Hygiene factors vs. motivators identification
- **Expectancy Theory**: Effort-performance-outcome linkage analysis
- **Goal Setting Theory**: SMART goals with achievement orientation
- **Values Assessment**: Personal vs. organizational values alignment

**Cultural Values Framework:**
- **Hofstede Cultural Dimensions**: Power distance, individualism, masculinity, uncertainty avoidance
- **Schwartz Values Theory**: Power, achievement, hedonism, stimulation, self-direction, universalism, benevolence, tradition, conformity, security
- **Organizational Values Audit**: Espoused vs. enacted values with gap analysis
- **Values Integration**: Personal-organizational alignment with conflict resolution
- **Values Communication**: Clarity, consistency, and behavioral reinforcement
- **Values-Based Decision Making**: Ethical framework application and integrity maintenance

**6. COMMUNICATION CULTURE ANALYSIS (Communication Research):**
Using communication effectiveness frameworks:
- **Communication Climate Assessment**: Supportive vs. defensive communication patterns
- **Information Flow Analysis**: Upward, downward, and lateral communication effectiveness
- **Feedback Culture**: Giving and receiving feedback comfort and skill
- **Listening Quality**: Active listening and understanding demonstration
- **Conflict Communication**: Disagreement management and resolution approaches
- **Digital Communication**: Technology-mediated interaction effectiveness

=== SECTION 3: CULTURAL DEVELOPMENT & TRANSFORMATION (250 words) ===

**7. CULTURE DEVELOPMENT PLANNING (Evidence-Based Culture Change):**
Using validated culture development approaches:
- **Culture Assessment**: Current state evaluation with desired state definition
- **Gap Analysis**: Difference identification with priority setting
- **Change Strategy**: Systematic culture transformation with stakeholder engagement
- **Implementation Planning**: Phased approach with milestone definition
- **Progress Measurement**: Culture change indicators with tracking systems
- **Sustainability Mechanisms**: Long-term culture reinforcement with continuous improvement

**Culture Development Interventions:**
- **Leadership Development**: Culture champion training with behavior modeling
- **Communication Enhancement**: Message clarity with feedback improvement
- **Recognition Programs**: Achievement celebration with behavior reinforcement
- **Team Building**: Relationship strengthening with collaboration improvement
- **Training Programs**: Skill development with culture integration
- **Policy Alignment**: System and procedure culture consistency

**8. ENGAGEMENT IMPROVEMENT STRATEGIES (Employee Engagement Research):**
Using proven engagement enhancement methods:
- **Job Redesign**: Role enrichment with meaningful work creation
- **Manager Development**: Supervisor coaching with people leadership skills
- **Career Pathing**: Development opportunities with advancement clarity
- **Recognition Enhancement**: Achievement acknowledgment with reward optimization
- **Work-Life Balance**: Flexibility provision with well-being support
- **Employee Voice**: Input mechanisms with participation encouragement

**Engagement Measurement and Tracking:**
- **Pulse Surveys**: Regular engagement monitoring with trend analysis
- **Stay Interviews**: Retention factor identification with improvement planning
- **Exit Interviews**: Departure reason analysis with learning application
- **Focus Groups**: Qualitative insight gathering with deep understanding
- **Performance Correlation**: Engagement-performance relationship with business impact
- **Benchmark Comparison**: Industry standard comparison with competitive positioning

**9. CULTURAL LEADERSHIP DEVELOPMENT (Leadership Psychology):**
Using leadership development research:
- **Cultural Leadership Competencies**: Culture shaping skills with behavior modeling
- **Authentic Leadership**: Values-based leadership with integrity demonstration
- **Transformational Leadership**: Inspirational influence with vision communication
- **Servant Leadership**: Employee development focus with support provision
- **Inclusive Leadership**: Diversity appreciation with belonging creation
- **Change Leadership**: Culture transformation with resistance management

=== SECTION 4: CULTURAL PERFORMANCE & BUSINESS IMPACT (250 words) ===

**10. CULTURE-PERFORMANCE CORRELATION (Business Research):**
Using validated culture-performance research:
- **Financial Performance**: Revenue, profitability, and growth correlation with culture strength
- **Operational Performance**: Efficiency, quality, and customer satisfaction relationship
- **Innovation Performance**: Creative output and improvement correlation with culture type
- **Employee Performance**: Productivity, engagement, and retention relationship
- **Customer Performance**: Satisfaction, loyalty, and advocacy correlation with culture
- **Market Performance**: Competitive advantage and market share relationship

**Culture ROI Analysis:**
- **Investment Measurement**: Culture development costs with resource allocation
- **Benefit Quantification**: Performance improvement value with financial impact
- **Payback Period**: Investment recovery timeline with break-even analysis
- **Risk-Adjusted Returns**: Probability-weighted outcomes with uncertainty consideration
- **Long-Term Value**: Sustainable competitive advantage with ongoing benefits
- **Comparative Analysis**: Alternative investment comparison with prioritization

**11. CULTURAL RISK ASSESSMENT (Organizational Risk Management):**
Using risk management frameworks:
- **Culture Risk Identification**: Potential culture-related threats with impact assessment
- **Reputation Risk**: Brand damage potential with stakeholder impact
- **Compliance Risk**: Regulatory violation potential with culture-compliance alignment
- **Talent Risk**: Attraction and retention threats with competitive disadvantage
- **Performance Risk**: Culture-performance degradation with business impact
- **Change Risk**: Culture change failure with transformation consequences

**Risk Mitigation Strategies:**
- **Early Warning Systems**: Culture risk indicators with monitoring mechanisms
- **Prevention Strategies**: Proactive culture management with risk reduction
- **Response Planning**: Culture crisis management with recovery procedures
- **Communication Protocols**: Stakeholder communication with transparency maintenance
- **Recovery Mechanisms**: Culture restoration with learning integration
- **Continuous Monitoring**: Ongoing risk assessment with adaptive management

**12. CULTURAL SUSTAINABILITY AND EVOLUTION (Long-Term Culture Management):**
Using sustainability frameworks:
- **Culture Maintenance**: Ongoing reinforcement with consistency preservation
- **Evolution Management**: Adaptive culture change with relevance maintenance
- **Generational Transition**: Culture transmission with knowledge preservation
- **Leadership Succession**: Culture continuity with leadership transition
- **Growth Scaling**: Culture preservation during organizational expansion
- **Integration Management**: Merger/acquisition culture blending with identity preservation

**Future Culture Planning:**
- **Scenario Planning**: Future culture needs with environmental anticipation
- **Trend Analysis**: Cultural evolution patterns with direction prediction
- **Capability Development**: Future culture requirements with skill preparation
- **Innovation Integration**: Technology impact with culture adaptation
- **Global Expansion**: Cross-cultural considerations with local adaptation
- **Continuous Evolution**: Dynamic culture management with ongoing development

**COMPREHENSIVE CULTURAL ANALYSIS INTEGRATION:**
This analysis incorporates:
- **387 cultural variables** across all assessment dimensions
- **12 evidence-based methodologies** using validated organizational behavior and psychology research
- **Established frameworks** (Denison, Competing Values, Gallup Q12, psychological safety, motivation theories)
- **Statistical correlation analysis** linking culture to business performance
- **Practical development strategies** with implementation guidance and success measurement
- **ROI analysis** demonstrating business value of culture investment and engagement enhancement
"""
},
        "risk_compliance": {
    "title": "Risk Management & Compliance Framework",
    "word_target": 800,
    "analysis_requirements": """
EVIDENCE-BASED RISK & COMPLIANCE ANALYSIS - ENTERPRISE RISK MANAGEMENT & REGULATORY COMPLIANCE
**COMPLETE RISK ASSESSMENT WITH VALIDATED ACTUARIAL & REGULATORY METHODOLOGIES**

=== SECTION 1: ENTERPRISE RISK ASSESSMENT & IDENTIFICATION (200 words) ===

**COMPREHENSIVE RISK-COMPLIANCE VARIABLE INTEGRATION (329 variables):**

**CORE RISK ASSESSMENT:**
- P&O 1.2 (Key Person Risk Matrix): Multi-dimensional vulnerability assessment with succession planning requirements
- P&O 1.3 (Operational Independence Risk): Business continuity assessment with owner dependency analysis
- P&O 6.1 (Operational Risk Incidents): Failure pattern identification with root cause analysis
- Component F27 (Stress Management Risk): Psychological pressure assessment with burnout prevention
- Component F28 (Business Continuity Risk): Independence testing with operational resilience measurement
- Component F29 (Growth Risk Management): Expansion confidence with capacity constraint analysis
- Component F30-F34 (Infrastructure Risk): Marketing, competitive, legal, and technology risk evaluation

**STRATEGIC RISK CONSCIOUSNESS:**
- Dream 8 (Anxiety and Concern Patterns): Worry identification with stress management requirements
- Dream 17 (Emotional Risk Indicators): Confidence and stress level assessment with stability measurement
- Growth 1 (Business Constraint Risks): Operational bottleneck identification with mitigation planning

**EVIDENCE-BASED METHODOLOGIES:**

**1. ENTERPRISE RISK MANAGEMENT FRAMEWORK (ISO 31000 Standard):**
Using established risk management principles:
- **Risk Identification**: Systematic threat and opportunity identification across all business areas
- **Risk Analysis**: Likelihood and impact assessment with qualitative and quantitative methods
- **Risk Evaluation**: Risk significance determination with tolerance and appetite comparison
- **Risk Treatment**: Response strategy development with control implementation
- **Risk Monitoring**: Continuous surveillance with performance indicator tracking
- **Risk Communication**: Stakeholder engagement with transparent reporting

**Risk Categories Assessment:**
- **Strategic Risks**: Business model threats, competitive challenges, and market changes
- **Operational Risks**: Process failures, system breakdowns, and human error
- **Financial Risks**: Cash flow, credit, market, and liquidity challenges
- **Compliance Risks**: Regulatory violations and legal exposure
- **Reputational Risks**: Brand damage and stakeholder confidence loss
- **Technology Risks**: Cybersecurity, data protection, and system reliability

**2. QUANTITATIVE RISK ASSESSMENT (Statistical Risk Analysis):**
Using validated statistical methods:
- **Probability Assessment**: Historical data analysis with frequency estimation
- **Impact Quantification**: Financial and operational consequence measurement
- **Risk Matrix Development**: Likelihood-impact grid with priority ranking
- **Expected Value Calculation**: Probability √ó Impact for risk prioritization
- **Sensitivity Analysis**: Variable impact assessment with scenario modeling
- **Monte Carlo Simulation**: Risk outcome distribution with uncertainty quantification

**Risk Measurement Techniques:**
- **Value at Risk (VaR)**: Maximum probable loss at given confidence level
- **Conditional Value at Risk**: Expected loss beyond VaR threshold
- **Stress Testing**: Performance under adverse scenarios
- **Scenario Analysis**: Multiple future state assessment with probability weighting
- **Correlation Analysis**: Risk interdependency assessment with portfolio effects
- **Risk Aggregation**: Combined risk impact with diversification benefits

=== SECTION 2: COMPLIANCE MANAGEMENT & REGULATORY ASSESSMENT (200 words) ===

**3. REGULATORY COMPLIANCE FRAMEWORK (Compliance Management Systems):**
Using established compliance methodologies:
- **Regulatory Inventory**: Applicable law and regulation identification with impact assessment
- **Compliance Assessment**: Current state evaluation with gap analysis
- **Policy Development**: Written procedures with behavioral expectations
- **Training Programs**: Education delivery with competency verification
- **Monitoring Systems**: Compliance surveillance with violation detection
- **Corrective Actions**: Remediation procedures with root cause elimination

**Industry-Specific Compliance:**
- **Financial Services**: Banking regulations, securities law, and consumer protection
- **Healthcare**: Privacy regulations, safety standards, and quality requirements
- **Manufacturing**: Environmental regulations, safety standards, and product liability
- **Technology**: Data protection, cybersecurity, and intellectual property
- **Professional Services**: Licensing requirements, ethics standards, and client protection
- **General Business**: Employment law, tax compliance, and corporate governance

**4. INTERNAL CONTROL SYSTEMS (COSO Framework Application):**
Using Committee of Sponsoring Organizations framework:
- **Control Environment**: Tone at top with integrity and ethical values
- **Risk Assessment**: Objective setting with risk identification and analysis
- **Control Activities**: Policies and procedures with authorization controls
- **Information Systems**: Relevant information with communication systems
- **Monitoring Activities**: Ongoing assessments with separate evaluations

**Control Effectiveness Assessment:**
- **Design Effectiveness**: Control design adequacy for risk mitigation
- **Operating Effectiveness**: Control performance consistency over time
- **Control Testing**: Sampling procedures with evidence evaluation
- **Deficiency Identification**: Control gaps with severity assessment
- **Management Action Plans**: Remediation strategies with timeline completion
- **External Validation**: Independent assessment with assurance provision

**5. CYBERSECURITY RISK MANAGEMENT (Information Security Frameworks):**
Using established cybersecurity standards:
- **NIST Cybersecurity Framework**: Identify, Protect, Detect, Respond, Recover
- **ISO 27001**: Information security management system requirements
- **Risk Assessment**: Asset identification with threat and vulnerability analysis
- **Security Controls**: Preventive, detective, and corrective control implementation
- **Incident Response**: Breach detection with containment and recovery procedures
- **Business Continuity**: Disaster recovery with operational resilience planning

=== SECTION 3: CRISIS MANAGEMENT & BUSINESS CONTINUITY (200 words) ===

**6. BUSINESS CONTINUITY PLANNING (Continuity Management Standards):**
Using ISO 22301 business continuity framework:
- **Business Impact Analysis**: Critical process identification with recovery priorities
- **Risk Assessment**: Threat identification with probability and impact evaluation
- **Recovery Strategies**: Alternative approaches with resource requirements
- **Plan Development**: Documented procedures with roles and responsibilities
- **Testing and Exercises**: Plan validation with performance improvement
- **Maintenance and Review**: Regular updates with lessons learned integration

**Continuity Components:**
- **Emergency Response**: Immediate threat response with life safety priority
- **Damage Assessment**: Impact evaluation with resource requirement identification
- **Recovery Operations**: Service restoration with normal operation resumption
- **Communications**: Stakeholder notification with status updates
- **Resource Management**: Personnel, facilities, and technology coordination
- **Vendor Management**: Supplier continuity with alternative sourcing

**7. CRISIS MANAGEMENT (Crisis Response Framework):**
Using established crisis management principles:
- **Crisis Identification**: Early warning systems with escalation triggers
- **Response Team Activation**: Crisis management team with defined roles
- **Situation Assessment**: Impact evaluation with stakeholder analysis
- **Response Strategy**: Action plan development with resource mobilization
- **Communication Management**: Message development with media relations
- **Recovery Planning**: Post-crisis restoration with lessons learned

**Crisis Categories:**
- **Operational Crises**: Service disruptions and system failures
- **Financial Crises**: Cash flow problems and market volatility
- **Reputational Crises**: Brand damage and stakeholder confidence loss
- **Legal Crises**: Regulatory violations and litigation exposure
- **Natural Disasters**: Weather events and environmental disruptions
- **Human Crises**: Workplace violence and key person loss

=== SECTION 4: RISK MITIGATION & PERFORMANCE MONITORING (200 words) ===

**8. RISK MITIGATION STRATEGIES (Treatment Option Analysis):**
Using systematic risk treatment approaches:
- **Risk Avoidance**: Activity elimination with alternative approach selection
- **Risk Reduction**: Likelihood or impact reduction with control implementation
- **Risk Transfer**: Insurance coverage with contractual risk allocation
- **Risk Acceptance**: Conscious retention with monitoring requirements
- **Risk Sharing**: Partnership arrangements with collaborative risk management
- **Contingency Planning**: Backup procedures with emergency response protocols

**Mitigation Effectiveness:**
- **Cost-Benefit Analysis**: Treatment cost comparison with risk reduction benefits
- **Implementation Feasibility**: Resource requirements with capability assessment
- **Time-to-Implementation**: Treatment timeline with urgency consideration
- **Residual Risk Assessment**: Remaining risk after treatment implementation
- **Control Monitoring**: Ongoing effectiveness assessment with performance tracking
- **Adaptation Requirements**: Treatment modification with changing circumstances

**9. KEY RISK INDICATORS (Performance Measurement):**
Using risk monitoring best practices:
- **Leading Indicators**: Forward-looking metrics with early warning capability
- **Lagging Indicators**: Historical performance with trend analysis
- **Threshold Setting**: Alert levels with escalation triggers
- **Dashboard Development**: Visual presentation with executive reporting
- **Trend Analysis**: Pattern identification with predictive insights
- **Benchmarking**: Industry comparison with peer assessment

**Risk Reporting Framework:**
- **Board Reporting**: Executive summary with strategic risk focus
- **Management Reporting**: Operational detail with action requirements
- **Regulatory Reporting**: Compliance demonstration with statutory requirements
- **Stakeholder Communication**: External reporting with transparency provision
- **Performance Metrics**: Risk management effectiveness with improvement tracking
- **Continuous Improvement**: Process enhancement with best practice adoption

**10. RISK CULTURE DEVELOPMENT (Organizational Risk Awareness):**
Using risk culture enhancement approaches:
- **Risk Awareness Training**: Education programs with competency development
- **Accountability Systems**: Clear responsibilities with performance measurement
- **Incentive Alignment**: Reward systems with risk-appropriate behavior
- **Communication Programs**: Risk messaging with cultural reinforcement
- **Leadership Modeling**: Executive behavior with risk culture demonstration
- **Continuous Learning**: Lessons learned with knowledge sharing

**Culture Assessment:**
- **Risk Appetite Understanding**: Tolerance awareness with decision making alignment
- **Speaking Up Culture**: Error reporting comfort with blame-free environment
- **Risk-Informed Decisions**: Consideration integration with business planning
- **Proactive Risk Management**: Prevention focus with early intervention
- **Collaborative Risk Approach**: Cross-functional cooperation with shared responsibility
- **Continuous Improvement**: Risk management enhancement with innovation encouragement

**COMPREHENSIVE RISK ANALYSIS INTEGRATION:**
This analysis incorporates:
- **329 risk variables** across all assessment dimensions
- **10 evidence-based methodologies** using validated risk management and compliance frameworks
- **Established standards** (ISO 31000, COSO, NIST Cybersecurity Framework, ISO 22301)
- **Quantitative risk assessment** with statistical analysis and Monte Carlo simulation
- **Practical mitigation strategies** with implementation guidance and effectiveness measurement
- **Performance monitoring systems** with key risk indicators and continuous improvement mechanisms
"""
},
        "implementation_roadmap": {
    "title": "People & Operations Implementation Roadmap",
    "word_target": 1000,
    "analysis_requirements":"""
EVIDENCE-BASED IMPLEMENTATION ROADMAP ANALYSIS - PROJECT MANAGEMENT & CHANGE IMPLEMENTATION
**COMPLETE IMPLEMENTATION STRATEGY WITH VALIDATED PROJECT MANAGEMENT & CHANGE METHODOLOGIES**

=== SECTION 1: IMPLEMENTATION PLANNING & PROJECT MANAGEMENT (250 words) ===

**COMPREHENSIVE IMPLEMENTATION VARIABLE INTEGRATION (447 variables):**

**CORE IMPLEMENTATION ASSESSMENT:**
- ALL P&O Variables (1.1-9.2): Implementation readiness analysis with change capacity evaluation
- ALL Profile Variables (1-22): Behavioral change preferences with implementation methodology alignment
- ALL Dream Variables (1-22): Goal-implementation coherence with timeline reality assessment
- ALL Growth Variables (1-16): Resource constraint analysis with scaling implementation requirements
- ALL Analyst Variables (1-50+): Current state baseline with capability gap identification
- ALL Component Variables (Foundation-Enterprise): Maturity-based implementation pathways with phase transitions

**EVIDENCE-BASED METHODOLOGIES:**

**1. PROJECT MANAGEMENT FRAMEWORK (PMI/PMBOK Standards):**
Using established project management methodologies:
- **Project Initiation**: Charter development with stakeholder identification and success criteria
- **Project Planning**: Scope definition, work breakdown structure, and resource allocation
- **Project Execution**: Implementation coordination with team management and communication
- **Project Monitoring**: Progress tracking with performance measurement and variance analysis
- **Project Closing**: Deliverable acceptance with lessons learned and knowledge transfer

**Implementation Planning Components:**
- **Work Breakdown Structure**: Hierarchical task decomposition with deliverable organization
- **Critical Path Method**: Task sequencing with dependency analysis and timeline optimization
- **Resource Planning**: Human, financial, and material resource allocation with availability analysis
- **Risk Management**: Implementation risk identification with mitigation planning
- **Communication Planning**: Stakeholder engagement with information distribution strategies
- **Quality Planning**: Standards definition with acceptance criteria and testing procedures

**2. AGILE IMPLEMENTATION METHODOLOGY (Scrum/Kanban Framework):**
Using iterative implementation approaches:
- **Sprint Planning**: Short-term implementation cycles with specific deliverable targets
- **Daily Standups**: Progress review with obstacle identification and team coordination
- **Sprint Reviews**: Deliverable demonstration with stakeholder feedback integration
- **Retrospectives**: Process improvement with team learning and adaptation
- **Continuous Integration**: Ongoing implementation with frequent testing and validation
- **Adaptive Planning**: Flexible response to changing requirements and priorities

**Agile Implementation Principles:**
- **Customer Collaboration**: Stakeholder involvement with regular feedback incorporation
- **Responding to Change**: Flexibility over rigid plan adherence
- **Working Solutions**: Functional deliverables over comprehensive documentation
- **Individuals and Interactions**: People focus over process and tool emphasis
- **Iterative Delivery**: Incremental value delivery with continuous improvement
- **Self-Organizing Teams**: Autonomous team decision-making with empowerment

=== SECTION 2: CHANGE MANAGEMENT & ORGANIZATIONAL TRANSFORMATION (250 words) ===

**3. CHANGE MANAGEMENT FRAMEWORK (Kotter's 8-Step Process):**
Using validated organizational change methodology:
- **Create Urgency**: Compelling reason development with stakeholder buy-in
- **Build Coalition**: Leadership team assembly with change champion identification
- **Develop Vision**: Clear direction with compelling future state description
- **Communicate Vision**: Message dissemination with consistent communication
- **Empower Action**: Obstacle removal with broad-based action encouragement
- **Generate Wins**: Short-term success identification with momentum building
- **Consolidate Gains**: Success building with additional change pursuit
- **Anchor Changes**: Culture embedding with new approach institutionalization

**Change Readiness Assessment:**
- **Organizational Capability**: Change capacity evaluation with resource assessment
- **Leadership Commitment**: Executive support with visible participation
- **Employee Engagement**: Stakeholder involvement with participation willingness
- **Communication Effectiveness**: Message clarity with understanding verification
- **Resource Availability**: Implementation support with adequate investment
- **Cultural Alignment**: Change compatibility with organizational values

**4. ADKAR CHANGE MODEL (Individual Change Framework):**
Using individual-focused change approach:
- **Awareness**: Understanding of need for change with personal impact recognition
- **Desire**: Motivation to support change with personal commitment development
- **Knowledge**: Skills and capabilities required for change with learning provision
- **Ability**: Practical application with behavior change implementation
- **Reinforcement**: Sustainability mechanisms with continued change support

**Resistance Management:**
- **Resistance Identification**: Source analysis with root cause understanding
- **Stakeholder Analysis**: Impact assessment with influence mapping
- **Communication Strategy**: Targeted messaging with concern addressing
- **Participation Encouragement**: Involvement opportunities with contribution recognition
- **Support Provision**: Training and coaching with implementation assistance
- **Feedback Integration**: Concern addressing with adaptation willingness

=== SECTION 3: IMPLEMENTATION MONITORING & PERFORMANCE MANAGEMENT (250 words) ===

**5. PERFORMANCE MEASUREMENT FRAMEWORK (Balanced Scorecard Approach):**
Using comprehensive performance assessment:
- **Financial Perspective**: Cost management with return on investment measurement
- **Customer Perspective**: Stakeholder satisfaction with value delivery assessment
- **Internal Process**: Efficiency improvement with quality enhancement
- **Learning and Growth**: Capability development with innovation measurement

**Key Performance Indicators:**
- **Leading Indicators**: Predictive metrics with early warning capability
- **Lagging Indicators**: Result measurement with outcome assessment
- **Milestone Tracking**: Progress measurement with timeline adherence
- **Quality Metrics**: Deliverable assessment with standard compliance
- **Resource Utilization**: Efficiency measurement with cost management
- **Stakeholder Satisfaction**: Engagement assessment with feedback analysis

**6. CONTINUOUS IMPROVEMENT METHODOLOGY (PDCA Cycle):**
Using systematic improvement approach:
- **Plan**: Improvement identification with implementation strategy development
- **Do**: Small-scale testing with pilot implementation
- **Check**: Result evaluation with success measurement
- **Act**: Full implementation with standard procedure adoption

**Implementation Optimization:**
- **Process Analysis**: Workflow evaluation with efficiency identification
- **Bottleneck Identification**: Constraint analysis with resolution strategies
- **Best Practice Development**: Success pattern identification with replication
- **Knowledge Management**: Learning capture with experience sharing
- **Technology Integration**: Tool utilization with process enhancement
- **Feedback Loops**: Continuous assessment with adaptive management

=== SECTION 4: IMPLEMENTATION SUCCESS & SUSTAINABILITY (250 words) ===

**7. SUCCESS MEASUREMENT FRAMEWORK (Results-Based Management):**
Using outcome-focused assessment:
- **Output Measurement**: Deliverable completion with specification compliance
- **Outcome Assessment**: Objective achievement with goal attainment
- **Impact Evaluation**: Long-term benefit realization with value creation
- **Return on Investment**: Cost-benefit analysis with financial justification
- **Stakeholder Value**: Benefit distribution with satisfaction measurement
- **Competitive Advantage**: Market position improvement with differentiation

**Success Factors:**
- **Clear Objectives**: Specific, measurable, achievable, relevant, time-bound goals
- **Executive Sponsorship**: Leadership support with visible commitment
- **Resource Adequacy**: Sufficient investment with capability provision
- **Team Competence**: Skill availability with experience application
- **Communication Effectiveness**: Information sharing with understanding achievement
- **Risk Management**: Proactive issue identification with mitigation implementation

**8. SUSTAINABILITY PLANNING (Long-Term Implementation Management):**
Using sustainability frameworks:
- **Culture Integration**: Change embedding with organizational norm establishment
- **Process Standardization**: Procedure documentation with consistency maintenance
- **Training Programs**: Skill development with competency reinforcement
- **Governance Systems**: Oversight mechanisms with accountability establishment
- **Continuous Monitoring**: Performance tracking with deviation detection
- **Adaptation Capability**: Flexibility maintenance with evolution support

**Sustainability Components:**
- **Institutional Memory**: Knowledge retention with experience documentation
- **Succession Planning**: Capability transfer with continuity assurance
- **Performance Standards**: Quality maintenance with excellence pursuit
- **Innovation Culture**: Continuous improvement with creative problem-solving
- **Stakeholder Engagement**: Ongoing support with relationship maintenance
- **Resource Planning**: Long-term investment with capability sustainability

**9. LESSONS LEARNED FRAMEWORK (Knowledge Management):**
Using systematic learning capture:
- **Experience Documentation**: Success and failure analysis with pattern identification
- **Best Practice Development**: Effective approach identification with replication guidance
- **Knowledge Sharing**: Learning distribution with organization-wide benefit
- **Process Improvement**: Experience integration with methodology enhancement
- **Future Application**: Learning utilization with implementation optimization
- **Organizational Memory**: Experience retention with institutional knowledge building

**10. IMPLEMENTATION MATURITY ASSESSMENT (Capability Development):**
Using maturity model evaluation:
- **Level 1 - Initial**: Ad-hoc implementation with limited repeatability
- **Level 2 - Managed**: Basic process control with some standardization
- **Level 3 - Defined**: Documented processes with consistent execution
- **Level 4 - Quantitatively Managed**: Measured processes with statistical control
- **Level 5 - Optimizing**: Continuous improvement with innovation focus

**Maturity Enhancement:**
- **Process Definition**: Methodology documentation with standard procedures
- **Skill Development**: Competency building with capability enhancement
- **Tool Integration**: Technology utilization with efficiency improvement
- **Performance Measurement**: Metric development with progress tracking
- **Continuous Learning**: Experience integration with knowledge advancement
- **Innovation Adoption**: New approach evaluation with implementation enhancement

**COMPREHENSIVE IMPLEMENTATION ANALYSIS INTEGRATION:**
This analysis incorporates:
- **447 implementation variables** across all assessment dimensions
- **10 evidence-based methodologies** using validated project management and change management frameworks
- **Established standards** (PMI/PMBOK, Agile/Scrum, Kotter, ADKAR, Balanced Scorecard)
- **Performance measurement systems** with quantified success metrics and tracking
- **Practical implementation strategies** with resource planning and risk management
- **Sustainability planning** with long-term success assurance and continuous improvement
"""
},
        "breakthrough_opportunities": {
    "title": "Breakthrough Organizational Opportunities",
    "word_target": 800,
    "analysis_requirements": """
EVIDENCE-BASED BREAKTHROUGH OPPORTUNITIES ANALYSIS - INNOVATION STRATEGY & OPPORTUNITY IDENTIFICATION
**COMPLETE OPPORTUNITY ASSESSMENT WITH VALIDATED INNOVATION & STRATEGIC PLANNING METHODOLOGIES**

=== SECTION 1: OPPORTUNITY IDENTIFICATION & INNOVATION ASSESSMENT (200 words) ===

**COMPREHENSIVE BREAKTHROUGH VARIABLE INTEGRATION (523 variables):**

**CORE OPPORTUNITY ASSESSMENT:**
- ALL Assessment Variables (523 total): Comprehensive capability analysis with untapped potential identification
- Profile 10 (Surprise Insights): Personal innovation patterns with creative breakthrough indicators
- Profile 16-17 (Transformative Relationships): Network-based opportunities with partnership potential
- Dream 22 (Undisclosed Aspirations): Hidden ambitions with unrevealed opportunity directions
- Growth 15-16 (Untapped Opportunities): Identified but unexploited potential with resource requirements
- Analyst Clarity 4 (Key Insights): Experience-based wisdom with learning pattern recognition

**EVIDENCE-BASED METHODOLOGIES:**

**1. SYSTEMATIC OPPORTUNITY ANALYSIS (Strategic Planning Framework):**
Using established opportunity identification methods:
- **SWOT Analysis Enhancement**: Strengths-based opportunity identification with competitive advantage leverage
- **Gap Analysis**: Current vs. potential state comparison with opportunity space mapping
- **Market Analysis**: Industry trends with emerging opportunity identification
- **Capability Assessment**: Core competency evaluation with extension possibilities
- **Resource Audit**: Underutilized assets with alternative application potential
- **Stakeholder Analysis**: Network relationships with partnership opportunity identification

**Innovation Opportunity Categories:**
- **Product/Service Innovation**: New offering development with market differentiation
- **Process Innovation**: Operational improvement with efficiency enhancement
- **Business Model Innovation**: Revenue model transformation with value creation
- **Market Innovation**: New market entry with expansion opportunities
- **Technology Innovation**: Digital transformation with automation potential
- **Partnership Innovation**: Strategic alliance with collaborative advantage

**2. INNOVATION CAPABILITY ASSESSMENT (Innovation Management Framework):**
Using validated innovation evaluation methods:
- **Innovation Readiness**: Organizational capacity for breakthrough development
- **Creative Climate Assessment**: Environment supporting innovation with psychological safety
- **Innovation Pipeline**: Idea generation through commercialization process
- **Resource Availability**: Investment capacity with innovation funding capability
- **Risk Tolerance**: Uncertainty acceptance with experimentation willingness
- **Learning Orientation**: Knowledge acquisition with adaptation capability

**Innovation Success Factors:**
- **Leadership Support**: Executive commitment with innovation championing
- **Culture of Experimentation**: Failure tolerance with learning emphasis
- **Cross-Functional Collaboration**: Integration across organizational boundaries
- **External Network**: Industry connections with knowledge access
- **Time Allocation**: Innovation dedicated time with project protection
- **Performance Metrics**: Innovation measurement with appropriate incentives

=== SECTION 2: MARKET OPPORTUNITY & COMPETITIVE ANALYSIS (200 words) ===

**3. MARKET OPPORTUNITY ASSESSMENT (Market Research Framework):**
Using established market analysis methods:
- **Market Sizing**: Total addressable market with serviceable available market
- **Growth Projections**: Market expansion with trend analysis
- **Customer Segmentation**: Target market identification with need analysis
- **Competitive Landscape**: Competitor analysis with positioning assessment
- **Value Proposition**: Unique value delivery with differentiation strategy
- **Go-to-Market Strategy**: Market entry with channel optimization

**Opportunity Evaluation Criteria:**
- **Market Attractiveness**: Size, growth, and profitability potential
- **Competitive Intensity**: Rivalry level with entry barrier assessment
- **Customer Need**: Problem severity with solution urgency
- **Technical Feasibility**: Development capability with resource requirements
- **Financial Viability**: Revenue potential with investment requirements
- **Strategic Fit**: Alignment with organizational capabilities and objectives

**4. COMPETITIVE ADVANTAGE ANALYSIS (Strategic Management Framework):**
Using competitive strategy principles:
- **Porter's Five Forces**: Industry structure analysis with competitive dynamics
- **Resource-Based View**: Unique capability identification with competitive sustainability
- **Value Chain Analysis**: Activity analysis with advantage source identification
- **Blue Ocean Strategy**: Uncontested market space with value innovation
- **Disruptive Innovation**: Market disruption with new value network creation
- **Core Competency Leverage**: Distinctive capability extension with new application

**Competitive Positioning:**
- **Cost Leadership**: Efficiency advantage with price competitiveness
- **Differentiation**: Unique value delivery with premium positioning
- **Focus Strategy**: Niche market dominance with specialized capability
- **Innovation Leadership**: First-mover advantage with technology superiority
- **Customer Intimacy**: Relationship depth with customized solutions
- **Operational Excellence**: Process efficiency with reliability advantage

=== SECTION 3: INNOVATION STRATEGY & DEVELOPMENT PLANNING (200 words) ===

**5. INNOVATION STRATEGY DEVELOPMENT (Strategic Innovation Framework):**
Using systematic innovation planning:
- **Innovation Vision**: Long-term innovation direction with strategic alignment
- **Innovation Portfolio**: Balanced mix of incremental and breakthrough innovations
- **Resource Allocation**: Investment distribution across innovation categories
- **Innovation Metrics**: Performance measurement with success tracking
- **Innovation Governance**: Decision-making process with accountability structure
- **Innovation Culture**: Environment fostering with behavioral reinforcement

**Innovation Development Process:**
- **Idea Generation**: Systematic creativity with diverse input sources
- **Concept Development**: Idea refinement with feasibility assessment
- **Business Case Development**: Economic analysis with investment justification
- **Prototype Development**: Proof of concept with testing validation
- **Pilot Implementation**: Small-scale deployment with learning capture
- **Full-Scale Launch**: Market introduction with scaling preparation

**6. TECHNOLOGY AND DIGITAL OPPORTUNITY (Digital Transformation Framework):**
Using technology innovation approaches:
- **Digital Capability Assessment**: Current technology maturity with gap identification
- **Automation Opportunities**: Process digitization with efficiency enhancement
- **Data Analytics**: Information leverage with insight generation
- **Platform Strategy**: Ecosystem development with network effects
- **Artificial Intelligence**: AI application with decision enhancement
- **Emerging Technology**: New technology adoption with competitive advantage

**Digital Innovation Areas:**
- **Customer Experience**: Digital interface improvement with satisfaction enhancement
- **Operational Efficiency**: Process automation with cost reduction
- **Data-Driven Decisions**: Analytics integration with insight utilization
- **New Revenue Streams**: Digital product development with monetization
- **Partnership Platforms**: Ecosystem creation with collaborative value
- **Innovation Acceleration**: Technology-enabled development with speed improvement

=== SECTION 4: IMPLEMENTATION PLANNING & SUCCESS MEASUREMENT (200 words) ===

**7. OPPORTUNITY PRIORITIZATION (Portfolio Management Framework):**
Using systematic prioritization methods:
- **Impact-Effort Matrix**: Opportunity assessment with implementation difficulty
- **Financial Analysis**: NPV, IRR, and payback period with risk adjustment
- **Strategic Importance**: Alignment with organizational objectives and vision
- **Resource Requirements**: Investment needs with capability assessment
- **Timeline Considerations**: Development duration with market timing
- **Risk Assessment**: Implementation challenges with mitigation strategies

**Prioritization Criteria:**
- **Market Potential**: Revenue opportunity with growth prospects
- **Competitive Advantage**: Differentiation potential with sustainability
- **Implementation Feasibility**: Capability requirements with resource availability
- **Strategic Alignment**: Organizational fit with vision coherence
- **Risk-Adjusted Returns**: Probability-weighted outcomes with uncertainty consideration
- **Time to Market**: Speed advantage with competitive timing

**8. BREAKTHROUGH IMPLEMENTATION PLANNING (Project Management Framework):**
Using systematic implementation approaches:
- **Project Planning**: Scope definition with milestone establishment
- **Resource Allocation**: Team assembly with budget allocation
- **Risk Management**: Challenge identification with mitigation planning
- **Stakeholder Engagement**: Support building with communication strategy
- **Performance Monitoring**: Progress tracking with success measurement
- **Learning Integration**: Experience capture with knowledge application

**Implementation Success Factors:**
- **Executive Sponsorship**: Leadership support with resource commitment
- **Cross-Functional Teams**: Diverse expertise with collaborative approach
- **Agile Methodology**: Iterative development with adaptive planning
- **Customer Involvement**: User feedback with requirement validation
- **Change Management**: Organizational adaptation with culture alignment
- **Continuous Improvement**: Learning application with optimization focus

**9. SUCCESS MEASUREMENT AND VALIDATION (Performance Management Framework):**
Using comprehensive success assessment:
- **Financial Metrics**: Revenue, profit, and return on investment measurement
- **Market Metrics**: Market share, customer acquisition, and retention analysis
- **Operational Metrics**: Efficiency, quality, and productivity improvement
- **Innovation Metrics**: Idea generation, development speed, and success rate
- **Customer Metrics**: Satisfaction, loyalty, and value perception assessment
- **Learning Metrics**: Knowledge acquisition, capability building, and adaptation

**Validation Methodology:**
- **Pilot Testing**: Small-scale validation with performance measurement
- **Market Research**: Customer feedback with acceptance assessment
- **Financial Analysis**: Cost-benefit verification with ROI validation
- **Competitive Analysis**: Market position assessment with advantage confirmation
- **Risk Assessment**: Challenge identification with mitigation effectiveness
- **Scalability Testing**: Growth capacity with expansion feasibility

**10. LONG-TERM OPPORTUNITY DEVELOPMENT (Strategic Planning Framework):**
Using future-focused planning:
- **Scenario Planning**: Multiple future consideration with strategic flexibility
- **Trend Analysis**: Long-term pattern identification with implication assessment
- **Capability Development**: Future skill building with competency planning
- **Partnership Strategy**: Strategic alliance with collaborative advantage
- **Innovation Pipeline**: Continuous opportunity development with succession planning
- **Organizational Learning**: Knowledge integration with adaptation capability

**Future Opportunity Areas:**
- **Emerging Technologies**: New technology adoption with first-mover advantage
- **Market Evolution**: Changing customer needs with solution development
- **Regulatory Changes**: Compliance opportunity with competitive positioning
- **Global Expansion**: International market entry with localization strategy
- **Sustainability Innovation**: Environmental opportunity with responsibility integration
- **Social Impact**: Purpose-driven innovation with stakeholder value creation

**COMPREHENSIVE BREAKTHROUGH ANALYSIS INTEGRATION:**
This analysis incorporates:
- **523 opportunity variables** across all assessment dimensions
- **10 evidence-based methodologies** using validated innovation and strategic planning frameworks
- **Established approaches** (SWOT analysis, Porter's Five Forces, innovation management, digital transformation)
- **Systematic prioritization** with financial analysis and risk assessment
- **Practical implementation planning** with project management and success measurement
- **Long-term strategic development** with scenario planning and capability building
"""
},

"market_positioning": {
    "title": "Strategic Market Intelligence & Competitive Dynamics",
    "word_target": 900,
    "analysis_requirements":"""
EVIDENCE-BASED MARKET POSITIONING ANALYSIS - COMPETITIVE STRATEGY & MARKET INTELLIGENCE
**COMPLETE MARKET ASSESSMENT WITH VALIDATED STRATEGIC MARKETING & COMPETITIVE ANALYSIS METHODOLOGIES**

=== SECTION 1: MARKET ANALYSIS & COMPETITIVE LANDSCAPE ASSESSMENT (225 words) ===

**COMPREHENSIVE MARKET-COMPETITIVE VARIABLE INTEGRATION (394 variables):**

**CORE MARKET POSITIONING ASSESSMENT:**
- Growth 14 (Competitive Advantage): Unique value proposition identification with differentiation analysis
- Analyst Market 1-5 (Market Position Intelligence): Customer relationships through network role assessment
- Analyst Market Deep Dive: Brand strength, market intelligence, competitive positioning, network influence
- Component Competitive Positioning: Market position evolution across maturity phases
- Growth 6 (Revenue Patterns): Market cycle analysis with seasonal dynamics and predictability
- Growth 4 (Lead Generation Methods): Channel effectiveness with market penetration analysis

**EVIDENCE-BASED METHODOLOGIES:**

**1. COMPETITIVE STRATEGY ANALYSIS (Porter's Strategic Framework):**
Using established competitive strategy principles:
- **Five Forces Analysis**: Industry structure assessment with competitive intensity measurement
 * Threat of New Entrants: Barrier analysis with market accessibility evaluation
 * Bargaining Power of Suppliers: Supplier concentration with switching cost analysis
 * Bargaining Power of Buyers: Customer concentration with price sensitivity assessment
 * Threat of Substitutes: Alternative solution analysis with substitution risk evaluation
 * Competitive Rivalry: Direct competition intensity with differentiation analysis

**Strategic Positioning Options:**
- **Cost Leadership**: Low-cost strategy with operational efficiency and scale advantages
- **Differentiation**: Unique value delivery with premium positioning and brand strength
- **Focus Strategy**: Niche market targeting with specialized capability development
- **Hybrid Strategies**: Combined approaches with value innovation and blue ocean creation
- **Platform Strategy**: Ecosystem development with network effects and multi-sided markets
- **Innovation Leadership**: Technology advantage with first-mover positioning

**2. MARKET SEGMENTATION & TARGET ANALYSIS (Marketing Strategy Framework):**
Using systematic market analysis approaches:
- **Market Segmentation**: Customer group identification with needs-based clustering
- **Target Market Selection**: Segment attractiveness with competitive position assessment
- **Value Proposition Design**: Customer need alignment with competitive differentiation
- **Positioning Strategy**: Market position definition with competitive comparison
- **Brand Positioning**: Identity development with customer perception management
- **Go-to-Market Strategy**: Market entry with channel optimization and timing

**Market Analysis Components:**
- **Market Size**: Total addressable market with serviceable available market calculation
- **Growth Rate**: Market expansion with trend analysis and projection
- **Customer Analysis**: Buyer behavior with decision-making process evaluation
- **Competitive Landscape**: Direct and indirect competitor assessment with market share
- **Industry Trends**: Market evolution with disruption threat and opportunity identification
- **Regulatory Environment**: Compliance requirements with policy impact analysis

=== SECTION 2: CUSTOMER ANALYSIS & VALUE PROPOSITION DEVELOPMENT (225 words) ===

**3. CUSTOMER BEHAVIOR ANALYSIS (Consumer Research Framework):**
Using validated customer analysis methods:
- **Customer Journey Mapping**: Touchpoint analysis with experience optimization opportunities
- **Persona Development**: Detailed customer profiles with needs and behavior patterns
- **Jobs-to-be-Done Analysis**: Customer need identification with solution requirement assessment
- **Voice of Customer**: Feedback analysis with satisfaction and loyalty measurement
- **Customer Lifetime Value**: Economic value calculation with retention strategy development
- **Net Promoter Score**: Loyalty measurement with advocacy behavior analysis

**Customer Segmentation Approaches:**
- **Demographic Segmentation**: Age, income, education, and geographic characteristics
- **Psychographic Segmentation**: Values, attitudes, interests, and lifestyle patterns
- **Behavioral Segmentation**: Usage patterns, loyalty, and purchase behavior analysis
- **Needs-Based Segmentation**: Problem-solution fit with requirement clustering
- **Value-Based Segmentation**: Price sensitivity and value perception analysis
- **Channel Preference**: Communication and purchase channel optimization

**4. VALUE PROPOSITION DEVELOPMENT (Value Creation Framework):**
Using systematic value proposition design:
- **Customer Pain Point Analysis**: Problem identification with severity assessment
- **Solution Fit Assessment**: Product-market fit with customer need alignment
- **Competitive Comparison**: Alternative solution analysis with differentiation identification
- **Value Quantification**: Benefit measurement with economic impact calculation
- **Price-Value Relationship**: Pricing strategy with value perception optimization
- **Value Communication**: Message development with customer understanding verification

**Value Proposition Components:**
- **Functional Benefits**: Practical problem solving with performance improvement
- **Emotional Benefits**: Feeling enhancement with experience satisfaction
- **Social Benefits**: Status improvement with community belonging
- **Economic Benefits**: Cost savings with revenue enhancement opportunities
- **Risk Reduction**: Security improvement with uncertainty mitigation
- **Convenience Benefits**: Simplification with time and effort savings

=== SECTION 3: COMPETITIVE INTELLIGENCE & MARKET DYNAMICS (225 words) ===

**5. COMPETITIVE INTELLIGENCE SYSTEM (Market Research Framework):**
Using systematic competitive analysis:
- **Competitor Profiling**: Comprehensive competitor assessment with capability analysis
- **Competitive Benchmarking**: Performance comparison with best practice identification
- **Market Share Analysis**: Position tracking with trend analysis and projection
- **Pricing Analysis**: Competitor pricing with strategy assessment and response planning
- **Product Comparison**: Feature analysis with differentiation opportunity identification
- **Marketing Strategy Analysis**: Competitor promotion with channel strategy assessment

**Intelligence Gathering Methods:**
- **Primary Research**: Customer interviews with market survey and focus groups
- **Secondary Research**: Industry reports with public information analysis
- **Digital Intelligence**: Online monitoring with social media analysis
- **Patent Analysis**: Technology development with innovation pipeline assessment
- **Financial Analysis**: Public company performance with investment pattern analysis
- **Industry Expert**: Professional network with insider knowledge access

**6. MARKET DYNAMICS ANALYSIS (Industry Analysis Framework):**
Using established industry analysis methods:
- **Industry Lifecycle**: Market maturity assessment with growth stage identification
- **Market Trends**: Pattern analysis with future direction prediction
- **Disruption Analysis**: Technology threat with business model innovation impact
- **Regulatory Impact**: Policy change with compliance requirement assessment
- **Economic Factors**: Market sensitivity with economic cycle correlation
- **Social Trends**: Demographic shift with cultural change impact

**Market Forces Assessment:**
- **Technology Drivers**: Innovation impact with adoption curve analysis
- **Economic Drivers**: Market demand with purchasing power assessment
- **Social Drivers**: Cultural shift with behavior change analysis
- **Regulatory Drivers**: Policy impact with compliance requirement evolution
- **Environmental Drivers**: Sustainability requirement with green market opportunity
- **Political Drivers**: Government policy with trade regulation impact

=== SECTION 4: STRATEGIC POSITIONING & PERFORMANCE MEASUREMENT (225 words) ===

**7. BRAND POSITIONING STRATEGY (Brand Management Framework):**
Using systematic brand development approaches:
- **Brand Identity**: Core values with personality definition and visual identity
- **Brand Promise**: Value delivery commitment with customer expectation management
- **Brand Differentiation**: Unique positioning with competitive distinction
- **Brand Architecture**: Product relationship with portfolio management strategy
- **Brand Experience**: Customer interaction with touchpoint optimization
- **Brand Equity**: Value measurement with recognition and loyalty assessment

**Positioning Implementation:**
- **Message Development**: Key communication with audience-specific content
- **Channel Strategy**: Media selection with reach optimization and budget allocation
- **Content Marketing**: Educational content with thought leadership development
- **Digital Presence**: Online visibility with search optimization and social media
- **Public Relations**: Reputation management with media relationship building
- **Event Marketing**: Industry presence with network building and lead generation

**8. PERFORMANCE MEASUREMENT & OPTIMIZATION (Marketing Analytics Framework):**
Using comprehensive performance assessment:
- **Market Share Tracking**: Position monitoring with competitive comparison
- **Brand Awareness**: Recognition measurement with unaided and aided recall
- **Customer Acquisition**: New customer measurement with cost per acquisition
- **Customer Retention**: Loyalty measurement with churn rate analysis
- **Revenue Attribution**: Marketing contribution with ROI calculation
- **Competitive Response**: Market reaction with strategy effectiveness assessment

**Key Performance Indicators:**
- **Market Metrics**: Share, penetration, and growth rate measurement
- **Brand Metrics**: Awareness, consideration, and preference tracking
- **Customer Metrics**: Acquisition, retention, and lifetime value calculation
- **Financial Metrics**: Revenue, margin, and profitability analysis
- **Operational Metrics**: Efficiency, quality, and productivity measurement
- **Innovation Metrics**: New product success with pipeline development

**9. STRATEGIC ADAPTATION & MARKET EVOLUTION (Strategic Planning Framework):**
Using adaptive strategy development:
- **Market Monitoring**: Continuous surveillance with trend identification
- **Scenario Planning**: Future state preparation with multiple possibility planning
- **Strategic Flexibility**: Adaptation capability with pivot preparation
- **Innovation Pipeline**: New offering development with market timing optimization
- **Partnership Strategy**: Alliance development with ecosystem participation
- **Global Expansion**: International market entry with localization strategy

**Adaptation Mechanisms:**
- **Early Warning Systems**: Trend detection with signal identification
- **Rapid Response**: Quick adaptation with agile decision making
- **Learning Organization**: Knowledge integration with continuous improvement
- **Innovation Culture**: Creative environment with experimentation encouragement
- **Strategic Reviews**: Regular assessment with course correction capability
- **Stakeholder Engagement**: Feedback integration with relationship management

**10. DIGITAL MARKET POSITIONING (Digital Marketing Framework):**
Using digital transformation approaches:
- **Digital Customer Journey**: Online touchpoint optimization with user experience
- **Search Engine Optimization**: Visibility improvement with content optimization
- **Social Media Strategy**: Platform selection with community building
- **Content Strategy**: Educational content with thought leadership positioning
- **Marketing Automation**: Lead nurturing with personalized communication
- **Analytics and Measurement**: Performance tracking with data-driven optimization

**Digital Positioning Elements:**
- **Online Brand Presence**: Website optimization with user experience design
- **Search Marketing**: Paid and organic search with keyword strategy
- **Social Media**: Platform presence with engagement and community building
- **Email Marketing**: Direct communication with segmented messaging
- **Marketing Technology**: Tool integration with automation and analytics
- **Mobile Optimization**: Responsive design with mobile-first approach

**COMPREHENSIVE MARKET ANALYSIS INTEGRATION:**
This analysis incorporates:
- **394 market variables** across all assessment dimensions
- **10 evidence-based methodologies** using validated strategic marketing and competitive analysis frameworks
- **Established approaches** (Porter's Five Forces, market segmentation, competitive intelligence, brand positioning)
- **Performance measurement systems** with quantified metrics and market tracking
- **Practical positioning strategies** with implementation guidance and success measurement
- **Digital transformation integration** with modern marketing technology and analytics
"""
},
"financial_architecture": {
    "title": "Capital Structure & Value Creation Physics",
    "word_target": 900,
    "analysis_requirements": """
EVIDENCE-BASED FINANCIAL ARCHITECTURE ANALYSIS - FINANCIAL MANAGEMENT & CAPITAL OPTIMIZATION
**COMPLETE FINANCIAL ASSESSMENT WITH VALIDATED FINANCIAL PLANNING & CAPITAL MANAGEMENT METHODOLOGIES**

=== SECTION 1: FINANCIAL PERFORMANCE & CAPITAL STRUCTURE ANALYSIS (225 words) ===

**COMPREHENSIVE FINANCIAL-CAPITAL VARIABLE INTEGRATION (412 variables):**

**CORE FINANCIAL ASSESSMENT:**
- Dream 5 (Revenue Reality): Current revenue scale with growth potential assessment
- Dream 10 (Revenue Targets): Growth multiplier analysis with scalability evaluation
- Analyst Financial 1-10 (Financial Intelligence): Comprehensive financial situation assessment
- Component Financial Infrastructure: Financial maturity evolution across organizational phases
- Growth 6-8 (Revenue Architecture): Revenue predictability, patterns, and sales process effectiveness

**EVIDENCE-BASED METHODOLOGIES:**

**1. FINANCIAL PERFORMANCE ANALYSIS (Corporate Finance Framework):**
Using established financial analysis methods:
- **DuPont Analysis**: Return on equity decomposition with profitability, efficiency, and leverage
- **Financial Ratio Analysis**: Liquidity, profitability, efficiency, and leverage ratios with benchmarking
- **Cash Flow Analysis**: Operating, investing, and financing cash flows with sustainability assessment
- **Working Capital Management**: Current asset and liability optimization with cash conversion cycle
- **Profitability Analysis**: Gross, operating, and net margin analysis with cost structure evaluation
- **Return Analysis**: ROE, ROA, ROIC with value creation measurement and comparison

**Financial Health Indicators:**
- **Liquidity Ratios**: Current ratio, quick ratio, and cash ratio with short-term solvency
- **Activity Ratios**: Inventory turnover, receivables turnover, and asset turnover efficiency
- **Leverage Ratios**: Debt-to-equity, times interest earned, and debt service coverage
- **Profitability Ratios**: Gross margin, operating margin, net margin, and return metrics
- **Market Ratios**: Price-to-earnings, price-to-book, and market-to-book value assessment
- **Growth Ratios**: Revenue growth, earnings growth, and dividend growth sustainability

**2. CAPITAL STRUCTURE OPTIMIZATION (Financial Strategy Framework):**
Using systematic capital structure approaches:
- **Debt-Equity Mix**: Optimal leverage with cost of capital minimization
- **Cost of Capital**: Weighted average cost of capital (WACC) calculation and optimization
- **Capital Allocation**: Investment prioritization with return on invested capital maximization
- **Dividend Policy**: Payout ratio optimization with shareholder value creation
- **Share Buyback**: Repurchase analysis with value creation assessment
- **Financial Flexibility**: Debt capacity with financial constraint analysis

**Capital Structure Components:**
- **Debt Financing**: Term loans, lines of credit, and bond financing with cost analysis
- **Equity Financing**: Common stock, preferred stock, and retained earnings optimization
- **Hybrid Securities**: Convertible bonds and preferred equity with flexibility benefits
- **Lease Financing**: Operating and capital leases with cash flow optimization
- **Trade Credit**: Supplier financing with working capital management
- **Alternative Financing**: Revenue-based financing and crowdfunding evaluation

=== SECTION 2: FINANCIAL PLANNING & FORECASTING (225 words) ===

**3. FINANCIAL FORECASTING & MODELING (Financial Planning Framework):**
Using systematic forecasting approaches:
- **Revenue Forecasting**: Sales projection with market analysis and growth assumptions
- **Expense Planning**: Cost structure analysis with variable and fixed cost management
- **Cash Flow Projections**: Monthly cash flow forecasting with seasonal adjustment
- **Scenario Analysis**: Best-case, worst-case, and most likely financial projections
- **Sensitivity Analysis**: Key variable impact with break-even and risk assessment
- **Monte Carlo Simulation**: Probability-weighted outcomes with uncertainty quantification

**Financial Model Components:**
- **Income Statement**: Revenue, costs, and profitability projection with margin analysis
- **Balance Sheet**: Asset, liability, and equity forecasting with working capital planning
- **Cash Flow Statement**: Operating, investing, and financing cash flow projection
- **Key Performance Indicators**: Financial metrics tracking with benchmark comparison
- **Valuation Models**: DCF, comparable company, and precedent transaction analysis
- **Return Analysis**: IRR, NPV, and payback period for investment evaluation

**4. BUDGETING & COST MANAGEMENT (Management Accounting Framework):**
Using comprehensive budgeting approaches:
- **Operating Budget**: Revenue and expense budgeting with departmental allocation
- **Capital Budget**: Investment planning with project evaluation and prioritization
- **Cash Budget**: Liquidity planning with funding requirement identification
- **Flexible Budgeting**: Variable cost adjustment with volume change accommodation
- **Zero-Based Budgeting**: Cost justification with efficiency optimization
- **Activity-Based Budgeting**: Resource allocation with activity cost analysis

**Cost Management Strategies:**
- **Cost Structure Analysis**: Fixed vs. variable cost identification with optimization
- **Break-Even Analysis**: Volume threshold with profitability planning
- **Contribution Margin**: Product profitability with pricing optimization
- **Cost-Volume-Profit**: Relationship analysis with decision support
- **Variance Analysis**: Actual vs. budget comparison with corrective action
- **Cost Reduction**: Efficiency improvement with margin enhancement

=== SECTION 3: INVESTMENT ANALYSIS & CAPITAL ALLOCATION (225 words) ===

**5. CAPITAL INVESTMENT EVALUATION (Corporate Finance Framework):**
Using systematic investment assessment:
- **Net Present Value (NPV)**: Discounted cash flow with value creation measurement
- **Internal Rate of Return (IRR)**: Profitability threshold with hurdle rate comparison
- **Payback Period**: Recovery timeline with liquidity consideration
- **Profitability Index**: Benefit-cost ratio with resource allocation optimization
- **Real Options Analysis**: Flexibility value with strategic option assessment
- **Risk-Adjusted Returns**: Beta adjustment with market risk consideration

**Investment Categories:**
- **Growth Investments**: Market expansion with revenue enhancement projects
- **Efficiency Investments**: Process improvement with cost reduction benefits
- **Technology Investments**: Digital transformation with competitive advantage
- **Infrastructure Investments**: Capacity building with scalability enhancement
- **Maintenance Investments**: Asset preservation with operational continuity
- **Strategic Investments**: Long-term positioning with competitive moats

**6. WORKING CAPITAL MANAGEMENT (Cash Management Framework):**
Using systematic working capital optimization:
- **Cash Conversion Cycle**: Days sales outstanding, inventory, and payable optimization
- **Cash Management**: Liquidity planning with cash flow forecasting
- **Accounts Receivable**: Collection optimization with credit policy management
- **Inventory Management**: Stock optimization with carrying cost minimization
- **Accounts Payable**: Payment timing with supplier relationship optimization
- **Short-Term Financing**: Credit facilities with liquidity backup planning

**Working Capital Optimization:**
- **Cash Flow Timing**: Receipt and payment optimization with float management
- **Credit Policy**: Customer credit assessment with collection procedures
- **Inventory Control**: Stock level optimization with demand forecasting
- **Supplier Management**: Payment terms negotiation with relationship optimization
- **Banking Relationships**: Credit facilities with cash management services
- **International Considerations**: Foreign exchange with hedging strategies

=== SECTION 4: RISK MANAGEMENT & FINANCIAL CONTROLS (225 words) ===

**7. FINANCIAL RISK MANAGEMENT (Risk Assessment Framework):**
Using comprehensive risk evaluation:
- **Market Risk**: Interest rate, foreign exchange, and commodity price exposure
- **Credit Risk**: Customer default and counterparty risk assessment
- **Liquidity Risk**: Cash flow timing with funding availability
- **Operational Risk**: Process failure with internal control assessment
- **Strategic Risk**: Business model with competitive positioning
- **Regulatory Risk**: Compliance requirement with policy change impact

**Risk Mitigation Strategies:**
- **Hedging Instruments**: Derivatives with risk transfer mechanisms
- **Insurance Coverage**: Property, liability, and business interruption protection
- **Diversification**: Revenue stream and geographic risk spreading
- **Credit Management**: Customer assessment with collection procedures
- **Contingency Planning**: Emergency funding with crisis management
- **Internal Controls**: Process documentation with audit procedures

**8. FINANCIAL CONTROLS & GOVERNANCE (Internal Control Framework):**
Using systematic control implementation:
- **Internal Controls**: COSO framework with control environment assessment
- **Segregation of Duties**: Authorization, recording, and custody separation
- **Financial Reporting**: Accuracy and timeliness with compliance verification
- **Audit Function**: Internal and external audit with control testing
- **Compliance Monitoring**: Regulatory requirement with policy adherence
- **Performance Monitoring**: KPI tracking with variance analysis

**Control Environment:**
- **Board Oversight**: Financial supervision with audit committee function
- **Management Philosophy**: Risk tolerance with ethical behavior
- **Organizational Structure**: Authority and responsibility with accountability
- **Human Resources**: Competency requirements with background verification
- **Information Systems**: Data integrity with access controls
- **Communication**: Policy dissemination with training programs

**9. PERFORMANCE MEASUREMENT & VALUE CREATION (Value-Based Management):**
Using value-focused assessment:
- **Economic Value Added (EVA)**: Value creation measurement with cost of capital
- **Return on Invested Capital**: Profitability assessment with capital efficiency
- **Cash Return on Investment**: Cash-based performance with sustainability
- **Market Value Added**: Shareholder value with market assessment
- **Total Shareholder Return**: Stock performance with dividend consideration
- **Balanced Scorecard**: Multi-perspective performance with strategic alignment

**Value Creation Drivers:**
- **Revenue Growth**: Market expansion with pricing optimization
- **Margin Improvement**: Cost management with efficiency enhancement
- **Capital Efficiency**: Asset utilization with working capital optimization
- **Risk Management**: Volatility reduction with predictability improvement
- **Strategic Positioning**: Competitive advantage with market leadership
- **Innovation Investment**: Growth opportunity with future value creation

**10. FINANCIAL STRATEGY & LONG-TERM PLANNING (Strategic Finance Framework):**
Using comprehensive strategic planning:
- **Financial Strategy**: Capital allocation with shareholder value creation
- **Growth Financing**: Funding strategy with capital structure optimization
- **Merger & Acquisition**: Inorganic growth with synergy realization
- **International Expansion**: Global financing with currency risk management
- **Exit Strategy**: Liquidity planning with value realization
- **Succession Planning**: Ownership transition with continuity assurance

**Strategic Financial Planning:**
- **Long-Term Forecasting**: Multi-year projection with scenario planning
- **Capital Market Access**: Debt and equity financing with timing optimization
- **Tax Planning**: Structure optimization with compliance assurance
- **Estate Planning**: Ownership transfer with tax minimization
- **Stakeholder Management**: Investor relations with communication strategy
- **Performance Benchmarking**: Industry comparison with best practice adoption

**COMPREHENSIVE FINANCIAL ANALYSIS INTEGRATION:**
This analysis incorporates:
- **412 financial variables** across all assessment dimensions
- **10 evidence-based methodologies** using validated financial management and corporate finance frameworks
- **Established approaches** (DuPont analysis, DCF valuation, working capital management, risk assessment)
- **Performance measurement systems** with quantified financial metrics and benchmarking
- **Practical financial strategies** with implementation guidance and value creation focus
- **Risk management integration** with comprehensive financial control and governance systems
"""
},

"innovation_ecosystem": {
    "title": "Creative Intelligence & Future Adaptation",
    "word_target": 850,
    "analysis_requirements": """
EVIDENCE-BASED INNOVATION ECOSYSTEM ANALYSIS - INNOVATION MANAGEMENT & CREATIVE CAPABILITY DEVELOPMENT
**COMPLETE INNOVATION ASSESSMENT WITH VALIDATED CREATIVITY & INNOVATION METHODOLOGIES**

=== SECTION 1: INNOVATION CAPABILITY ASSESSMENT & CREATIVE INTELLIGENCE (212 words) ===

**COMPREHENSIVE INNOVATION-ADAPTATION VARIABLE INTEGRATION (439 variables):**

**CORE INNOVATION ASSESSMENT:**
- Profile 7 (Intellectual Stimulation Preferences): Learning and development interest patterns with innovation catalyst identification
- Profile 9 (Business Curiosity Areas): Topic fascination analysis with creative exploration tendencies
- Profile 15 (Inspiration Sources): Motivation triggers with innovation energy assessment
- Growth 9-12 (Strategic Innovation): Growth focus with barrier-to-innovation analysis
- Analyst Growth 4-5 (Innovation Approach): Innovation maturity from reactive to category creation
- Component Innovation (All Phases): Innovation capability evolution from foundation through enterprise

**EVIDENCE-BASED METHODOLOGIES:**

**1. INNOVATION CAPABILITY ASSESSMENT (Innovation Management Framework):**
Using established innovation evaluation methods:
- **Innovation Readiness**: Organizational capacity for breakthrough development with capability assessment
- **Creative Climate Evaluation**: Environment supporting innovation using validated creativity scales
- **Innovation Process Maturity**: Systematic innovation process from idea generation through commercialization
- **Resource Allocation**: Innovation investment patterns with portfolio management principles
- **Innovation Culture Assessment**: Cultural factors supporting creativity using validated instruments
- **Innovation Performance Measurement**: Success metrics with benchmark comparison and tracking

**Innovation Capability Dimensions:**
- **Idea Generation**: Creative input mechanisms with systematic ideation processes
- **Concept Development**: Idea refinement with feasibility assessment and business case development
- **Innovation Pipeline**: Portfolio management with stage-gate processes and resource allocation
- **Commercialization**: Market introduction with scaling and adoption strategies
- **Innovation Leadership**: Management support with innovation championing and resource provision
- **Learning Orientation**: Knowledge acquisition with adaptation capability and continuous improvement

**2. CREATIVE PROBLEM-SOLVING METHODOLOGIES (Design Thinking Framework):**
Using systematic creative approaches:
- **Design Thinking Process**: Empathize, Define, Ideate, Prototype, Test with human-centered innovation
- **Creative Problem Solving**: Osborn-Parnes model with divergent and convergent thinking phases
- **SCAMPER Technique**: Substitute, Combine, Adapt, Modify, Put to other uses, Eliminate, Reverse
- **Brainstorming Methods**: Traditional brainstorming, brainwriting, and electronic brainstorming with facilitation
- **Mind Mapping**: Visual thinking with associative idea development and concept organization
- **Lateral Thinking**: Edward de Bono methods with alternative perspective development

**Creative Process Components:**
- **Problem Definition**: Challenge identification with constraint analysis and opportunity framing
- **Idea Generation**: Divergent thinking with quantity emphasis and judgment deferral
- **Idea Evaluation**: Convergent thinking with criteria application and concept selection
- **Solution Development**: Concept refinement with prototype development and testing
- **Implementation Planning**: Action planning with resource allocation and timeline development
- **Solution Validation**: Testing and refinement with feedback integration and optimization

**3. INNOVATION SYSTEMS ANALYSIS (Systems Innovation Framework):**
Using comprehensive innovation ecosystem approaches:
- **Innovation Ecosystem Mapping**: Stakeholder identification with relationship analysis and value flow
- **Open Innovation**: External collaboration with partner integration and knowledge sharing
- **Innovation Networks**: Relationship management with knowledge transfer and collaborative development
- **Innovation Platforms**: Infrastructure development with ecosystem enablement and scaling
- **Innovation Partnerships**: Strategic alliances with joint development and risk sharing
- **Innovation Communities**: Internal and external communities with knowledge sharing and collaboration

=== SECTION 2: TECHNOLOGY INNOVATION & DIGITAL TRANSFORMATION (212 words) ===

**4. TECHNOLOGY INNOVATION ASSESSMENT (Technology Management Framework):**
Using systematic technology evaluation:
- **Technology Readiness**: Maturity assessment using established TRL (Technology Readiness Level) scales
- **Digital Innovation Capability**: Technology adoption with digital transformation readiness
- **Emerging Technology Assessment**: New technology evaluation with impact and adoption potential
- **Technology Integration**: System integration with legacy system compatibility and migration
- **Innovation Technology Stack**: Platform assessment with scalability and flexibility evaluation
- **Technology Partnership**: Vendor relationships with technology access and capability enhancement

**Technology Innovation Categories:**
- **Process Innovation**: Operational improvement with efficiency enhancement and cost reduction
- **Product Innovation**: Offering enhancement with feature development and customer value
- **Service Innovation**: Service delivery with customer experience and satisfaction improvement
- **Business Model Innovation**: Revenue model with value creation and delivery transformation
- **Marketing Innovation**: Customer engagement with channel optimization and experience enhancement
- **Organizational Innovation**: Structure and process with capability development and effectiveness

**5. DIGITAL INNOVATION STRATEGY (Digital Transformation Framework):**
Using systematic digital innovation approaches:
- **Digital Strategy Development**: Technology vision with strategic alignment and roadmap planning
- **Data Analytics Innovation**: Information utilization with insight generation and decision support
- **Artificial Intelligence**: AI application with automation and intelligence enhancement
- **Platform Development**: Ecosystem creation with network effects and value aggregation
- **Digital Customer Experience**: Interface optimization with user experience and satisfaction
- **Digital Operations**: Process digitization with efficiency improvement and cost optimization

**Digital Innovation Implementation:**
- **Proof of Concept**: Technology validation with small-scale testing and learning
- **Pilot Programs**: Limited deployment with performance measurement and optimization
- **Scaling Strategy**: Full deployment with change management and adoption support
- **Performance Monitoring**: Success measurement with KPI tracking and optimization
- **Continuous Improvement**: Iterative enhancement with feedback integration and adaptation
- **Innovation Culture**: Digital mindset with skill development and change readiness

=== SECTION 3: COLLABORATIVE INNOVATION & KNOWLEDGE MANAGEMENT (213 words) ===

**6. COLLABORATIVE INNOVATION (Open Innovation Framework):**
Using systematic collaboration approaches:
- **Internal Collaboration**: Cross-functional innovation with team integration and knowledge sharing
- **External Partnerships**: Supplier, customer, and academic collaboration with joint innovation
- **Innovation Communities**: Professional networks with knowledge exchange and peer learning
- **Crowdsourcing**: External idea generation with community engagement and solution development
- **Innovation Competitions**: Challenge-based innovation with incentive systems and recognition
- **Joint Ventures**: Partnership development with shared risk and resource pooling

**Collaboration Success Factors:**
- **Trust Building**: Relationship development with transparency and reliability
- **Knowledge Sharing**: Information exchange with intellectual property management
- **Goal Alignment**: Objective coherence with mutual benefit and win-win outcomes
- **Communication Systems**: Information flow with regular updates and feedback loops
- **Resource Coordination**: Asset sharing with complementary capability utilization
- **Performance Management**: Joint measurement with success tracking and optimization

**7. KNOWLEDGE MANAGEMENT FOR INNOVATION (Knowledge Management Framework):**
Using systematic knowledge approaches:
- **Knowledge Creation**: New knowledge development with research and experimentation
- **Knowledge Capture**: Experience documentation with learning preservation and storage
- **Knowledge Sharing**: Information distribution with accessibility and utilization
- **Knowledge Application**: Practical utilization with implementation and value creation
- **Knowledge Storage**: Repository management with organization and retrieval systems
- **Knowledge Networks**: Relationship systems with expert identification and access

**Knowledge Management Components:**
- **Explicit Knowledge**: Documented information with formal knowledge repositories
- **Tacit Knowledge**: Experience-based wisdom with socialization and mentoring
- **Knowledge Mapping**: Expertise location with skill inventory and expert networks
- **Learning Systems**: Continuous education with skill development and capability building
- **Innovation Memory**: Historical learning with pattern recognition and experience application
- **Knowledge Culture**: Sharing orientation with collaboration encouragement and recognition

=== SECTION 4: INNOVATION PERFORMANCE & CONTINUOUS IMPROVEMENT (213 words) ===

**8. INNOVATION METRICS & PERFORMANCE MEASUREMENT (Performance Management Framework):**
Using comprehensive innovation assessment:
- **Innovation Input Metrics**: Investment measurement with resource allocation and funding analysis
- **Innovation Process Metrics**: Efficiency assessment with cycle time and conversion rates
- **Innovation Output Metrics**: Result measurement with new product/service development
- **Innovation Outcome Metrics**: Impact assessment with revenue generation and market success
- **Innovation Culture Metrics**: Environment assessment with engagement and participation
- **Innovation ROI**: Return measurement with investment justification and value demonstration

**Innovation Performance Indicators:**
- **Idea Generation Rate**: Creative input with quantity and quality measurement
- **Innovation Pipeline Health**: Portfolio strength with stage progression and success probability
- **Time to Market**: Development speed with competitive advantage and opportunity capture
- **Innovation Success Rate**: Project success with commercial viability and market acceptance
- **Revenue from Innovation**: Financial impact with growth contribution and profitability
- **Customer Satisfaction**: Market response with adoption rate and feedback analysis

**9. CONTINUOUS INNOVATION IMPROVEMENT (Continuous Improvement Framework):**
Using systematic enhancement approaches:
- **Innovation Process Optimization**: Workflow improvement with efficiency enhancement
- **Learning Integration**: Experience application with knowledge utilization and sharing
- **Best Practice Development**: Success pattern identification with replication and scaling
- **Innovation Capability Building**: Skill development with competency enhancement and training
- **Innovation Culture Evolution**: Environment enhancement with engagement and motivation
- **Innovation Strategy Refinement**: Approach optimization with strategic alignment and focus

**Improvement Methodologies:**
- **Plan-Do-Check-Act**: Systematic improvement with testing and validation
- **Benchmarking**: Performance comparison with best practice identification
- **Root Cause Analysis**: Problem identification with solution development
- **Process Reengineering**: Fundamental redesign with breakthrough improvement
- **Kaizen**: Continuous small improvements with cultural integration
- **Innovation Audits**: Systematic assessment with gap identification and improvement planning

**10. INNOVATION LEADERSHIP DEVELOPMENT (Leadership Development Framework):**
Using systematic leadership enhancement:
- **Innovation Leadership Competencies**: Skill identification with development planning
- **Change Leadership**: Transformation capability with resistance management and vision communication
- **Creative Leadership**: Inspiration ability with creative environment creation
- **Collaborative Leadership**: Partnership skills with network development and management
- **Strategic Leadership**: Vision development with innovation strategy and implementation
- **Learning Leadership**: Continuous development with adaptation and knowledge integration

**Leadership Development Components:**
- **Innovation Mindset**: Thinking patterns with creativity encouragement and risk tolerance
- **Innovation Skills**: Practical capabilities with tool utilization and process management
- **Innovation Behaviors**: Action patterns with modeling and culture creation
- **Innovation Networks**: Relationship building with external connection and collaboration
- **Innovation Communication**: Message delivery with vision sharing and engagement
- **Innovation Measurement**: Performance tracking with success demonstration and improvement

**COMPREHENSIVE INNOVATION ANALYSIS INTEGRATION:**
This analysis incorporates:
- **439 innovation variables** across all assessment dimensions
- **10 evidence-based methodologies** using validated innovation management and creativity frameworks
- **Established approaches** (Design Thinking, Open Innovation, Technology Readiness Levels, Knowledge Management)
- **Performance measurement systems** with quantified innovation metrics and success tracking
- **Practical innovation strategies** with implementation guidance and capability development
- **Leadership development integration** with innovation culture and collaborative capability building
"""
}



    }

# ======================================================
# STEP 2: Replace your existing generate_people_ops_section_with_dedicated_client function with this:
# ======================================================

def generate_people_ops_section_with_dedicated_client(
    section_name: str,
    section_config: Dict,
    complete_raw_data: Dict,
    api_key: str,
    section_index: int,
    max_retries: int = 3
) -> Dict:
    """FIXED: Generate people & ops section with enhanced retry mechanism and API key reset"""
    
    client_id = f"people_ops_section_{section_index}_{section_name}"
    original_api_key = api_key  # Keep track of original key
    current_api_key = api_key   # Current key being used
    
    # ENHANCED: Log initial API key selection and health with comprehensive metrics
    key_health = api_key_health.get(current_api_key, {})
    success_rate = key_health.get('success_rate', 1.0)
    current_load = key_health.get('current_load', 0)
    consecutive_failures = key_health.get('consecutive_failures', 0)
    total_requests = key_health.get('total_requests', 0)
    avg_response = statistics.mean(key_health.get('response_times', [0])) if key_health.get('response_times') else 0
    
    logging.info(f"üîë [{client_id}] STARTING SECTION GENERATION")
    logging.info(f"üîë [{client_id}] Initial API key: {key_health.get('key_id', 'unknown')} (...{current_api_key[-4:]})")
    logging.info(f"üîë [{client_id}] Initial key health:")
    logging.info(f"   - Consecutive Failures: {consecutive_failures}")
    logging.info(f"   - Total Requests: {total_requests}")
    logging.info(f"   - Success Rate: {success_rate:.3f}")
    logging.info(f"   - Current Load: {current_load}")
    logging.info(f"   - Avg Response Time: {avg_response:.1f}s")
    logging.info(f"üîë [{client_id}] Overall API ecosystem: {get_api_key_status_summary()}")
    
    # Track attempts for comprehensive analysis
    attempt_history = []
    
    for retry_attempt in range(max_retries):
        attempt_start_time = time.time()
        attempt_info = {
            'attempt_number': retry_attempt + 1,
            'api_key_used': current_api_key[-4:],
            'start_time': attempt_start_time,
            'success': False,
            'error': None,
            'words_generated': 0,
            'tokens_used': 0,
            'key_switched': False
        }
        
        try:
            # CRITICAL FIX: Reset API key and select new one for retries
            if retry_attempt > 0:
                logging.info(f"üîÑ [{client_id}] RETRY {retry_attempt + 1}: Starting retry process...")
                
                # STEP 2a: Reset the current API key to clear its failure state
                logging.info(f"üîß [{client_id}] Resetting current API key before retry...")
                reset_api_key_immediately(current_api_key)
                
                # STEP 2b: Select optimal API key for retry with enhanced strategy
                logging.info(f"üéØ [{client_id}] Selecting optimal API key for retry...")
                retry_key_start = time.time()
                
                # Use different selection strategy based on retry attempt
                if retry_attempt == 1:
                    # First retry: Use load balancing
                    try:
                        new_api_key = get_load_balanced_api_key(section_index)
                        selection_method = "load_balanced"
                        logging.info(f"‚úÖ [{client_id}] Load balancing selection successful")
                    except Exception as lb_error:
                        logging.warning(f"‚ö†Ô∏è [{client_id}] Load balancing failed: {lb_error}, using smart selection")
                        new_api_key = get_smart_api_key(section_index, retry_attempt)
                        selection_method = "smart_fallback"
                else:
                    # Later retries: Use smart selection
                    new_api_key = get_smart_api_key(section_index, retry_attempt)
                    selection_method = "smart_selection"
                
                key_selection_time = time.time() - retry_key_start
                
                # Track if key actually changed
                key_switched = new_api_key != current_api_key
                attempt_info['key_switched'] = key_switched
                
                if key_switched:
                    old_key_health = api_key_health.get(current_api_key, {})
                    new_key_health = api_key_health.get(new_api_key, {})
                    
                    logging.info(f"üîÑ [{client_id}] KEY SWITCH EXECUTED:")
                    logging.info(f"   - Old key: {old_key_health.get('key_id', 'unknown')} (...{current_api_key[-4:]})")
                    logging.info(f"   - New key: {new_key_health.get('key_id', 'unknown')} (...{new_api_key[-4:]})")
                    logging.info(f"   - Selection method: {selection_method}")
                    logging.info(f"   - Selection time: {key_selection_time:.3f}s")
                    logging.info(f"   - Old key failures: {old_key_health.get('consecutive_failures', 0)}")
                    logging.info(f"   - New key failures: {new_key_health.get('consecutive_failures', 0)}")
                    logging.info(f"   - New key success rate: {new_key_health.get('success_rate', 1.0):.3f}")
                    
                    current_api_key = new_api_key
                else:
                    logging.info(f"üîÑ [{client_id}] KEY REUSED: Same key selected (...{current_api_key[-4:]})")
                    logging.info(f"   - Selection method: {selection_method}")
                    logging.info(f"   - Selection time: {key_selection_time:.3f}s")
                    logging.info(f"   - Key was reset before reuse")
                
                # Update attempt info
                attempt_info['api_key_used'] = current_api_key[-4:]
                attempt_info['key_switched'] = key_switched
                attempt_info['selection_method'] = selection_method
                
                # Log new key health metrics
                current_key_health = api_key_health.get(current_api_key, {})
                current_success_rate = current_key_health.get('success_rate', 1.0)
                current_key_load = current_key_health.get('current_load', 0)
                
                logging.info(f"üîë [{client_id}] Selected key metrics for retry:")
                logging.info(f"   - Key ID: {current_key_health.get('key_id', 'unknown')}")
                logging.info(f"   - Success Rate: {current_success_rate:.3f}")
                logging.info(f"   - Current Load: {current_key_load}")
                logging.info(f"   - Consecutive Failures: {current_key_health.get('consecutive_failures', 0)}")
            
            # ENHANCED: Log attempt details
            current_key_health = api_key_health.get(current_api_key, {})
            current_success_rate = current_key_health.get('success_rate', 1.0)
            current_key_load = current_key_health.get('current_load', 0)
            current_avg_response = statistics.mean(current_key_health.get('response_times', [0])) if current_key_health.get('response_times') else 0
            
            logging.info(f"üöÄ [{client_id}] ATTEMPT {retry_attempt + 1}/{max_retries} DETAILS:")
            logging.info(f"   - API Key: {current_key_health.get('key_id', 'unknown')} (...{current_api_key[-4:]})")
            logging.info(f"   - Key Health: {current_key_health.get('consecutive_failures', 0)} failures, "
                        f"{current_key_health.get('total_requests', 0)} total requests")
            logging.info(f"   - Success Rate: {current_success_rate:.3f}")
            logging.info(f"   - Current Load: {current_key_load}")
            logging.info(f"   - Avg Response Time: {current_avg_response:.1f}s")
            logging.info(f"   - Target Words: {section_config['word_target']:,}")
            logging.info(f"   - Section: {section_name}")
            logging.info(f"   - Max Tokens: 1,000,000")
            
            # CRITICAL: Execute the analysis
            logging.info(f"üéØ [{client_id}] Executing people & ops analysis...")
            analysis_start_time = time.time()
            
            target_words = min(section_config["word_target"], 3000)
            
            response = people_ops_ultra_deep_analysis(
                complete_raw_data=complete_raw_data,
                analysis_type=section_name,
                analysis_requirements=section_config["analysis_requirements"],
                api_key=current_api_key,
                client_id=client_id,
                temperature=0.7,
                max_tokens=1000000
            )
            
            analysis_time = time.time() - analysis_start_time
            current_words = len(response.content.split())
            
            logging.info(f"üìä [{client_id}] Analysis completed:")
            logging.info(f"   - Analysis time: {analysis_time:.2f}s")
            logging.info(f"   - Words generated: {current_words:,}")
            logging.info(f"   - Tokens used: {response.token_count:,}")
            logging.info(f"   - Target words: {target_words:,}")
            logging.info(f"   - Word ratio: {(current_words/target_words)*100:.1f}% of target")
            
            # ENHANCED: Response quality validation
            if current_words < 100 and retry_attempt < max_retries - 1:
                logging.warning(f"‚ö†Ô∏è [{client_id}] RESPONSE TOO SHORT: {current_words} words < 100 minimum")
                logging.warning(f"üîç [{client_id}] Short response analysis:")
                logging.warning(f"   - API key: {current_key_health.get('key_id', 'unknown')} (...{current_api_key[-4:]})")
                logging.warning(f"   - Key success rate: {current_success_rate:.3f}")
                logging.warning(f"   - Key load: {current_key_load}")
                logging.warning(f"   - Response preview: '{response.content[:200]}...'")
                
                # Update attempt history
                attempt_info.update({
                    'success': False,
                    'error': f'Response too short: {current_words} words',
                    'words_generated': current_words,
                    'tokens_used': response.token_count,
                    'analysis_time': analysis_time
                })
                attempt_history.append(attempt_info)
                
                # CRITICAL FIX: Mark this as a failure and reset the key
                logging.warning(f"üîß [{client_id}] Marking short response as failure and resetting key...")
                update_api_key_health(current_api_key, success=False, error_code="SHORT_RESPONSE")
                reset_api_key_immediately(current_api_key)
                
                # Calculate smart wait time
                wait_time = 30 * (retry_attempt + 1)
                logging.info(f"‚è≥ [{client_id}] Waiting {wait_time}s before retry due to short response...")
                time.sleep(wait_time)
                continue
            
            # SUCCESS: Log detailed success metrics
            total_attempt_time = time.time() - attempt_start_time
            final_key_health = api_key_health.get(current_api_key, {})
            final_success_rate = final_key_health.get('success_rate', 1.0)
            final_load = final_key_health.get('current_load', 0)
            
            # Update attempt history
            attempt_info.update({
                'success': True,
                'words_generated': current_words,
                'tokens_used': response.token_count,
                'analysis_time': analysis_time,
                'total_attempt_time': total_attempt_time
            })
            attempt_history.append(attempt_info)
            
            logging.info(f"üéâ [{client_id}] SECTION GENERATION SUCCESS!")
            logging.info(f"‚úÖ [{client_id}] Success metrics:")
            logging.info(f"   - Words Generated: {current_words:,}")
            logging.info(f"   - Tokens Used: {response.token_count:,}")
            logging.info(f"   - Analysis Time: {analysis_time:.2f}s")
            logging.info(f"   - Total Attempt Time: {total_attempt_time:.2f}s")
            logging.info(f"   - API Key Used: {final_key_health.get('key_id', 'unknown')} (...{current_api_key[-4:]})")
            logging.info(f"   - Final Key Performance: Success Rate: {final_success_rate:.3f}, Load: {final_load}")
            logging.info(f"   - Total Key Requests: {final_key_health.get('total_requests', 0)}")
            logging.info(f"   - Retry Attempts: {retry_attempt + 1}")
            logging.info(f"   - Key Switched: {current_api_key != original_api_key}")
            
            # Log attempt history summary
            if len(attempt_history) > 1:
                logging.info(f"üìà [{client_id}] Attempt history summary:")
                for i, attempt in enumerate(attempt_history):
                    status = "‚úÖ SUCCESS" if attempt['success'] else "‚ùå FAILED"
                    logging.info(f"   - Attempt {i+1}: {status} | Key: ...{attempt['api_key_used']} | "
                                f"Words: {attempt['words_generated']} | Time: {attempt.get('analysis_time', 0):.1f}s")
            
            return {
                "title": section_config["title"],
                "content": response.content,
                "metadata": {
                    "word_target": target_words,
                    "words_generated": current_words,
                    "tokens_generated": response.token_count,
                    "ai_analysis_time": analysis_time,
                    "ai_model": "gemini-2.5-pro-people-ops",
                    "analysis_type": "people_ops_dedicated_analysis",
                    "timestamp": datetime.now().isoformat(),
                    "client_id": client_id,
                    "retry_attempts": retry_attempt + 1,
                    "success": True,
                    # Enhanced metadata with API key tracking and reset functionality
                    "api_key_used": current_key_health.get('key_id', 'unknown'),
                    "api_key_suffix": current_api_key[-4:],
                    "key_switched": current_api_key != original_api_key,
                    "key_reset_used": retry_attempt > 0,  # Track if reset was used
                    "original_key": original_api_key[-4:],
                    "final_key": current_api_key[-4:],
                    "load_balancing_used": retry_attempt == 1,
                    "attempt_history": attempt_history,  # Full attempt history
                    "api_key_health_at_completion": {
                        "consecutive_failures": final_key_health.get('consecutive_failures', 0),
                        "total_requests": final_key_health.get('total_requests', 0),
                        "success_rate": final_success_rate,
                        "current_load": final_load,
                        "key_status": "healthy" if final_key_health.get('consecutive_failures', 0) == 0 else "degraded",
                        "avg_response_time": statistics.mean(final_key_health.get('response_times', [0])) if final_key_health.get('response_times') else 0
                    }
                }
            }
            
        except Exception as e:
            error_str = str(e)
            retry_number = retry_attempt + 1
            attempt_time = time.time() - attempt_start_time
            
            # Update attempt history
            attempt_info.update({
                'success': False,
                'error': error_str,
                'analysis_time': attempt_time,
                'total_attempt_time': attempt_time
            })
            attempt_history.append(attempt_info)
            
            # ENHANCED: Error logging with comprehensive API key context
            current_key_health = api_key_health.get(current_api_key, {})
            current_success_rate = current_key_health.get('success_rate', 1.0)
            current_key_load = current_key_health.get('current_load', 0)
            current_failures = current_key_health.get('consecutive_failures', 0)
            
            logging.error(f"‚ùå [{client_id}] ATTEMPT {retry_number} FAILED")
            logging.error(f"üîç [{client_id}] Failure details:")
            logging.error(f"   - Error: {error_str}")
            logging.error(f"   - Error type: {type(e).__name__}")
            logging.error(f"   - Attempt time: {attempt_time:.2f}s")
            logging.error(f"   - API Key: {current_key_health.get('key_id', 'unknown')} (...{current_api_key[-4:]})")
            logging.error(f"   - Key failures before attempt: {current_failures}")
            logging.error(f"   - Key success rate: {current_success_rate:.3f}")
            logging.error(f"   - Key load: {current_key_load}")
            
            # ENHANCED: Error type analysis for intelligent retry strategy
            is_503_error = "503" in error_str
            is_429_error = "429" in error_str
            is_overload_error = "overloaded" in error_str.lower() or "service unavailable" in error_str.lower()
            is_api_key_issue = any(code in error_str for code in ["401", "403", "invalid", "unauthorized"])
            is_content_issue = any(indicator in error_str.lower() for indicator in ["short", "empty", "metadata"])
            is_timeout_issue = "timeout" in error_str.lower()
            
            logging.error(f"üîç [{client_id}] Error classification:")
            logging.error(f"   - 503/Overload: {is_503_error or is_overload_error}")
            logging.error(f"   - Rate limit (429): {is_429_error}")
            logging.error(f"   - API key issue: {is_api_key_issue}")
            logging.error(f"   - Content issue: {is_content_issue}")
            logging.error(f"   - Timeout issue: {is_timeout_issue}")
            
            if retry_attempt < max_retries - 1:
                # ENHANCED: Intelligent wait time calculation based on error type
                if is_503_error or is_overload_error:
                    wait_time = 300 + (retry_attempt * 180)  # 5min, 8min, 11min for 503/overload
                    logging.warning(f"üö® [{client_id}] API OVERLOAD - Extended wait: {wait_time}s")
                    
                    # Log ecosystem health during overload
                    ecosystem_health = get_enhanced_api_key_status()
                    healthy_keys = ecosystem_health.get('healthy_keys', 0)
                    logging.warning(f"üîë [{client_id}] Ecosystem during overload: {healthy_keys} healthy keys")
                    
                elif is_429_error:
                    wait_time = 120 + (retry_attempt * 60)   # 2min, 3min, 4min for rate limits
                    logging.warning(f"üö® [{client_id}] RATE LIMIT - Moderate wait: {wait_time}s")
                    
                elif is_api_key_issue:
                    wait_time = 30  # Quick retry with different key for key issues
                    logging.warning(f"üö® [{client_id}] API KEY ISSUE - Quick retry: {wait_time}s")
                    
                elif is_content_issue:
                    wait_time = 45 + (retry_attempt * 30)   # 45s, 75s, 105s for content issues
                    logging.warning(f"üö® [{client_id}] CONTENT ISSUE - Medium wait: {wait_time}s")
                    
                elif is_timeout_issue:
                    wait_time = 90 + (retry_attempt * 60)   # 90s, 150s, 210s for timeouts
                    logging.warning(f"üö® [{client_id}] TIMEOUT ISSUE - Extended wait: {wait_time}s")
                    
                else:
                    wait_time = 60 * (retry_attempt + 1)    # Standard exponential backoff
                    logging.warning(f"‚ö†Ô∏è [{client_id}] GENERAL ERROR - Standard wait: {wait_time}s")
                
                # ENHANCED: Log comprehensive retry strategy
                next_strategy = "Load Balancing + Reset" if retry_attempt == 0 else "Smart Selection + Reset"
                logging.info(f"‚è≥ [{client_id}] RETRY STRATEGY:")
                logging.info(f"   - Wait Time: {wait_time}s")
                logging.info(f"   - Next Attempt: {retry_number + 1}/{max_retries}")
                logging.info(f"   - Next Key Strategy: {next_strategy}")
                logging.info(f"   - Error Category: {'API Overload' if is_503_error or is_overload_error else 'Rate Limit' if is_429_error else 'API Key Issue' if is_api_key_issue else 'Content Issue' if is_content_issue else 'Timeout' if is_timeout_issue else 'General Error'}")
                logging.info(f"   - Reset will be applied: True")
                
                # Log current ecosystem health before wait
                pre_wait_health = get_api_key_status_summary()
                logging.info(f"üîë [{client_id}] Pre-wait ecosystem health: {pre_wait_health}")
                
                time.sleep(wait_time)
                
                # Log ecosystem health after wait
                post_wait_health = get_api_key_status_summary()
                logging.info(f"üîë [{client_id}] Post-wait ecosystem health: {post_wait_health}")
                
                if pre_wait_health != post_wait_health:
                    logging.info(f"üìà [{client_id}] Ecosystem health improved during wait")
                
            else:
                # FINAL FAILURE: Comprehensive logging
                total_function_time = time.time() - attempt_history[0]['start_time'] if attempt_history else attempt_time
                final_key_health = api_key_health.get(current_api_key, {})
                final_success_rate = final_key_health.get('success_rate', 1.0)
                final_load = final_key_health.get('current_load', 0)
                
                logging.error(f"üí• [{client_id}] ALL ATTEMPTS EXHAUSTED - FINAL FAILURE")
                logging.error(f"üîç [{client_id}] Final failure analysis:")
                logging.error(f"   - Total attempts: {max_retries}")
                logging.error(f"   - Total function time: {total_function_time:.2f}s")
                logging.error(f"   - Original API Key: {api_key_health.get(original_api_key, {}).get('key_id', 'unknown')} (...{original_api_key[-4:]})")
                logging.error(f"   - Final API Key: {final_key_health.get('key_id', 'unknown')} (...{current_api_key[-4:]})")
                logging.error(f"   - Key Switched: {current_api_key != original_api_key}")
                logging.error(f"   - Reset Operations: {retry_attempt}")  # Number of resets performed
                logging.error(f"   - Final Key Performance: Success Rate: {final_success_rate:.3f}, Load: {final_load}")
                logging.error(f"   - Final Error: {error_str}")
                logging.error(f"   - Section: {section_name}")
                
                # Log comprehensive attempt history
                logging.error(f"üìà [{client_id}] Complete attempt history:")
                for i, attempt in enumerate(attempt_history):
                    status = "‚úÖ SUCCESS" if attempt['success'] else "‚ùå FAILED"
                    key_switched_marker = " (KEY SWITCHED)" if attempt.get('key_switched') else ""
                    reset_marker = " (RESET APPLIED)" if i > 0 else ""
                    
                    logging.error(f"   - Attempt {i+1}: {status} | Key: ...{attempt['api_key_used']}{key_switched_marker}{reset_marker}")
                    logging.error(f"     Words: {attempt['words_generated']} | Tokens: {attempt.get('tokens_used', 0)} | Time: {attempt.get('analysis_time', 0):.1f}s")
                    if attempt.get('error'):
                        logging.error(f"     Error: {attempt['error']}")
                
                # Log final ecosystem state
                final_ecosystem = get_enhanced_api_key_status()
                logging.error(f"üîë [{client_id}] Final ecosystem state:")
                logging.error(f"   - Healthy keys: {final_ecosystem.get('healthy_keys', 0)}/{final_ecosystem.get('total_keys', 0)}")
                logging.error(f"   - Failed keys: {final_ecosystem.get('failed_keys', 0)}")
                logging.error(f"   - Cooling down: {final_ecosystem.get('cooling_down', 0)}")
                logging.error(f"   - Total ecosystem load: {final_ecosystem.get('total_load', 0)}")
                
                # ENHANCED: Fallback content with comprehensive error context
                fallback_content = f"""This people & operations section encountered persistent API issues during generation.

SECTION DETAILS:
- Section: {section_config['title']}
- Target Words: {section_config.get('word_target', 'Unknown'):,}
- Analysis Type: {section_name}

FAILURE ANALYSIS:
- Total Attempts: {max_retries}
- API Keys Tried: {len(set([attempt['api_key_used'] for attempt in attempt_history]))}
- Key Resets Applied: {retry_attempt}
- Load Balancing Used: {max_retries > 1}
- Total Processing Time: {total_function_time:.1f}s

ATTEMPT BREAKDOWN:
{chr(10).join([f"‚Ä¢ Attempt {i+1}: {'Success' if attempt['success'] else 'Failed'} - Key: ...{attempt['api_key_used']} - {attempt['words_generated']} words" for i, attempt in enumerate(attempt_history)])}

FINAL ERROR: {error_str}

RECOMMENDATIONS:
- Regenerate during off-peak hours (2-6 AM UTC)
- Current API ecosystem has {final_ecosystem.get('healthy_keys', 0)} healthy keys available
- Consider upgrading to higher-tier Gemini API limits

CURRENT ECOSYSTEM STATUS: {get_api_key_status_summary()}

This analysis will be completed when API capacity is restored. The system has applied {retry_attempt} key resets and tried {len(set([attempt['api_key_used'] for attempt in attempt_history]))} different API keys to ensure maximum success probability."""
                
                return {
                    "title": section_config["title"],
                    "content": fallback_content,
                    "metadata": {
                        "error": True,
                        "error_message": error_str,
                        "timestamp": datetime.now().isoformat(),
                        "client_id": client_id,
                        "retry_attempts": max_retries,
                        "final_error": error_str,
                        # ENHANCED: Comprehensive error metadata with reset tracking
                        "api_key_attempts": {
                            "original_key": original_api_key[-4:],
                            "final_key": current_api_key[-4:],
                            "key_switched": current_api_key != original_api_key,
                            "keys_tried": len(set([attempt['api_key_used'] for attempt in attempt_history])),
                            "resets_applied": retry_attempt,  # Track number of resets
                            "load_balancing_attempted": max_retries > 1,
                            "attempt_history": attempt_history
                        },
                        "error_classification": {
                            "is_503_overload": is_503_error or is_overload_error,
                            "is_rate_limit": is_429_error,
                            "is_api_key_issue": is_api_key_issue,
                            "is_content_issue": is_content_issue,
                            "is_timeout_issue": is_timeout_issue,
                            "error_type": type(e).__name__
                        },
                        "api_health_at_failure": {
                            "ecosystem_summary": get_api_key_status_summary(),
                            "ecosystem_detailed": final_ecosystem,
                            "final_key_health": {
                                "consecutive_failures": final_key_health.get('consecutive_failures', 0),
                                "total_requests": final_key_health.get('total_requests', 0),
                                "success_rate": final_success_rate,
                                "current_load": final_load,
                                "avg_response_time": statistics.mean(final_key_health.get('response_times', [0])) if final_key_health.get('response_times') else 0
                            }
                        },
                        "recovery_recommendations": {
                            "retry_during_off_peak": "2-6 AM UTC for best API availability",
                            "healthy_keys_available": final_ecosystem.get('healthy_keys', 0),
                            "estimated_recovery_time": "15-30 minutes during peak hours",
                            "alternative_approach": "Consider breaking section into smaller parts"
                        }
                    }
                }
    
    # This should never be reached, but adding comprehensive logging just in case
    logging.error(f"üí• [{client_id}] UNEXPECTED CODE PATH - Function should have returned by now")
    logging.error(f"üîç [{client_id}] Debug info:")
    logging.error(f"   - max_retries: {max_retries}")
    logging.error(f"   - section_name: {section_name}")
    logging.error(f"   - attempt_history length: {len(attempt_history)}")
    logging.error(f"   - original_api_key: ...{original_api_key[-4:]}")
    logging.error(f"   - current_api_key: ...{current_api_key[-4:]}")
    
    return None


def generate_comprehensive_people_ops_report(complete_raw_data: Dict, report_id: str, max_report_retries: int = 2) -> Dict:
    """Generate comprehensive people & operations report with notifications and enhanced API key management"""
    
    logging.info(f"üöÄ Starting People & Operations Report Generation with Smart Notifications and Load Balancing for {report_id}")
    start_time = time.time()
    
    # Extract user data for personalized notifications
    user_id = complete_raw_data.get("user_id", "unknown")
    user_profile = complete_raw_data.get("user_profile", {})
    
    # People & ops notification tracking
    notifications_sent = {"start": False, "middle": False, "complete": False}
    
    # üîî NOTIFICATION 1: START - Personalized people & ops start message
    send_people_ops_notification_background(user_id, user_profile, "start")
    notifications_sent["start"] = True
    
    # Initialize API key health tracking for this report
    logging.info(f"üîë Initial API Key Health Status: {get_api_key_status_summary()}")
    
    for report_attempt in range(max_report_retries):
        logging.info(f"üîÑ People & ops report attempt {report_attempt + 1}/{max_report_retries}")
        
        people_ops_sections = get_people_ops_report_sections()
        
        report_data = {}
        failed_sections = []
        successful_sections = []
        
        # Track API key usage for this attempt
        api_keys_used = set()
        load_balancing_stats = {
            "total_sections": len(people_ops_sections),
            "load_balanced_selections": 0,
            "smart_selections": 0,
            "key_switches": 0
        }
        
        # Process sections in batches
        section_items = list(people_ops_sections.items())
        batch_size = 3
        
        for batch_start in range(0, len(section_items), batch_size):
            batch_end = min(batch_start + batch_size, len(section_items))
            batch = section_items[batch_start:batch_end]
            
            logging.info(f"üîÑ Processing people & ops batch {batch_start//batch_size + 1}: sections {batch_start+1}-{batch_end}")
            logging.info(f"üîë Pre-batch API Key Health: {get_api_key_status_summary()}")
            
            # Parallel processing within batch with enhanced API key management
            with ThreadPoolExecutor(max_workers=batch_size) as executor:
                future_to_section = {}
                
                for i, (section_name, section_config) in enumerate(batch):
                    # Enhanced API key selection strategy
                    section_index = batch_start + i
                    
                    # Use load balancing for better distribution
                    try:
                        api_key = get_load_balanced_api_key(section_index)
                        selection_method = "load_balanced"
                        load_balancing_stats["load_balanced_selections"] += 1
                    except Exception as e:
                        logging.warning(f"‚ö†Ô∏è Load balancing failed for section {section_index}, falling back to smart selection: {e}")
                        api_key = get_smart_api_key(section_index, 0)
                        selection_method = "smart_fallback"
                        load_balancing_stats["smart_selections"] += 1
                    
                    api_keys_used.add(api_key)
                    
                    # Log API key selection
                    key_health = api_key_health.get(api_key, {})
                    success_rate = key_health.get('success_rate', 1.0)
                    current_load = key_health.get('current_load', 0)
                    
                    logging.info(f"üîë Section {section_index + 1} ({section_name}): "
                                f"Using {key_health.get('key_id', 'unknown')} (...{api_key[-4:]}) "
                                f"[{selection_method}] - Success: {success_rate:.2f}, Load: {current_load}")
                    
                    if i > 0:
                        time.sleep(2)  # Delay between submissions to prevent overload
                    
                    future = executor.submit(
                        generate_people_ops_section_with_dedicated_client,
                        section_name=section_name,
                        section_config=section_config,
                        complete_raw_data=complete_raw_data,
                        api_key=api_key,
                        section_index=section_index,
                        max_retries=2
                    )
                    
                    future_to_section[future] = (section_name, section_index, api_key, selection_method)
                    logging.info(f"üì§ Submitted people & ops section {section_index + 1}/{len(section_items)}: {section_name}")
                
                # Collect batch results with enhanced tracking
                for future in as_completed(future_to_section):
                    section_name, section_index, original_api_key, selection_method = future_to_section[future]
                    
                    try:
                        section_content = future.result()
                        report_data[section_name] = section_content
                        
                        # Track API key switching
                        metadata = section_content.get("metadata", {})
                        if metadata.get("key_switched", False):
                            load_balancing_stats["key_switches"] += 1
                            logging.info(f"üîÑ Key switch detected for section {section_name}")
                        
                        # Track success/failure with API key context
                        if section_content.get("metadata", {}).get("error", False):
                            failed_sections.append(section_name)
                            
                            # Log API key performance on failure
                            final_key = metadata.get("final_key", "unknown")
                            logging.error(f"‚ùå People & ops section failed: {section_name} "
                                        f"(Original: ...{original_api_key[-4:]}, Final: ...{final_key}, Method: {selection_method})")
                        else:
                            successful_sections.append(section_name)
                            
                            # Log successful API key usage
                            words_generated = metadata.get("words_generated", 0)
                            api_key_used = metadata.get("api_key_used", "unknown")
                            analysis_time = metadata.get("ai_analysis_time", 0)
                            
                            logging.info(f"‚úÖ People & ops section completed: {section_name} "
                                        f"({words_generated:,} words, {analysis_time:.1f}s, Key: {api_key_used})")
                        
                        total_completed = len(successful_sections) + len(failed_sections)
                        
                        # Update job status
                        if report_id in people_ops_job_status:
                            completion_percentage = (total_completed / len(section_items)) * 100
                            people_ops_job_status[report_id]["message"] = f"People & ops processing: {total_completed}/{len(section_items)} sections ({completion_percentage:.1f}%)"
                            people_ops_job_status[report_id]["sections_completed"] = total_completed
                            
                            # üîî NOTIFICATION 2: MIDDLE - Smart check for ~50% completion
                            if not notifications_sent["middle"] and completion_percentage >= 45 and completion_percentage <= 65:
                                send_people_ops_notification_background(user_id, user_profile, "middle")
                                notifications_sent["middle"] = True
                        
                        logging.info(f"üìä People & ops progress: {total_completed}/{len(section_items)} sections completed")
                        
                    except Exception as e:
                        logging.error(f"‚ùå Error retrieving people & ops result for {section_name}: {str(e)}")
                        failed_sections.append(section_name)
            
            # Log post-batch API key health
            logging.info(f"üîë Post-batch API Key Health: {get_api_key_status_summary()}")
            
            # Wait between batches with intelligent timing based on API key health
            if batch_end < len(section_items):
                # Get current API key health to determine wait time
                enhanced_status = get_enhanced_api_key_status()
                healthy_keys = enhanced_status.get("healthy_keys", 0)
                total_load = enhanced_status.get("total_load", 0)
                
                # Adjust wait time based on API key health
                if healthy_keys <= 3 or total_load > 10:
                    wait_time = 90  # Longer wait if keys are stressed
                    logging.warning(f"‚ö†Ô∏è API keys under stress (healthy: {healthy_keys}, load: {total_load}), extended wait: {wait_time}s")
                elif healthy_keys <= 5:
                    wait_time = 75  # Medium wait
                    logging.info(f"‚è≥ Moderate API key health, medium wait: {wait_time}s")
                else:
                    wait_time = 65  # Standard wait
                    logging.info(f"‚è≥ Good API key health, standard wait: {wait_time}s")
                
                logging.info(f"‚è≥ People & ops batch wait: {wait_time}s before next batch...")
                time.sleep(wait_time)
        
        # Log comprehensive API key usage statistics for this attempt
        logging.info(f"üîë API Key Usage Statistics for Attempt {report_attempt + 1}:")
        logging.info(f"   - Unique Keys Used: {len(api_keys_used)}/{len(GEMINI_API_KEYS)}")
        logging.info(f"   - Load Balanced Selections: {load_balancing_stats['load_balanced_selections']}")
        logging.info(f"   - Smart Fallback Selections: {load_balancing_stats['smart_selections']}")
        logging.info(f"   - Key Switches During Processing: {load_balancing_stats['key_switches']}")
        logging.info(f"   - Final API Key Health: {get_api_key_status_summary()}")
        
        # Check success rate
        success_rate = len(successful_sections) / len(people_ops_sections)
        parallel_time = time.time() - start_time
        
        logging.info(f"üìä People & ops attempt {report_attempt + 1} completed: {len(successful_sections)}/{len(people_ops_sections)} sections successful ({success_rate:.1%})")
        
        if success_rate >= 0.8:
            logging.info(f"‚úÖ People & ops report successful with {success_rate:.1%} success rate")
            break
        else:
            logging.warning(f"‚ö†Ô∏è People & ops report attempt {report_attempt + 1} below threshold ({success_rate:.1%} < 80%)")
            if report_attempt < max_report_retries - 1:
                # Reset API key health for failed keys before retry
                reset_failed_api_keys()
                logging.info(f"üîÑ Reset failed API keys, retrying in 60s...")
                time.sleep(60)
    
    # Calculate final metrics
    total_time = time.time() - start_time
    total_words = sum([
        len(section.get("content", "").split()) 
        for section in report_data.values()
    ])
    
    logging.info(f"üåü People & Operations Report Completed: {len(successful_sections)} successful sections, {total_words:,} words")
    
    # üîî NOTIFICATION 3: COMPLETE - Personalized completion message
    if not notifications_sent["complete"]:
        send_people_ops_notification_background(user_id, user_profile, "complete")
        notifications_sent["complete"] = True
    
    # Add enhanced report metadata with multi-database intelligence tracking and API key statistics
    report_data["_enhanced_people_ops_report_metadata"] = {
        "report_id": report_id,
        "generation_timestamp": datetime.now().isoformat(),
        "total_sections": len(report_data),
        "successful_sections": len(successful_sections),
        "failed_sections": len(failed_sections),
        "success_rate": len(successful_sections) / len(people_ops_sections),
        "total_words": total_words,
        "total_generation_time": total_time,
        "ai_model": "gemini-2.5-pro-people-ops",
        "processing_method": "people_ops_parallel_analysis_load_balanced",
        "report_type": "comprehensive_people_operations_strategy",
        "notifications_sent": notifications_sent,
        "multi_database_integration": {
            "enabled": True,
            "data_sources_used": complete_raw_data.get("multi_database_intelligence", {}).get("data_sources_available", []),
            "intelligence_correlation_applied": True,
            "behavioral_customization": True,
            "personality_integration": True,
            "dream_alignment": True,
            "complete_qa_pairs": complete_raw_data.get("multi_database_intelligence", {}).get("complete_qa_data", {}).get("token_tracking", {}).get("qa_pairs_count", 0)
        },
        # Enhanced API key usage tracking
        "api_key_optimization": {
            "load_balancing_enabled": True,
            "unique_keys_used": len(api_keys_used),
            "total_keys_available": len(GEMINI_API_KEYS),
            "key_utilization_rate": len(api_keys_used) / len(GEMINI_API_KEYS),
            "load_balanced_selections": load_balancing_stats.get("load_balanced_selections", 0),
            "smart_fallback_selections": load_balancing_stats.get("smart_selections", 0),
            "key_switches_during_processing": load_balancing_stats.get("key_switches", 0),
            "final_api_health_summary": get_api_key_status_summary(),
            "enhanced_api_health": get_enhanced_api_key_status()
        }
    }
    
    return report_data


# ======================================================
#           Document Creation for People & Operations
# ======================================================

def create_people_ops_word_document(report_data: Dict, user_id: str) -> Document:
    """Create people & operations Word document with better formatting"""
    logging.info("üìÑ Creating People & Operations Word Document")
    
    doc = Document()
    
    # Enhanced styling
    style = doc.styles['Normal']
    style.font.name = 'Calibri'
    style.font.size = Pt(11)
    
    # Professional title page
    title = doc.add_heading("BACKABLE", 0)
    title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
    title_run = title.runs[0]
    title_run.font.size = Pt(42)
    title_run.font.bold = True
    title_run.font.color.rgb = RGBColor(0, 51, 102)
    
    subtitle = doc.add_heading("Comprehensive People & Operations Strategy Blueprint", 1)
    subtitle.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
    subtitle_run = subtitle.runs[0]
    subtitle_run.font.size = Pt(20)
    subtitle_run.font.color.rgb = RGBColor(255, 102, 0)  # Orange for People & Ops
    
    # Add metadata
    metadata_para = doc.add_paragraph()
    metadata_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
    
    report_meta = report_data.get("_enhanced_people_ops_report_metadata", {})
    
    metadata_para.add_run(f"User ID: {user_id}\n").bold = True
    metadata_para.add_run(f"Generated: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}\n")
    metadata_para.add_run(f"Analysis: {report_meta.get('total_words', 0):,} words\n")
    metadata_para.add_run(f"Model: Gemini 2.5 Pro People & Operations Engine\n")
    metadata_para.add_run(f"Focus: Organizational Excellence & Leadership\n")
    
    # Add multi-database intelligence indicator
    multi_db_info = report_meta.get("multi_database_integration", {})
    if multi_db_info.get("enabled", False):
        data_sources = multi_db_info.get("data_sources_used", [])
        metadata_para.add_run(f"Intelligence Sources: {len(data_sources)} databases integrated\n")
        complete_qa_pairs = multi_db_info.get("complete_qa_pairs", 0)
        if complete_qa_pairs > 0:
            metadata_para.add_run(f"Q&A Intelligence: {complete_qa_pairs} cross-engine insights\n")
    
    doc.add_page_break()
    
    # Table of Contents
    toc_heading = doc.add_heading("TABLE OF CONTENTS", 1)
    toc_heading.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
    
    section_number = 1
    for section_name, section_data in report_data.items():
        if section_name != "_enhanced_people_ops_report_metadata" and isinstance(section_data, dict):
            title = section_data.get("title", "Untitled Section")
            
            toc_para = doc.add_paragraph()
            toc_para.add_run(f"{section_number}. {title}").bold = True
            
            # Add word count
            metadata = section_data.get("metadata", {})
            words_generated = metadata.get("words_generated", 0)
            
            toc_para.add_run(f" ({words_generated:,} words)")
            
            section_number += 1
    
    doc.add_page_break()
    
    # Process each section
    section_number = 1
    for section_name, section_data in report_data.items():
        if section_name != "_enhanced_people_ops_report_metadata" and isinstance(section_data, dict):
            
            logging.info(f"üìù Formatting people & ops section: {section_name}")
            
            title = section_data.get("title", "Untitled Section")
            content = section_data.get("content", "")
            
            # Add section header
            section_heading = doc.add_heading(f"{section_number}. {title}", 1)
            heading_run = section_heading.runs[0]
            heading_run.font.color.rgb = RGBColor(0, 51, 102)
            
            # Add the AI-generated content
            add_people_ops_content_to_document(doc, content)
            
            # Add section separator
            separator_para = doc.add_paragraph()
            separator_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            separator_run = separator_para.add_run("üë• ‚óÜ ‚óÜ ‚óÜ üë•")
            separator_run.font.color.rgb = RGBColor(255, 102, 0)  # Orange for People & Ops
            separator_run.font.size = Pt(16)
            
            section_number += 1
            doc.add_page_break()
    
    # Add report summary
    add_people_ops_report_summary(doc, report_data)
    
    logging.info("‚úÖ People & Operations Word Document Created")
    return doc

def add_people_ops_content_to_document(doc: Document, content: str):
    """Add AI-generated people & ops content to document with intelligent formatting"""
    
    # Split by paragraphs and headers
    lines = content.split('\n')
    current_paragraph = ""
    
    for line in lines:
        line = line.strip()
        
        if not line:
            # Empty line - finalize paragraph
            if current_paragraph:
                para = doc.add_paragraph(current_paragraph)
                current_paragraph = ""
        elif line.startswith('###'):
            # Sub-subsection header
            if current_paragraph:
                para = doc.add_paragraph(current_paragraph)
                current_paragraph = ""
            
            header_text = line.replace('###', '').strip()
            subheading = doc.add_heading(header_text, 3)
            subheading_run = subheading.runs[0]
            subheading_run.font.color.rgb = RGBColor(255, 153, 51)  # Light orange for People & Ops
            
        elif line.startswith('##'):
            # Subsection header
            if current_paragraph:
                para = doc.add_paragraph(current_paragraph)
                current_paragraph = ""
            
            header_text = line.replace('##', '').strip()
            subheading = doc.add_heading(header_text, 2)
            subheading_run = subheading.runs[0]
            subheading_run.font.color.rgb = RGBColor(255, 102, 0)  # Orange for People & Ops
            
        elif line.startswith('#'):
            # Main header
            if current_paragraph:
                para = doc.add_paragraph(current_paragraph)
                current_paragraph = ""
            
            header_text = line.replace('#', '').strip()
            subheading = doc.add_heading(header_text, 2)
            subheading_run = subheading.runs[0]
            subheading_run.font.color.rgb = RGBColor(255, 102, 0)
            
        elif line.startswith('- ') or line.startswith('‚Ä¢ '):
            # Bullet point
            if current_paragraph:
                para = doc.add_paragraph(current_paragraph)
                current_paragraph = ""
            
            bullet_text = line[2:].strip()
            doc.add_paragraph(bullet_text, style='List Bullet')
            
        elif re.match(r'^\d+\.', line):
            # Numbered list
            if current_paragraph:
                para = doc.add_paragraph(current_paragraph)
                current_paragraph = ""
            
            number_text = re.sub(r'^\d+\.\s*', '', line)
            doc.add_paragraph(number_text, style='List Number')
            
        elif line.startswith('üë•') or line.startswith('üè¢') or line.startswith('‚öôÔ∏è'):
            # People & Ops-specific emojis - treat as emphasis
            if current_paragraph:
                para = doc.add_paragraph(current_paragraph)
                current_paragraph = ""
            
            emoji_para = doc.add_paragraph(line)
            emoji_run = emoji_para.runs[0]
            emoji_run.bold = True
            emoji_run.font.color.rgb = RGBColor(255, 102, 0)  # Orange for People & Ops
            
        else:
            # Regular content - accumulate
            if current_paragraph:
                current_paragraph += " " + line
            else:
                current_paragraph = line
    
    # Add any remaining paragraph
    if current_paragraph:
        para = doc.add_paragraph(current_paragraph)

def add_people_ops_report_summary(doc: Document, report_data: Dict):
    """Add people & operations-specific report summary"""
    
    summary_heading = doc.add_heading("PEOPLE & OPERATIONS REPORT SUMMARY", 1)
    summary_heading.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
    summary_heading_run = summary_heading.runs[0]
    summary_heading_run.font.color.rgb = RGBColor(255, 102, 0)  # Orange for People & Ops
    
    report_meta = report_data.get("_enhanced_people_ops_report_metadata", {})
    
    summary_para = doc.add_paragraph()
    summary_para.add_run("People & Operations Strategy Report Statistics:").bold = True
    summary_para.add_run(f"\n‚Ä¢ Total Organizational Sections: {report_meta.get('total_sections', 0)}")
    summary_para.add_run(f"\n‚Ä¢ Total Words Generated: {report_meta.get('total_words', 0):,}")
    summary_para.add_run(f"\n‚Ä¢ AI Model: {report_meta.get('ai_model', 'N/A')}")
    summary_para.add_run(f"\n‚Ä¢ Processing Method: {report_meta.get('processing_method', 'N/A')}")
    summary_para.add_run(f"\n‚Ä¢ Report Type: {report_meta.get('report_type', 'N/A')}")
    summary_para.add_run(f"\n‚Ä¢ Focus Areas: Leadership, Team Architecture, Operational Systems, Culture")
    
    # Add people & ops-specific insights summary
    insights_para = doc.add_paragraph()
    insights_para.add_run("\nPeople & Operations Intelligence Summary:").bold = True
    insights_para.add_run(f"\nüéØ Leadership Development Opportunities Identified")
    insights_para.add_run(f"\nüë• Team Architecture Optimization with Implementation Timeline")
    insights_para.add_run(f"\nüè¢ Operational Systems Strategy with Process Excellence")
    insights_para.add_run(f"\n‚öôÔ∏è Culture & Engagement Enhancement with Metrics")
    insights_para.add_run(f"\nüîß Risk Management Framework for Business Continuity")
    insights_para.add_run(f"\nüìä Implementation Roadmap for Organizational Excellence")
    
    # Add multi-database integration summary
    multi_db_info = report_meta.get("multi_database_integration", {})
    if multi_db_info.get("enabled", False):
        summary_para.add_run(f"\n‚Ä¢ Multi-Database Integration: Enabled")
        data_sources = multi_db_info.get("data_sources_used", [])
        summary_para.add_run(f"\n‚Ä¢ Intelligence Sources: {', '.join(data_sources).title() if data_sources else 'People & Ops Assessment Only'}")
        complete_qa_pairs = multi_db_info.get("complete_qa_pairs", 0)
        if complete_qa_pairs > 0:
            summary_para.add_run(f"\n‚Ä¢ Cross-Engine Q&A Intelligence: {complete_qa_pairs} insights integrated")

# ======================================================
#           Enhanced Azure Storage for People & Operations Engine
# ======================================================

# ======================================================
#           BLOB UPLOAD HELPER WITH RETRY
# ======================================================
def upload_blob_with_retry(container_client, blob_name, data, content_settings, max_retries=3):
    """
    Helper function to upload blob with retry logic
    """
    for attempt in range(max_retries):
        try:
            container_client.upload_blob(
                name=blob_name,
                data=data,
                overwrite=True,
                content_settings=content_settings
            )
            logging.info(f"‚úÖ Successfully uploaded: {blob_name}")
            return True
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 2
                logging.warning(f"Upload attempt {attempt + 1} failed for {blob_name}: {str(e)}. Retrying in {wait_time}s...")
                time.sleep(wait_time)
                # Reset data stream position if possible
                if hasattr(data, 'seek'):
                    data.seek(0)
            else:
                logging.error(f"‚ùå Failed to upload {blob_name} after {max_retries} attempts: {str(e)}")
                raise
    return False

async def upload_people_ops_report_to_azure(report_data: Dict, report_id: str, user_id: str):
    """Upload people & operations report to Azure with enhanced Word document chunking AND Question-Response chunking"""
    try:
        logging.info(f"üöÄ Starting People & Operations Report Azure Upload for report_id={report_id}, user_id={user_id}")
        
        container_name = get_azure_container_name(user_id)
        logging.info(f"üì¶ Using Azure container: {container_name}")
        
        blob_service_client = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)
        container_client = blob_service_client.get_container_client(container_name)
        
        try:
            container_client.create_container()
            logging.info(f"‚úÖ Container '{container_name}' created")
        except:
            logging.info(f"üì¶ Container '{container_name}' already exists")
        
        # Get client folder from database (e.g., "499-tkrotiris")
        client_folder = get_client_folder_name(user_id)
        folder_name = f"{client_folder}/the people and operations engine report"
        logging.info(f"üìÇ Uploading people ops report to: {container_name}/{folder_name}/")
        
        # ===============================================================
        # 1. Upload complete Word document
        # ===============================================================
        logging.info("üìÑ Step 1/6: Creating and uploading complete Word document...")
        doc = create_people_ops_word_document(report_data, user_id)
        doc_bytes = io.BytesIO()
        doc.save(doc_bytes)
        doc_bytes.seek(0)
        
        doc_blob_name = f"{folder_name}/{report_id}_comprehensive_people_operations_strategy.docx"
        upload_blob_with_retry(
            container_client,
            doc_blob_name,
            doc_bytes,
            ContentSettings(
                content_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        )
        logging.info(f"‚úÖ Complete People & Ops Word document uploaded: {doc_blob_name}")
        
        # ===============================================================
        # 2. Upload complete JSON data
        # ===============================================================
        logging.info("üìä Step 2/6: Creating and uploading complete JSON data...")
        json_data = json.dumps(report_data, indent=2, default=str)
        json_bytes = io.BytesIO(json_data.encode("utf-8"))
        
        json_blob_name = f"{folder_name}/{report_id}_comprehensive_people_ops_report.json"
        upload_blob_with_retry(
            container_client,
            json_blob_name,
            json_bytes,
            ContentSettings(content_type="application/json")
        )
        logging.info(f"‚úÖ Complete People & Ops JSON file uploaded: {json_blob_name}")
        
        # ===============================================================
        # 3. Create and upload Word document chunks for Azure Cognitive Search
        # ===============================================================
        logging.info("üîß Step 3/6: Creating Word document chunks for Azure Cognitive Search...")
        word_chunks = await create_people_ops_word_document_chunks(report_data, report_id, user_id)
        logging.info(f"üìä Created {len(word_chunks)} report Word chunks")
        
        # Upload individual Word chunk files
        chunk_files_created = []
        for i, chunk_doc in enumerate(word_chunks):
            chunk_blob_name = f"{folder_name}/{report_id}_people_ops_chunk_{i+1:03d}.docx"
            
            # Save Word document chunk to bytes
            chunk_bytes = io.BytesIO()
            chunk_doc['document'].save(chunk_bytes)
            chunk_bytes.seek(0)
            
            upload_blob_with_retry(
                container_client,
                chunk_blob_name,
                chunk_bytes,
                ContentSettings(
                    content_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
            )
            chunk_files_created.append(chunk_blob_name)
            logging.info(f"‚úÖ People & Ops Word chunk {i+1} uploaded: {chunk_blob_name} ({chunk_doc['word_count']} words)")
        
        # ===============================================================
        # 4. Create and upload Question-Response chunks for RAG context
        # ===============================================================
        logging.info("üß† Step 4/6: Creating Question-Response chunks for RAG context...")
        
        # Get the raw assessment data that contains questions and responses
        raw_assessment_data = report_data.get('_enhanced_people_ops_report_metadata', {}).get('raw_assessment_data', {})
        if not raw_assessment_data:
            # Try to get from other sources in report_data
            logging.warning("‚ö†Ô∏è No raw assessment data found in report metadata, attempting to extract from available data...")
            raw_assessment_data = extract_people_ops_assessment_data_from_report(report_data)
        
        if raw_assessment_data:
            qr_chunks = await create_people_ops_question_response_chunks(raw_assessment_data, report_id, user_id)
            logging.info(f"üìä Created {len(qr_chunks)} Question-Response chunks for RAG")
            
            # Upload Question-Response chunk files
            qr_chunk_files_created = []
            for i, qr_chunk in enumerate(qr_chunks):
                qr_chunk_blob_name = f"{folder_name}/{report_id}_people_ops_qr_chunk_{i+1:03d}.docx"
                
                # Save Question-Response document chunk to bytes
                qr_chunk_bytes = io.BytesIO()
                qr_chunk['document'].save(qr_chunk_bytes)
                qr_chunk_bytes.seek(0)
                
                upload_blob_with_retry(
                    container_client,
                    qr_chunk_blob_name,
                    qr_chunk_bytes,
                    ContentSettings(
                        content_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                )
                qr_chunk_files_created.append(qr_chunk_blob_name)
                logging.info(f"‚úÖ People & Ops Question-Response chunk {i+1} uploaded: {qr_chunk_blob_name} ({qr_chunk['word_count']} words, {qr_chunk['question_count']} questions)")
        else:
            logging.error("‚ùå No assessment data available for Question-Response chunking")
            qr_chunks = []
            qr_chunk_files_created = []
        
        # ===============================================================
        # 5. Create comprehensive chunks index file
        # ===============================================================
        logging.info("üìã Step 5/6: Creating comprehensive chunks index...")
        
        chunks_index = {
            "report_id": report_id,
            "user_id": user_id,
            "total_report_chunks": len(word_chunks),
            "total_qr_chunks": len(qr_chunks),
            "total_all_chunks": len(word_chunks) + len(qr_chunks),
            "report_chunk_files": chunk_files_created,
            "qr_chunk_files": qr_chunk_files_created,
            "chunking_strategy": {
                "report_chunks": {
                    "target_size_words": 300,  # Consistent with growth engine
                    "max_size_words": 400,
                    "min_size_words": 150,
                    "chunk_type": "people_ops_word_documents",
                    "optimized_for": "azure_cognitive_search_people_ops_analysis"
                },
                "qr_chunks": {
                    "target_size_words": 800,
                    "max_size_words": 1000,
                    "min_size_words": 0,      
                    "chunk_type": "question_response_documents",
                    "optimized_for": "rag_context_people_ops_questions"
                }
            },
            "report_chunks_summary": [
                {
                    "chunk_id": chunk_doc["chunk_id"],
                    "section_title": chunk_doc["section_title"],
                    "word_count": chunk_doc["word_count"],
                    "character_count": chunk_doc["character_count"],
                    "content_preview": chunk_doc["content_preview"],
                    "file_name": chunk_files_created[i],
                    "sections_included": chunk_doc["sections_included"],
                    "chunk_type": "report_content"
                }
                for i, chunk_doc in enumerate(word_chunks)
            ],
            "qr_chunks_summary": [
                {
                    "chunk_id": qr_chunk["chunk_id"],
                    "expansion_title": qr_chunk["expansion_title"],
                    "word_count": qr_chunk["word_count"],
                    "question_count": qr_chunk["question_count"],
                    "character_count": qr_chunk["character_count"],
                    "content_preview": qr_chunk["content_preview"],
                    "file_name": qr_chunk_files_created[i],
                    "questions_included": qr_chunk["questions_included"],
                    "chunk_type": "question_response"
                }
                for i, qr_chunk in enumerate(qr_chunks)
            ],
            "created_at": datetime.now().isoformat(),
            "folder": folder_name,
            "report_type": "comprehensive_people_operations_strategy_with_qr_chunks",
            "database_pooling_enabled": True
        }
        
        chunks_index_blob_name = f"{folder_name}/{report_id}_people_ops_chunks_index.json"
        chunks_index_json = json.dumps(chunks_index, indent=2, default=str)
        chunks_index_bytes = io.BytesIO(chunks_index_json.encode("utf-8"))

        upload_blob_with_retry(
            container_client,
            chunks_index_blob_name,
            chunks_index_bytes,
            ContentSettings(content_type="application/json")
        )
        logging.info(f"‚úÖ Comprehensive Chunks index uploaded: {chunks_index_blob_name}")
        
        # ===============================================================
        # 6. Upload final summary and statistics
        # ===============================================================
        logging.info("üìà Step 6/6: Generating final upload summary...")
        
        total_sections = len([k for k in report_data.keys() if k != "_enhanced_people_ops_report_metadata"])
        total_files = 3 + len(word_chunks) + len(qr_chunks)  # Word doc + JSON + chunks index + all chunk files
        
        # Create detailed upload summary
        upload_summary = {
            "report_id": report_id,
            "user_id": user_id,
            "upload_completed_at": datetime.now().isoformat(),
            "folder_name": folder_name,
            "files_created": {
                "complete_word_document": doc_blob_name,
                "complete_json_report": json_blob_name,
                "chunks_index": chunks_index_blob_name,
                "report_chunks": chunk_files_created,
                "question_response_chunks": qr_chunk_files_created
            },
            "statistics": {
                "total_files_created": total_files,
                "report_sections": total_sections,
                "report_word_chunks": len(word_chunks),
                "question_response_chunks": len(qr_chunks),
                "total_chunks": len(word_chunks) + len(qr_chunks)
            },
            "chunk_optimization": {
                "report_chunks_for": "Azure Cognitive Search People & Operations Analysis",
                "qr_chunks_for": "RAG Context for AI People & Operations Questions",
                "target_chunk_size": "300-400 words (main), 800-1000 words (Q&R)",
                "chunk_format": "Microsoft Word (.docx)",
                "database_pooling_used": True
            }
        }
        
        # Upload summary file
        summary_blob_name = f"{folder_name}/{report_id}_people_ops_upload_summary.json"
        summary_json = json.dumps(upload_summary, indent=2, default=str)
        summary_bytes = io.BytesIO(summary_json.encode("utf-8"))

        upload_blob_with_retry(
            container_client,
            summary_blob_name,
            summary_bytes,
            ContentSettings(content_type="application/json")
        )
        logging.info(f"‚úÖ Upload summary created: {summary_blob_name}")
        
        # ===============================================================
        # Final Success Logging
        # ===============================================================
        logging.info(f"üéâ People & Operations Report upload complete: {total_files} files in '{folder_name}' folder")
        logging.info(f"üìä Created {len(word_chunks)} People & Ops Word document chunks for Azure Cognitive Search")
        logging.info(f"üß† Created {len(qr_chunks)} Question-Response chunks for RAG context")
        logging.info(f"üìÅ All files uploaded to container '{container_name}' in folder '{folder_name}/'")
        
        success_message = f"People & operations report uploaded successfully: {total_sections} sections, {len(word_chunks)} report chunks, {len(qr_chunks)} Q&R chunks, {total_files} files total (with database pooling)"
        logging.info(f"‚úÖ {success_message}")
        
        return True, success_message
        
    except Exception as e:
        error_message = f"Error uploading people & operations report: {str(e)}"
        logging.error(f"‚ùå {error_message}")
        logging.error(f"üîç Error details: {type(e).__name__}: {e}")
        import traceback
        logging.error(f"üîç Full traceback: {traceback.format_exc()}")
        return False, error_message

def extract_people_ops_assessment_data_from_report(report_data: Dict) -> Dict:
    """Extract assessment data from people & ops report if not available in metadata"""
    try:
        # Try to find assessment data in various places within the report
        for key, value in report_data.items():
            if isinstance(value, dict) and 'responses' in value:
                return value
            elif isinstance(value, dict) and 'assessment_data' in value:
                return value['assessment_data']
        
        logging.warning("‚ö†Ô∏è Could not extract people & ops assessment data from report")
        return {}
    except Exception as e:
        logging.error(f"‚ùå Error extracting people & ops assessment data: {str(e)}")
        return {}

# ======================================================
#           People & Operations Word Document Chunking
# ======================================================

async def create_people_ops_word_document_chunks(report_data: Dict, report_id: str, user_id: str) -> List[Dict]:
    """Create Word document chunks optimized for RAG performance with detailed monitoring"""
    
    logging.info(f"üöÄ Starting RAG-optimized people & ops chunking for report_id={report_id}, user_id={user_id}")
    
    word_chunks = []
    
    # Get user profile for context using async connection pooling
    user_profile = await get_user_profile_data(user_id)
    if user_profile:
        logging.info(f"üë§ User context: {user_profile.get('business_name', 'Unknown')} ({user_profile.get('industry', 'Unknown')})")
    else:
        logging.warning(f"‚ö†Ô∏è No user profile found for user_id={user_id}")
    
    # RAG-OPTIMIZED chunking settings for better retrieval performance (consistent with growth engine)
    TARGET_SIZE_WORDS = 300  # Sweet spot for RAG retrieval
    MAX_SIZE_WORDS = 400     # Hard limit to prevent oversized chunks
    MIN_SIZE_WORDS = 150     # Minimum to maintain semantic meaning
    
    logging.info(f"‚öôÔ∏è RAG chunking settings: target={TARGET_SIZE_WORDS}, max={MAX_SIZE_WORDS}, min={MIN_SIZE_WORDS}")
    
    chunk_id = 1
    total_sections = len([k for k in report_data.keys() if k != "_enhanced_people_ops_report_metadata"])
    logging.info(f"üìÇ Processing {total_sections} report sections for chunking")
    
    # Track overall statistics
    total_input_words = 0
    total_output_chunks = 0
    section_stats = []
    
    # Process each section and create smart chunks
    for section_idx, (section_name, section_data) in enumerate(report_data.items()):
        if section_name == "_enhanced_people_ops_report_metadata":
            continue
            
        if not isinstance(section_data, dict):
            logging.warning(f"‚ö†Ô∏è Skipping non-dict section: {section_name}")
            continue
            
        title = section_data.get("title", "Untitled Section")
        content = section_data.get("content", "")
        metadata = section_data.get("metadata", {})
        
        # Log section processing start
        section_word_count = len(content.split())
        total_input_words += section_word_count
        logging.info(f"üìÑ Processing section {section_idx + 1}/{total_sections}: '{title}' ({section_word_count:,} words)")
        
        # Clean content for better processing
        clean_content = clean_people_ops_content_for_word_chunks(content)
        clean_word_count = len(clean_content.split())
        
        if clean_word_count != section_word_count:
            logging.info(f"üßπ Content cleaned: {section_word_count} ‚Üí {clean_word_count} words")
        
        # Create semantic chunks from this section with detailed monitoring
        logging.info(f"üîß Starting semantic chunking for section '{title}'...")
        section_chunks = create_semantic_people_ops_word_chunks(clean_content, TARGET_SIZE_WORDS, MAX_SIZE_WORDS, MIN_SIZE_WORDS)
        
        # Validate section chunks
        section_chunk_stats = validate_people_ops_chunk_sizes(section_chunks, TARGET_SIZE_WORDS, f"Section: {title}")
        section_stats.append({
            "section_name": section_name,
            "section_title": title,
            "input_words": clean_word_count,
            "chunks_created": len(section_chunks),
            "chunk_stats": section_chunk_stats
        })
        
        logging.info(f"‚úÖ Section '{title}' chunked: {clean_word_count} words ‚Üí {len(section_chunks)} chunks")
        
        # Convert each chunk to a Word document
        for i, chunk_content in enumerate(section_chunks):
            chunk_title = title if len(section_chunks) == 1 else f"{title} - Part {i+1}"
            chunk_word_count = len(chunk_content.split())
            
            logging.debug(f"üìù Creating Word document for chunk {chunk_id}: '{chunk_title}' ({chunk_word_count} words)")
            
            # Create Word document for this chunk
            chunk_doc = create_people_ops_chunk_word_document(
                chunk_content, 
                chunk_title, 
                user_profile,
                section_name,
                f"{report_id}_people_ops_chunk_{chunk_id:03d}"
            )
            
            character_count = len(chunk_content)
            
            # Determine chunk quality metrics
            chunk_category = categorize_people_ops_chunk_size_by_words(chunk_word_count)
            semantic_completeness = calculate_people_ops_semantic_completeness(chunk_content)
            
            # Log chunk quality
            quality_status = "‚úÖ OPTIMAL" if TARGET_SIZE_WORDS * 0.8 <= chunk_word_count <= TARGET_SIZE_WORDS * 1.2 else \
                           "‚ö†Ô∏è LARGE" if chunk_word_count > TARGET_SIZE_WORDS * 1.2 else \
                           "‚ö†Ô∏è SMALL" if chunk_word_count < TARGET_SIZE_WORDS * 0.8 else "‚ùì UNKNOWN"
            
            logging.info(f"üìä Chunk {chunk_id} quality: {quality_status} | "
                        f"{chunk_word_count} words | "
                        f"Category: {chunk_category} | "
                        f"Completeness: {semantic_completeness:.2f}")
            
            chunk_info = {
                "chunk_id": f"{report_id}_people_ops_chunk_{chunk_id:03d}",
                "section_name": section_name,
                "section_title": chunk_title,
                "word_count": chunk_word_count,
                "character_count": character_count,
                "content_preview": chunk_content[:200] + "..." if len(chunk_content) > 200 else chunk_content,
                "sections_included": [section_name],
                "document": chunk_doc,
                "chunk_metadata": {
                    "original_section": section_name,
                    "chunk_size_category": chunk_category,
                    "semantic_completeness": semantic_completeness,
                    "ai_analysis_time": metadata.get("ai_analysis_time", 0),
                    "chunk_type": "people_ops_analysis_rag_optimized",
                    "rag_optimization": {
                        "target_size": TARGET_SIZE_WORDS,
                        "size_ratio": chunk_word_count / TARGET_SIZE_WORDS,
                        "quality_status": quality_status.replace("‚úÖ ", "").replace("‚ö†Ô∏è ", "").replace("‚ùì ", ""),
                        "overlap_enabled": True
                    }
                },
                "user_context": {
                    "user_id": user_id,
                    "business_name": user_profile.get("business_name", "Unknown") if user_profile else "Unknown",
                    "industry": user_profile.get("industry", "Unknown") if user_profile else "Unknown",
                    "team_size": user_profile.get("team_size", "Unknown") if user_profile else "Unknown"
                },
                "created_at": datetime.now().isoformat()
            }
            
            word_chunks.append(chunk_info)
            total_output_chunks += 1
            chunk_id += 1
    
    # Final comprehensive statistics
    if word_chunks:
        avg_chunk_size = sum(c['word_count'] for c in word_chunks) // len(word_chunks)
        min_chunk_size = min(c['word_count'] for c in word_chunks)
        max_chunk_size = max(c['word_count'] for c in word_chunks)
        
        # Count optimal chunks
        optimal_chunks = sum(1 for c in word_chunks if TARGET_SIZE_WORDS * 0.8 <= c['word_count'] <= TARGET_SIZE_WORDS * 1.2)
        optimal_percentage = (optimal_chunks / len(word_chunks)) * 100
        
        # Calculate compression ratio
        compression_ratio = total_input_words / sum(c['word_count'] for c in word_chunks) if word_chunks else 1
        
        logging.info(f"üéâ RAG-optimized people & ops chunking complete!")
        logging.info(f"üìä FINAL STATISTICS:")
        logging.info(f"   üìÑ Input: {total_input_words:,} words across {total_sections} sections")
        logging.info(f"   üì¶ Output: {len(word_chunks)} chunks")
        logging.info(f"   üìè Chunk sizes: {min_chunk_size}-{max_chunk_size} words (avg: {avg_chunk_size})")
        logging.info(f"   üéØ Target compliance: {optimal_chunks}/{len(word_chunks)} chunks optimal ({optimal_percentage:.1f}%)")
        logging.info(f"   üîó Overlap enabled: 50-word context preservation between chunks")
        logging.info(f"   üìà Compression ratio: {compression_ratio:.2f}x (due to overlap)")
        
        # Log any quality concerns
        oversized_chunks = sum(1 for c in word_chunks if c['word_count'] > MAX_SIZE_WORDS)
        undersized_chunks = sum(1 for c in word_chunks if c['word_count'] < MIN_SIZE_WORDS)
        
        if oversized_chunks > 0:
            logging.warning(f"‚ö†Ô∏è Quality concern: {oversized_chunks} chunks exceed maximum size ({MAX_SIZE_WORDS} words)")
        if undersized_chunks > 0:
            logging.warning(f"‚ö†Ô∏è Quality concern: {undersized_chunks} chunks below minimum size ({MIN_SIZE_WORDS} words)")
        
        if optimal_percentage >= 80:
            logging.info(f"‚úÖ Excellent RAG optimization: {optimal_percentage:.1f}% of chunks are optimally sized")
        elif optimal_percentage >= 60:
            logging.info(f"‚ö†Ô∏è Good RAG optimization: {optimal_percentage:.1f}% of chunks are optimally sized")
        else:
            logging.warning(f"‚ùå Poor RAG optimization: Only {optimal_percentage:.1f}% of chunks are optimally sized")
            
    else:
        logging.error(f"‚ùå No chunks created from {total_sections} sections!")
    
    return word_chunks

def clean_people_ops_content_for_word_chunks(content: str) -> str:
    """Clean people & ops content for better Word document processing"""
    
    # Remove excessive whitespace
    content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)
    content = re.sub(r' +', ' ', content)
    
    # Fix common formatting issues
    content = re.sub(r'([.!?])\s*([A-Z])', r'\1 \2', content)
    content = re.sub(r'([a-z])([A-Z])', r'\1 \2', content)
    
    # Remove artifacts from AI generation
    content = re.sub(r'<[^>]+>', '', content)  # Remove any HTML tags
    content = re.sub(r'\[.*?\]', '', content)  # Remove bracket annotations
    
    # People & ops-specific cleaning
    content = re.sub(r'People & Operations Engine:', 'People & Operations Strategy:', content)
    content = re.sub(r'Chapter \d+:', 'Organizational Chapter:', content)
    
    # Normalize quotes and special characters
    content = content.replace('"', '"').replace('"', '"')
    content = content.replace(''', "'").replace(''', "'")
    content = re.sub(r'‚Ä¶', '...', content)
    
    return content.strip()

def create_semantic_people_ops_word_chunks(content: str, target_size: int, max_size: int, min_size: int) -> List[str]:
    """Create semantic chunks that preserve people & ops context WITH OVERLAP for better RAG performance"""
    
    logging.info(f"üîß Starting people & ops semantic chunking: target={target_size}, max={max_size}, min={min_size}")
    
    # If content is small enough, return as single chunk
    word_count = len(content.split())
    logging.info(f"üìä Input people & ops content: {word_count} words")
    
    if word_count <= max_size:
        logging.info(f"‚úÖ People & ops content fits in single chunk ({word_count} <= {max_size})")
        return [content]
    
    chunks = []
    OVERLAP_SIZE = 50  # 50 words overlap between chunks for context preservation
    logging.info(f"üîó Using {OVERLAP_SIZE}-word overlap between people & ops chunks")
    
    # Split by people & ops logic sections first
    people_ops_sections = split_by_people_ops_logic(content)
    logging.info(f"üìÇ Split into {len(people_ops_sections)} people & ops logic sections")
    
    current_chunk = ""
    current_word_count = 0
    previous_chunk_end = ""  # Store end of previous chunk for overlap
    
    for section_idx, section in enumerate(people_ops_sections):
        section_words = len(section.split())
        test_word_count = current_word_count + section_words
        
        logging.debug(f"üîç Processing people & ops section {section_idx + 1}/{len(people_ops_sections)}: {section_words} words")
        
        if test_word_count > max_size and current_chunk:
            # Current chunk is full, save it if it's substantial
            if current_word_count >= min_size:
                # Add overlap from previous chunk if available
                final_chunk = current_chunk
                if previous_chunk_end and chunks:
                    overlap_text = get_last_n_words(previous_chunk_end, OVERLAP_SIZE)
                    final_chunk = overlap_text + "\n\n" + current_chunk
                    logging.debug(f"üîó Added {len(overlap_text.split())} word overlap to people & ops chunk {len(chunks) + 1}")
                
                chunks.append(final_chunk.strip())
                
                # Store end of current chunk for next overlap
                previous_chunk_end = get_last_n_words(current_chunk, OVERLAP_SIZE * 2)
                
                logging.info(f"‚úÖ Saved people & ops chunk {len(chunks)}: {len(final_chunk.split())} words (original: {current_word_count})")
                
                current_chunk = section
                current_word_count = section_words
            else:
                # Current chunk too small, but adding section makes it too big
                logging.debug(f"‚ö†Ô∏è Current people & ops chunk too small ({current_word_count} < {min_size}), handling large section")
                
                if section_words > max_size:
                    logging.debug(f"üî® People & ops section too large ({section_words} > {max_size}), splitting with overlap")
                    sub_sections = split_large_people_ops_section_with_overlap(section, max_size)
                    logging.info(f"üìÇ Split large people & ops section into {len(sub_sections)} sub-sections with overlap")
                    
                    for sub_idx, sub_section in enumerate(sub_sections):
                        sub_words = len(sub_section.split())
                        logging.debug(f"üîç Processing people & ops sub-section {sub_idx + 1}/{len(sub_sections)}: {sub_words} words")
                        
                        if current_word_count + sub_words > max_size and current_chunk:
                            if current_word_count >= min_size:
                                # Add overlap before saving
                                final_chunk = current_chunk
                                if previous_chunk_end and chunks:
                                    overlap_text = get_last_n_words(previous_chunk_end, OVERLAP_SIZE)
                                    final_chunk = overlap_text + "\n\n" + current_chunk
                                    logging.debug(f"üîó Added {len(overlap_text.split())} word overlap to people & ops chunk {len(chunks) + 1}")
                                
                                chunks.append(final_chunk.strip())
                                previous_chunk_end = get_last_n_words(current_chunk, OVERLAP_SIZE * 2)
                                logging.info(f"‚úÖ Saved people & ops chunk {len(chunks)}: {len(final_chunk.split())} words")
                            
                            current_chunk = sub_section
                            current_word_count = sub_words
                        else:
                            current_chunk += "\n\n" + sub_section if current_chunk else sub_section
                            current_word_count += sub_words
                            logging.debug(f"‚ûï Added people & ops sub-section to current chunk: {current_word_count} total words")
                else:
                    current_chunk += "\n\n" + section if current_chunk else section
                    current_word_count = test_word_count
                    logging.debug(f"‚ûï Added people & ops section to current chunk: {current_word_count} total words")
        else:
            current_chunk += "\n\n" + section if current_chunk else section
            current_word_count = test_word_count
            logging.debug(f"‚ûï Added people & ops section to current chunk: {current_word_count} total words")
    
    # Add the last chunk if it exists and is substantial
    if current_chunk and current_word_count >= min_size:
        # Add overlap to final chunk too
        final_chunk = current_chunk
        if previous_chunk_end and chunks:
            overlap_text = get_last_n_words(previous_chunk_end, OVERLAP_SIZE)
            final_chunk = overlap_text + "\n\n" + current_chunk
            logging.debug(f"üîó Added {len(overlap_text.split())} word overlap to final people & ops chunk")
        
        chunks.append(final_chunk.strip())
        logging.info(f"‚úÖ Saved final people & ops chunk {len(chunks)}: {len(final_chunk.split())} words (original: {current_word_count})")
    elif current_chunk:
        logging.warning(f"‚ö†Ô∏è Discarded final people & ops chunk: {current_word_count} words < {min_size} minimum")
    
    # Validate the created chunks
    chunk_stats = validate_people_ops_chunk_sizes(chunks, target_size, "People & Ops Semantic Chunking")
     
    logging.info(f"üéâ People & ops semantic chunking complete: {len(chunks)} chunks created")
    logging.info(f"üìä People & ops chunk size range: {chunk_stats.get('min_words', 0)}-{chunk_stats.get('max_words', 0)} words")
    logging.info(f"üìà Average people & ops chunk size: {chunk_stats.get('avg_words', 0)} words (target: {target_size})")
    
    return chunks

def split_by_people_ops_logic(content: str) -> List[str]:
    """Split content by people & operations-specific logical boundaries"""
    
    logging.info(f"üîß Starting people & ops logic splitting...")
    
    # Log input content stats
    total_words = len(content.split())
    total_paragraphs = len([p for p in content.split('\n\n') if p.strip()])
    logging.info(f"üìä Input people & ops content: {total_words} words, {total_paragraphs} paragraphs")
    
    # Enhanced people & ops-specific section indicators
    people_ops_patterns = [
        r'(?i)(?:^|\n)(?:leadership|team|organization|culture|people|operations|systems):',
        r'(?i)(?:^|\n)(?:leadership development|team architecture|organizational systems|culture building):',
        r'(?i)(?:^|\n)(?:people analysis|team assessment|leadership evaluation|operational review):',
        r'(?i)(?:^|\n)(?:leadership strengths|team advantages|operational opportunities|culture assets):',
        r'(?i)(?:^|\n)(?:people challenges|team risks|leadership gaps|operational weaknesses):',
        r'(?i)(?:^|\n)(?:implementation|execution|deployment|rollout|change management):',
        r'(?i)(?:^|\n)(?:optimization|improvement|enhancement|excellence|transformation):',
        r'(?i)(?:^|\n)(?:integration|alignment|coordination|collaboration|synergy):',
        r'(?i)(?:^|\n)(?:measurement|metrics|tracking|kpis|performance indicators):',
        r'(?i)(?:^|\n)(?:development|training|growth|capability|skill building):',
        
        # Enhanced patterns for AI-generated people & ops content
        r'(?i)(?:^|\n)(?:##\s*|###\s*)?(?:strategic|operational|people|team|leadership|culture)',
        r'(?i)(?:^|\n)(?:##\s*|###\s*)?(?:analysis|assessment|evaluation|optimization|development)',
        r'(?i)(?:^|\n)(?:##\s*|###\s*)?(?:recommendations?|strategies|approaches|solutions|frameworks)',
        r'(?i)(?:^|\n)(?:##\s*|###\s*)?(?:chapter \d+|section \d+|area \d+|phase \d+)',
        r'(?i)(?:^|\n)(?:your team|your leadership|your organization|considering your people)',
        r'(?i)(?:^|\n)(?:to develop|to build|to implement|to optimize|moving forward)',
        
        # People & ops-specific structural patterns
        r'(?i)(?:^|\n)(?:hiring|retention|onboarding|performance|succession|development)',
        r'(?i)(?:^|\n)(?:processes|procedures|workflows|systems|technology|automation)',
        r'(?i)(?:^|\n)(?:communication|collaboration|decision making|accountability|transparency)'
    ]
    
    logging.info(f"üîç Using {len(people_ops_patterns)} people & ops-specific patterns for splitting")
    
    # Try to split by people & ops patterns first
    sections = []
    current_section = ""
    pattern_matches = 0
    
    paragraphs = content.split('\n\n')
    logging.info(f"üìÇ Processing {len(paragraphs)} paragraphs for people & ops pattern matching")
    
    for paragraph in paragraphs:
        # Check if this paragraph starts a new people & ops section
        is_new_section = False
        for pattern in people_ops_patterns:
            if re.search(pattern, paragraph):
                is_new_section = True
                pattern_matches += 1
                break
        
        if is_new_section and current_section:
            sections.append(current_section.strip())
            current_section = paragraph
        else:
            current_section += "\n\n" + paragraph if current_section else paragraph
    
    # Add the last section
    if current_section:
        sections.append(current_section.strip())
    
    logging.info(f"üìä People & ops pattern matching results: {pattern_matches} matches found, {len(sections)} sections created")
    
    # Smart fallback logic - if no people & ops patterns found or sections too large
    needs_fallback = False
    if len(sections) <= 1:
        needs_fallback = True
        logging.warning(f"‚ö†Ô∏è No people & ops patterns found, applying smart fallback")
    elif any(len(s.split()) > 400 for s in sections):  # Adjusted for people & ops content
        needs_fallback = True
        logging.warning(f"‚ö†Ô∏è People & ops sections too large (>400 words), applying smart fallback")
    
    if needs_fallback:
        logging.info(f"üîÑ Applying smart paragraph splitting with people & ops-optimized size limits...")
        
        # Smart paragraph splitting with people & ops-optimized size limits
        sections = []
        current_section = ""
        current_words = 0
        target_words = 300  # Target size for people & ops chunks (optimized for RAG)
        
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
            
            para_words = len(paragraph.split())
            
            # If adding this paragraph would make section too large, save current and start new
            if current_words + para_words > target_words and current_section:
                sections.append(current_section.strip())
                logging.debug(f"üìÑ Saved people & ops section {len(sections)}: {current_words} words")
                current_section = paragraph
                current_words = para_words
            else:
                current_section += "\n\n" + paragraph if current_section else paragraph
                current_words += para_words
        
        if current_section:
            sections.append(current_section.strip())
            logging.debug(f"üìÑ Saved final people & ops section {len(sections)}: {current_words} words")
        
        logging.info(f"üìÑ Smart people & ops paragraph splitting: {len(sections)} sections created")
    
    # Final validation - force split any remaining oversized sections
    final_sections = []
    for i, section in enumerate(sections):
        section_words = len(section.split())
        
        if section_words > 400:  # Adjusted for people & ops content
            logging.warning(f"‚ö†Ô∏è People & ops section {i+1} still oversized ({section_words} words), force splitting")
            
            # Force split by sentences with people & ops context preservation
            sentences = re.split(r'(?<=[.!?])\s+', section)
            sub_sections = []
            current_sub = ""
            current_sub_words = 0
            
            for sentence in sentences:
                sentence_words = len(sentence.split())
                
                if current_sub_words + sentence_words > 350 and current_sub:  # Slightly smaller for people & ops
                    sub_sections.append(current_sub.strip())
                    current_sub = sentence
                    current_sub_words = sentence_words
                else:
                    current_sub += " " + sentence if current_sub else sentence
                    current_sub_words += sentence_words
            
            if current_sub:
                sub_sections.append(current_sub.strip())
            
            final_sections.extend(sub_sections)
            logging.info(f"üî® Split oversized people & ops section into {len(sub_sections)} sub-sections")
        else:
            final_sections.append(section)
    
    # Final statistics
    section_sizes = [len(s.split()) for s in final_sections]
    avg_size = sum(section_sizes) // len(section_sizes) if final_sections else 0
    min_size = min(section_sizes) if final_sections else 0
    max_size = max(section_sizes) if final_sections else 0
    optimal_sections = sum(1 for size in section_sizes if 150 <= size <= 400)  # People & ops-optimized range
    optimal_percentage = (optimal_sections / len(final_sections)) * 100 if final_sections else 0
    
    logging.info(f"üéâ People & ops logic splitting complete!")
    logging.info(f"üìä Final: {len(final_sections)} sections, {min_size}-{max_size} words (avg: {avg_size})")
    logging.info(f"üéØ Optimal people & ops sections (150-400 words): {optimal_sections}/{len(final_sections)} ({optimal_percentage:.1f}%)")
    
    return final_sections

def split_large_people_ops_section_with_overlap(section: str, max_size: int) -> List[str]:
    """Split large people & ops section with overlap for context preservation"""
    
    OVERLAP_SIZE = 50  # words
    
    words = section.split()
    if len(words) <= max_size:
        return [section]
    
    chunks = []
    start = 0
    
    while start < len(words):
        # Calculate end position
        end = min(start + max_size, len(words))
        
        # Create chunk
        chunk_words = words[start:end]
        chunk = ' '.join(chunk_words)
        chunks.append(chunk)
        
        # Move start position with overlap
        if end >= len(words):
            break
        
        start = end - OVERLAP_SIZE
        if start <= 0:
            start = end
    
    logging.debug(f"üî® Split large people & ops section: {len(words)} words ‚Üí {len(chunks)} chunks with {OVERLAP_SIZE}-word overlap")
    return chunks

def validate_people_ops_chunk_sizes(chunks: List[str], target_size: int, context_name: str = "") -> Dict:
    """Validate and log people & ops chunk sizes for monitoring"""
    
    if not chunks:
        return {"total_chunks": 0}
    
    chunk_stats = {
        "total_chunks": len(chunks),
        "avg_words": 0,
        "min_words": float('inf'),
        "max_words": 0,
        "chunks_over_target": 0,
        "chunks_under_100": 0,  # Flag very small chunks
        "chunks_optimal": 0     # Chunks within target range
    }
    
    total_words = 0
    for chunk in chunks:
        words = len(chunk.split())
        total_words += words
        
        chunk_stats["min_words"] = min(chunk_stats["min_words"], words)
        chunk_stats["max_words"] = max(chunk_stats["max_words"], words)
        
        if words > target_size * 1.2:  # 20% over target
            chunk_stats["chunks_over_target"] += 1
        elif words < 100:
            chunk_stats["chunks_under_100"] += 1
        elif target_size * 0.8 <= words <= target_size * 1.2:  # Within 20% of target
            chunk_stats["chunks_optimal"] += 1
    
    chunk_stats["avg_words"] = total_words // len(chunks)
    chunk_stats["min_words"] = chunk_stats["min_words"] if chunk_stats["min_words"] != float('inf') else 0
    
    # Log the stats
    context_prefix = f"[{context_name}] " if context_name else ""
    logging.info(f"üìä {context_prefix}People & ops chunk validation: "
                f"{chunk_stats['total_chunks']} chunks, "
                f"avg: {chunk_stats['avg_words']} words, "
                f"range: {chunk_stats['min_words']}-{chunk_stats['max_words']}, "
                f"optimal: {chunk_stats['chunks_optimal']}/{chunk_stats['total_chunks']}")
    
    return chunk_stats

def categorize_people_ops_chunk_size_by_words(word_count: int) -> str:
    """Categorize chunk size for people & ops analysis"""
    if word_count < 200:
        return "small"
    elif word_count < 350:
        return "optimal"
    elif word_count < 600:
        return "large"
    else:
        return "oversized"

def calculate_people_ops_semantic_completeness(content: str) -> float:
    """Calculate semantic completeness score for people & ops content"""
    
    # People & ops-specific completeness indicators
    completeness_indicators = {
        'leadership_words': ['leadership', 'lead', 'manage', 'direct', 'guide', 'influence'],
        'team_words': ['team', 'group', 'staff', 'employees', 'workforce', 'personnel'],
        'process_words': ['process', 'procedure', 'workflow', 'system', 'method', 'approach'],
        'culture_words': ['culture', 'values', 'beliefs', 'environment', 'climate', 'atmosphere'],
        'organization_words': ['organization', 'structure', 'hierarchy', 'reporting', 'roles', 'responsibilities'],
        'performance_words': ['performance', 'results', 'outcomes', 'metrics', 'goals', 'objectives'],
        'development_words': ['development', 'training', 'growth', 'learning', 'skills', 'capabilities'],
        'communication_words': ['communication', 'feedback', 'collaboration', 'transparency', 'alignment'],
        'change_words': ['change', 'transformation', 'improvement', 'optimization', 'enhancement']
    }
    
    content_lower = content.lower()
    total_indicators = 0
    found_indicators = 0
    
    for category, words in completeness_indicators.items():
        total_indicators += len(words)
        found_indicators += sum(1 for word in words if word in content_lower)
    
    base_completeness = found_indicators / total_indicators if total_indicators > 0 else 0
    
    # Length bonus (longer content is generally more complete)
    word_count = len(content.split())
    length_factor = min(1.0, word_count / 400)  # Optimal around 400 words for people & ops
    
    # Structure bonus (headers, bullets, etc.)
    structure_indicators = ['##', '###', '- ', '* ', '1.', '2.', '3.', 'Chapter', 'Step', 'Phase']
    structure_count = sum(1 for indicator in structure_indicators if indicator in content)
    structure_factor = min(0.2, structure_count * 0.03)  # Up to 0.2 bonus
    
    # People & ops-specific bonus for strategic language
    strategic_indicators = ['recommend', 'suggest', 'should', 'focus on', 'prioritize', 'implement']
    strategic_count = sum(1 for indicator in strategic_indicators if indicator in content_lower)
    strategic_factor = min(0.15, strategic_count * 0.03)
    
    final_completeness = min(1.0, base_completeness + length_factor * 0.3 + structure_factor + strategic_factor)
    
    return final_completeness

def create_people_ops_chunk_word_document(content: str, title: str, user_profile: Dict, 
                                        section_name: str, chunk_id: str) -> Document:
    """Create a professionally formatted Word document for people & ops chunk"""
    
    try:
        doc = Document()
        
        # Enhanced styling
        style = doc.styles['Normal']
        style.font.name = 'Calibri'
        style.font.size = Pt(11)
        
        # Add header with branding
        header = doc.add_heading("BACKABLE PEOPLE & OPERATIONS ENGINE", 0)
        header.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
        header_run = header.runs[0]
        header_run.font.size = Pt(24)
        header_run.font.bold = True
        header_run.font.color.rgb = RGBColor(0, 51, 102)
        
        # Add chunk title
        chunk_title = doc.add_heading(title, 1)
        chunk_title.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT
        title_run = chunk_title.runs[0]
        title_run.font.size = Pt(18)
        title_run.font.color.rgb = RGBColor(255, 102, 0)  # Orange for People & Ops
        
        # Add metadata section
        # Add metadata section (CONTINUING FROM WHERE IT WAS CUT OFF)
        if user_profile:
            metadata_para = doc.add_paragraph()
            metadata_para.add_run("Business People & Operations Context:").bold = True
            metadata_para.add_run(f"\nBusiness: {user_profile.get('business_name', 'Unknown')}")
            metadata_para.add_run(f"\nIndustry: {user_profile.get('industry', 'Unknown')}")  
            metadata_para.add_run(f"\nTeam Size: {user_profile.get('team_size', 'Unknown')} employees")
            metadata_para.add_run(f"\nPeople & Ops Section: {section_name}")
            metadata_para.add_run(f"\nChunk ID: {chunk_id}")
            metadata_para.add_run(f"\nGenerated: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}")
        
        # Add separator
        doc.add_paragraph("‚îÄ" * 60)
        
        # Add the AI-generated content with people & ops-specific formatting
        add_people_ops_content_to_document(doc, content)
        
        # Add footer
        footer_para = doc.add_paragraph()
        footer_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
        footer_run = footer_para.add_run("Generated by Backable AI People & Operations Intelligence")
        footer_run.font.size = Pt(9)
        footer_run.font.color.rgb = RGBColor(128, 128, 128)
        
        logging.info(f"üìÑ Created people & ops chunk Word document: {len(content.split())} words")
        return doc
        
    except Exception as e:
        logging.error(f"‚ùå Error creating people & ops chunk Word document: {str(e)}")
        # Return minimal document on error
        doc = Document()
        doc.add_heading("Error Creating People & Ops Document", 1)
        doc.add_paragraph(f"Error: {str(e)}")
        return doc

# ======================================================
#           PEOPLE & OPS QUESTION-RESPONSE CHUNKING
# ======================================================

async def create_people_ops_question_response_chunks(assessment_data: Dict, report_id: str, user_id: str) -> List[Dict]:
    """Create Question-Response Word document chunks optimized for RAG context with retry mechanism and detailed logging"""
    try:
        logging.info(f"üß† Starting Question-Response chunking for people & ops report_id={report_id}")
        logging.info(f"üìä Assessment data keys: {list(assessment_data.keys()) if assessment_data else 'No data'}")
        
        qr_chunks = []
        chunk_id = 1
        
        # Get user profile for context using async connection pooling
        logging.info(f"üë§ Retrieving user profile for user_id={user_id}")
        user_profile = await get_user_profile_data(user_id)
        if user_profile:
            business_name = user_profile.get('business_name', 'Unknown')
            industry = user_profile.get('industry', 'Unknown')
            logging.info(f"‚úÖ Retrieved user profile: {business_name} ({industry})")
        else:
            logging.warning(f"‚ö†Ô∏è No user profile found for user_id={user_id}")
        
        # Get responses from assessment data
        responses = assessment_data.get('responses', [])
        if not responses:
            logging.error(f"‚ùå No responses found in people & ops assessment data")
            logging.error(f"üîç Assessment data structure: {assessment_data}")
            return []
        
        logging.info(f"üìä Processing {len(responses)} people & ops responses for Q&R chunking")
        logging.info(f"üìä Sample response structure: {responses[0] if responses else 'No responses'}")
        
        # RAG-optimized chunking settings
        TARGET_SIZE_WORDS = 800
        MAX_SIZE_WORDS = 1000
        MIN_SIZE_WORDS = 0
        
        logging.info(f"‚öôÔ∏è Chunking parameters: target={TARGET_SIZE_WORDS}, max={MAX_SIZE_WORDS}, min={MIN_SIZE_WORDS}")
        
        # Group responses by section/chapter for better context
        section_groups = {}
        section_response_counts = {}
        
        logging.info(f"üìÇ Grouping responses by section...")
        
        for i, response in enumerate(responses):
            section = response.get('section', f'Unknown People & Ops Section {i+1}')
            if section not in section_groups:
                section_groups[section] = []
                section_response_counts[section] = 0
            section_groups[section].append(response)
            section_response_counts[section] += 1
        
        logging.info(f"üìÇ Grouped people & ops responses into {len(section_groups)} sections:")
        for section_name, count in section_response_counts.items():
            logging.info(f"   - {section_name}: {count} responses")
        
        # Track processing results for comprehensive analysis
        processing_results = {
            'total_sections': len(section_groups),
            'successful_sections': [],
            'failed_sections': [],
            'retry_sections': [],
            'section_details': {}
        }
        
        # STEP 1: First pass - process all sections with detailed tracking
        logging.info(f"üîÑ PHASE 1: Initial processing of all {len(section_groups)} sections")
        
        for section_index, (section_name, section_responses) in enumerate(section_groups.items(), 1):
            section_start_time = time.time()
            section_result = {
                'section_name': section_name,
                'response_count': len(section_responses),
                'chunks_created': 0,
                'processing_time': 0,
                'status': 'pending',
                'error': None,
                'attempt': 1
            }
            
            try:
                logging.info(f"üîÑ Processing section {section_index}/{len(section_groups)}: {section_name}")
                logging.info(f"üìä Section details: {len(section_responses)} responses")
                
                # Create chunks from this section's responses
                logging.debug(f"üîß Calling create_people_ops_section_qr_chunks for {section_name}")
                section_qr_chunks = create_people_ops_section_qr_chunks(
                    section_name, section_responses, TARGET_SIZE_WORDS, MAX_SIZE_WORDS, MIN_SIZE_WORDS
                )
                
                section_processing_time = time.time() - section_start_time
                section_result['processing_time'] = section_processing_time
                
                if section_qr_chunks:
                    logging.info(f"‚úÖ Section {section_name} created {len(section_qr_chunks)} raw chunks")
                    section_result['chunks_created'] = len(section_qr_chunks)
                    section_result['status'] = 'success'
                    
                    # Convert each chunk to Word document
                    section_chunks_added = 0
                    for i, chunk_content in enumerate(section_qr_chunks):
                        try:
                            chunk_title = section_name if len(section_qr_chunks) == 1 else f"{section_name} - Part {i+1}"
                            
                            logging.debug(f"üìù Creating Word document for chunk {i+1}/{len(section_qr_chunks)}")
                            
                            # Create Word document for this Q&R chunk
                            chunk_doc = create_people_ops_qr_chunk_word_document(
                                chunk_content, 
                                chunk_title, 
                                user_profile,
                                section_name,
                                f"{report_id}_people_ops_qr_chunk_{chunk_id:03d}"
                            )
                            
                            # Calculate metrics with safety checks
                            word_count = 0
                            character_count = 0
                            question_count = len(chunk_content.get('question_responses', []))
                            
                            for qr in chunk_content.get('question_responses', []):
                                combined_text = qr.get('combined_text', '')
                                word_count += len(combined_text.split())
                                character_count += len(combined_text)
                            
                            # Create preview text with safety
                            preview_texts = []
                            for qr in chunk_content.get('question_responses', [])[:2]:  # First 2 Q&R pairs
                                q_text = qr.get('question_text', 'No question')[:100]
                                r_text = qr.get('response_text', 'No response')[:100]
                                preview_texts.append(f"Q: {q_text}... A: {r_text}...")
                            content_preview = " | ".join(preview_texts) if preview_texts else "No preview available"
                            
                            chunk_info = {
                                "chunk_id": f"{report_id}_people_ops_qr_chunk_{chunk_id:03d}",
                                "expansion_title": chunk_title,
                                "word_count": word_count,
                                "question_count": question_count,
                                "character_count": character_count,
                                "content_preview": content_preview,
                                "questions_included": [qr.get('question_id', f'unknown_{j}') for j, qr in enumerate(chunk_content.get('question_responses', []))],
                                "document": chunk_doc,
                                "chunk_metadata": {
                                    "original_section": section_name,
                                    "chunk_size_category": categorize_people_ops_chunk_size_by_words(word_count),
                                    "question_density": question_count / max(1, word_count / 100),  # questions per 100 words
                                    "chunk_type": "question_response_rag",
                                    "rag_optimized": True,
                                    "processing_attempt": 1,
                                    "section_index": section_index
                                },
                                "user_context": {
                                    "user_id": user_id,
                                    "business_name": user_profile.get("business_name", "Unknown") if user_profile else "Unknown",
                                    "industry": user_profile.get("industry", "Unknown") if user_profile else "Unknown",
                                    "team_size": user_profile.get("team_size", "Unknown") if user_profile else "Unknown"
                                },
                                "created_at": datetime.now().isoformat()
                            }
                            
                            qr_chunks.append(chunk_info)
                            section_chunks_added += 1
                            chunk_id += 1
                            
                            logging.info(f"‚úÖ Created People & Ops Q&R chunk {chunk_id-1}: {question_count} questions, {word_count} words")
                            
                        except Exception as chunk_error:
                            logging.error(f"‚ùå Error creating individual chunk {i+1} for section {section_name}: {chunk_error}")
                            continue
                    
                    if section_chunks_added > 0:
                        processing_results['successful_sections'].append(section_name)
                        section_result['final_chunks_added'] = section_chunks_added
                        logging.info(f"‚úÖ Section {section_name} completed: {section_chunks_added} chunks added to final list")
                    else:
                        logging.warning(f"‚ö†Ô∏è Section {section_name} created raw chunks but failed to convert to Word documents")
                        processing_results['failed_sections'].append(section_name)
                        section_result['status'] = 'partial_failure'
                        section_result['error'] = 'Failed to convert chunks to Word documents'
                else:
                    logging.warning(f"‚ö†Ô∏è Section {section_name} returned no chunks")
                    processing_results['failed_sections'].append(section_name)
                    section_result['status'] = 'no_chunks'
                    section_result['error'] = 'No chunks returned from section processing'
                
            except Exception as section_error:
                section_processing_time = time.time() - section_start_time
                section_result['processing_time'] = section_processing_time
                section_result['status'] = 'error'
                section_result['error'] = str(section_error)
                
                logging.error(f"‚ùå Error processing section {section_name}: {section_error}")
                logging.error(f"üîç Section error traceback: {traceback.format_exc()}")
                processing_results['failed_sections'].append(section_name)
            
            processing_results['section_details'][section_name] = section_result
            logging.info(f"üìä Section {section_name} summary: {section_result['status']} in {section_result['processing_time']:.2f}s")
        
        # STEP 2: Analyze first pass results and handle retries if needed
        total_successful = len(processing_results['successful_sections'])
        total_failed = len(processing_results['failed_sections'])
        success_rate = (total_successful / processing_results['total_sections']) * 100
        
        logging.info(f"üìä PHASE 1 RESULTS:")
        logging.info(f"   - Total sections: {processing_results['total_sections']}")
        logging.info(f"   - Successful: {total_successful}")
        logging.info(f"   - Failed: {total_failed}")
        logging.info(f"   - Success rate: {success_rate:.1f}%")
        logging.info(f"   - Total chunks created: {len(qr_chunks)}")
        
        # STEP 3: Retry failed sections (if any and success rate is low)
        if processing_results['failed_sections'] and success_rate < 80:
            logging.warning(f"üîÑ PHASE 2: Retrying {len(processing_results['failed_sections'])} failed sections")
            
            for retry_section in processing_results['failed_sections'][:]:  # Copy list to avoid modification issues
                if retry_section not in section_groups:
                    continue
                    
                retry_start_time = time.time()
                logging.info(f"üîÑ RETRY: Attempting {retry_section} again...")
                
                try:
                    # Use simplified approach for retry
                    section_responses = section_groups[retry_section]
                    
                    # Create a single consolidated chunk for failed sections
                    logging.info(f"üîß RETRY STRATEGY: Creating simplified chunk for {retry_section}")
                    
                    consolidated_chunk = {
                        "question_responses": []
                    }
                    
                    total_retry_words = 0
                    for response in section_responses:
                        try:
                            # Simplified response processing for retry
                            question_text = response.get('question_text', 'Question not available')
                            response_data = response.get('response_data', {})
                            question_id = response.get('question_id', 'unknown')
                            
                            # Safe response extraction
                            if isinstance(response_data, dict):
                                selected_response = str(response_data.get('selected_option') or 
                                                     response_data.get('response_text') or 
                                                     response_data.get('slider_value') or 
                                                     response_data.get('value') or 
                                                     'No response available')
                            else:
                                selected_response = str(response_data) if response_data else 'No response available'
                            
                            # Simplified combined text
                            combined_text = f"People & Ops Question: {question_text}\nResponse: {selected_response}\nSection: {retry_section}"
                            
                            qr_item = {
                                "question_id": question_id,
                                "question_text": question_text,
                                "response_text": selected_response,
                                "combined_text": combined_text,
                                "word_count": len(combined_text.split()),
                                "metadata": response.get('metadata', {}),
                                "all_options": response.get('all_options', []),
                                "context_richness": "simplified_retry"
                            }
                            
                            consolidated_chunk["question_responses"].append(qr_item)
                            total_retry_words += qr_item["word_count"]
                            
                        except Exception as response_retry_error:
                            logging.error(f"‚ùå Error in retry processing response in {retry_section}: {response_retry_error}")
                            continue
                    
                    if consolidated_chunk["question_responses"]:
                        # Create Word document for retry chunk
                        chunk_title = f"{retry_section} (Retry)"
                        
                        chunk_doc = create_people_ops_qr_chunk_word_document(
                            consolidated_chunk, 
                            chunk_title, 
                            user_profile,
                            retry_section,
                            f"{report_id}_people_ops_qr_chunk_{chunk_id:03d}"
                        )
                        
                        retry_chunk_info = {
                            "chunk_id": f"{report_id}_people_ops_qr_chunk_{chunk_id:03d}",
                            "expansion_title": chunk_title,
                            "word_count": total_retry_words,
                            "question_count": len(consolidated_chunk["question_responses"]),
                            "character_count": sum(len(qr.get('combined_text', '')) for qr in consolidated_chunk["question_responses"]),
                            "content_preview": f"Retry chunk for {retry_section} with {len(consolidated_chunk['question_responses'])} questions",
                            "questions_included": [qr.get('question_id') for qr in consolidated_chunk["question_responses"]],
                            "document": chunk_doc,
                            "chunk_metadata": {
                                "original_section": retry_section,
                                "chunk_size_category": categorize_people_ops_chunk_size_by_words(total_retry_words),
                                "question_density": len(consolidated_chunk["question_responses"]) / max(1, total_retry_words / 100),
                                "chunk_type": "question_response_retry",
                                "rag_optimized": True,
                                "processing_attempt": 2,
                                "retry_strategy": "simplified_consolidation"
                            },
                            "user_context": {
                                "user_id": user_id,
                                "business_name": user_profile.get("business_name", "Unknown") if user_profile else "Unknown",
                                "industry": user_profile.get("industry", "Unknown") if user_profile else "Unknown",
                                "team_size": user_profile.get("team_size", "Unknown") if user_profile else "Unknown"
                            },
                            "created_at": datetime.now().isoformat()
                        }
                        
                        qr_chunks.append(retry_chunk_info)
                        chunk_id += 1
                        
                        # Update tracking
                        processing_results['failed_sections'].remove(retry_section)
                        processing_results['retry_sections'].append(retry_section)
                        processing_results['section_details'][retry_section]['status'] = 'retry_success'
                        processing_results['section_details'][retry_section]['attempt'] = 2
                        processing_results['section_details'][retry_section]['retry_time'] = time.time() - retry_start_time
                        
                        logging.info(f"‚úÖ RETRY SUCCESS: {retry_section} recovered with {len(consolidated_chunk['question_responses'])} questions")
                        
                except Exception as retry_error:
                    retry_time = time.time() - retry_start_time
                    processing_results['section_details'][retry_section]['retry_error'] = str(retry_error)
                    processing_results['section_details'][retry_section]['retry_time'] = retry_time
                    logging.error(f"‚ùå RETRY FAILED: {retry_section} - {retry_error}")
        
        # STEP 4: Final comprehensive analysis
        final_successful = len(processing_results['successful_sections']) + len(processing_results['retry_sections'])
        final_failed = len(processing_results['failed_sections'])
        final_success_rate = (final_successful / processing_results['total_sections']) * 100
        
        avg_words_per_chunk = sum(c['word_count'] for c in qr_chunks) // len(qr_chunks) if qr_chunks else 0
        total_questions = sum(c['question_count'] for c in qr_chunks)
        
        logging.info(f"üéâ FINAL PEOPLE & OPS Q&R PROCESSING RESULTS:")
        logging.info(f"   - Total sections processed: {processing_results['total_sections']}")
        logging.info(f"   - Successful (first pass): {len(processing_results['successful_sections'])}")
        logging.info(f"   - Recovered (retry): {len(processing_results['retry_sections'])}")
        logging.info(f"   - Still failed: {final_failed}")
        logging.info(f"   - Final success rate: {final_success_rate:.1f}%")
        logging.info(f"   - Total chunks created: {len(qr_chunks)}")
        logging.info(f"   - Total questions processed: {total_questions}")
        logging.info(f"   - Average words per chunk: {avg_words_per_chunk}")
        
        # Log section-by-section results
        logging.info(f"üìã DETAILED SECTION RESULTS:")
        for section_name, details in processing_results['section_details'].items():
            status_emoji = "‚úÖ" if details['status'] in ['success', 'retry_success'] else "‚ùå"
            logging.info(f"   {status_emoji} {section_name}: {details['status']} (attempt {details['attempt']}, {details['processing_time']:.2f}s)")
            if details.get('error'):
                logging.info(f"      Error: {details['error']}")
        
        if final_failed > 0:
            logging.warning(f"‚ö†Ô∏è {final_failed} sections still failed after retry")
            for failed_section in processing_results['failed_sections']:
                logging.warning(f"   - {failed_section}: {processing_results['section_details'][failed_section].get('error', 'Unknown error')}")
        
        logging.info(f"üéâ Successfully created {len(qr_chunks)} People & Ops Question-Response chunks")
        return qr_chunks
        
    except Exception as e:
        logging.error(f"‚ùå Fatal error creating People & Ops Question-Response chunks: {str(e)}")
        import traceback
        logging.error(f"üîç Full traceback: {traceback.format_exc()}")
        return []

def create_people_ops_section_qr_chunks(section_name: str, responses: List[Dict], target_size: int, max_size: int, min_size: int) -> List[Dict]:
    """Create manageable People & Ops Q&R chunks from a section's responses with detailed logging"""
    try:
        logging.info(f"üîÑ Starting People & Ops Q&R chunk creation for section: {section_name}")
        logging.info(f"üìä Section parameters: {len(responses)} responses, target_size: {target_size}, max_size: {max_size}, min_size: {min_size}")
        
        chunks = []
        current_chunk = {"question_responses": [], "word_count": 0}
        
        # Track processing stats
        total_questions_processed = 0
        total_words_generated = 0
        ai_analysis_skipped_count = 0
        error_count = 0
        
        logging.info(f"üìù Processing {len(responses)} people & ops responses for section: {section_name}")
        
        for response_index, response in enumerate(responses):
            try:
                logging.debug(f"üîç Processing people & ops response {response_index + 1}/{len(responses)} in section: {section_name}")
                
                # Extract question and response data
                question_text = response.get('question_text', 'People & ops question not available')
                response_data = response.get('response_data', {})
                question_id = response.get('question_id', f'unknown_{response_index}')
                
                logging.debug(f"üìã People & Ops Question ID: {question_id}")
                logging.debug(f"üìã Question preview: {question_text[:50] if question_text else 'No question text'}...")
                
                # Safe data extraction with comprehensive logging
                logging.debug(f"üîç RAW DATA INSPECTION for {question_id}:")
                logging.debug(f"  - response_data type: {type(response_data)}")
                if isinstance(response_data, dict):
                    logging.debug(f"  - response_data keys: {list(response_data.keys())}")
                
                # Safe response extraction
                selected_response = None
                extraction_method = "unknown"
                
                if isinstance(response_data, dict):
                    if 'selected_option' in response_data:
                        selected_response = response_data['selected_option']
                        extraction_method = "selected_option"
                    elif 'selected_options' in response_data:  # Multiple selections
                        raw_value = response_data['selected_options']
                        if isinstance(raw_value, list):
                            selected_response = ', '.join(str(item) for item in raw_value)
                        else:
                            selected_response = str(raw_value)
                        extraction_method = "selected_options"
                    elif 'response_text' in response_data:
                        selected_response = response_data['response_text']
                        extraction_method = "response_text"
                    elif 'slider_value' in response_data:
                        selected_response = f"People & Ops Rating: {response_data['slider_value']}"
                        extraction_method = "slider_value"
                    elif 'value' in response_data:
                        selected_response = response_data['value']
                        extraction_method = "value"
                    else:
                        # Handle any other fields
                        for key, value in response_data.items():
                            if value is not None:
                                selected_response = value
                                extraction_method = f"fallback_{key}"
                                break
                        if selected_response is None:
                            selected_response = 'People & ops response not available'
                            extraction_method = "placeholder"
                elif response_data is not None:
                    selected_response = response_data
                    extraction_method = "direct_non_dict"
                else:
                    selected_response = 'People & ops response not available'
                    extraction_method = "no_data"
                
                # Safe string conversion
                try:
                    if selected_response is None:
                        selected_response_str = 'No response provided'
                    elif isinstance(selected_response, (list, tuple)):
                        selected_response_str = ', '.join(str(item) for item in selected_response)
                    elif isinstance(selected_response, dict):
                        selected_response_str = f"Dict response: {selected_response}"
                    else:
                        selected_response_str = str(selected_response)
                except Exception as conversion_error:
                    logging.error(f"  - String conversion failed: {conversion_error}")
                    selected_response_str = f"Conversion error for {type(selected_response)}"
                    error_count += 1
                
                # Get all available options with safety
                all_options = response.get('all_options', [])
                
                # Create enhanced combined Q&R text with rich people & ops context
                combined_text = f"People & Operations Question: {question_text}\n\n"
                
                # Add available options context
                if all_options:
                    combined_text += "Available People & Operations Options:\n"
                    try:
                        if isinstance(all_options, list):
                            # Handle list of options (normal case)
                            for i, option in enumerate(all_options, 1):
                                option_str = str(option)
                                if option_str == selected_response_str:
                                    combined_text += f"  {i}. ‚úì {option_str} (SELECTED)\n"
                                else:
                                    combined_text += f"  {i}. {option_str}\n"
                        elif isinstance(all_options, dict):
                            # Handle dictionary options (slider questions, etc.)
                            if 'labels' in all_options:
                                labels = all_options['labels']
                                min_val = all_options.get('min', 1)
                                max_val = all_options.get('max', 10)
                                combined_text += f"  Scale: {min_val} to {max_val}\n"
                                combined_text += f"  Labels: {', '.join(labels)}\n"
                            else:
                                # Generic dict handling
                                for key, value in all_options.items():
                                    combined_text += f"  {key}: {value}\n"
                        else:
                            # Handle other types
                            combined_text += f"  Options: {str(all_options)}\n"
                        
                        combined_text += f"\nClient's People & Operations Choice: {selected_response_str}\n"
                        
                    except Exception as options_error:
                        logging.error(f"üìã Error processing options: {options_error}")
                        combined_text += f"Client's People & Operations Choice: {selected_response_str}\n"
                        error_count += 1
                else:
                    combined_text += f"Client's People & Operations Response: {selected_response_str}\n"
                
                # Add people & ops-specific question context
                combined_text += f"\n--- People & Operations Context ---"
                combined_text += f"\nOrganizational Area: {response.get('section', 'Unknown')}"
                combined_text += f"\nQuestion Priority: {str(response.get('weight', 'medium')).upper()}"
                combined_text += f"\nQuestion Type: {response.get('question_type', 'people_ops_assessment')}"
                combined_text += f"\nPeople & Ops Question ID: {question_id}"
                combined_text += f"\nData Extraction Method: {extraction_method}"
                
                # Add response analytics from metadata
                metadata = response.get('metadata', {})
                if metadata:
                    timing_info = metadata.get('timing_data', {})
                    if timing_info:
                        time_spent = timing_info.get('total_engagement_time', 0)
                        combined_text += f"\n\n--- People & Ops Response Analytics ---"
                        combined_text += f"\nResponse Time: {time_spent} seconds"
                        combined_text += f"\nFocus Time: {timing_info.get('focus_time', 'N/A')} seconds"
                        combined_text += f"\nInteraction Count: {timing_info.get('interaction_count', 'N/A')}"
                        combined_text += f"\nDecision Speed: {'Quick' if time_spent < 30 else 'Deliberate' if time_spent < 90 else 'Thorough'}"
                
                # Add response pattern analysis for people & ops
                if all_options and isinstance(all_options, list):
                    try:
                        selected_index = -1
                        for i, option in enumerate(all_options):
                            if str(option) == selected_response_str:
                                selected_index = i
                                break
                        
                        if selected_index >= 0:
                            total_options = len(all_options)
                            percentile = (selected_index + 1) / total_options
                            
                            combined_text += f"\n\n--- People & Ops Response Pattern Analysis ---"
                            combined_text += f"\nSelected Option: {selected_index + 1} of {total_options}"
                            combined_text += f"\nResponse Percentile: {percentile:.1%}"
                            combined_text += f"\nOrganizational Preference: {'Conservative' if percentile <= 0.33 else 'Balanced' if percentile <= 0.66 else 'Progressive'}"
                    except Exception as pattern_error:
                        logging.error(f"üìà Error in pattern analysis: {pattern_error}")
                        error_count += 1
                
                # Skip AI-Generated analysis to preserve API keys for main report
                logging.debug(f"üö´ Skipping AI analysis for people & ops question {question_id} to preserve API keys for main report")
                ai_analysis_skipped_count += 1
                
                # Add enhanced basic analysis for people & ops context
                combined_text += f"\n\n--- Basic People & Ops Analysis ---"
                combined_text += f"\nOrganizational Focus Area: {section_name}"
                combined_text += f"\nStrategic Priority: {response.get('weight', 'medium')}"
                combined_text += f"\nAssessment Context: People & operations strategy evaluation for leadership, team architecture, and organizational systems"
                combined_text += f"\nOrganizational Stage Relevance: Applicable to current business phase and team development trajectory"
                combined_text += f"\nAnalysis Status: Basic analysis used to preserve API capacity for comprehensive people & ops strategy report"
                combined_text += f"\nProcessing Status: Successful extraction via {extraction_method}"
                
                # Calculate word count for this Q&R item
                qr_word_count = len(combined_text.split())
                total_words_generated += qr_word_count
                
                qr_item = {
                    "question_id": question_id,
                    "question_text": question_text,
                    "response_text": selected_response_str,
                    "combined_text": combined_text,
                    "word_count": qr_word_count,
                    "metadata": metadata,
                    "all_options": all_options,
                    "context_richness": "basic_people_ops_analysis",
                    "extraction_method": extraction_method,
                    "processing_errors": error_count
                }
                
                # Check if adding this Q&R would exceed max size
                if current_chunk["word_count"] + qr_item["word_count"] > max_size and current_chunk["question_responses"]:
                    # Current chunk is full, save it if substantial
                    if current_chunk["word_count"] >= min_size:
                        chunks.append(current_chunk)
                        logging.info(f"‚úÖ Completed People & Ops Q&R chunk {len(chunks)}: {len(current_chunk['question_responses'])} questions, {current_chunk['word_count']} words")
                        current_chunk = {"question_responses": [], "word_count": 0}
                
                # Add Q&R to current chunk
                current_chunk["question_responses"].append(qr_item)
                current_chunk["word_count"] += qr_item["word_count"]
                total_questions_processed += 1
                
            except Exception as response_error:
                logging.error(f"‚ùå Error processing individual response {response_index + 1} in {section_name}: {response_error}")
                error_count += 1
                continue
        
        # Add the last chunk if it's substantial
        if current_chunk["question_responses"] and current_chunk["word_count"] >= min_size:
            chunks.append(current_chunk)
            logging.info(f"‚úÖ Completed final People & Ops Q&R chunk {len(chunks)}: {len(current_chunk['question_responses'])} questions, {current_chunk['word_count']} words")
        elif current_chunk["question_responses"]:
            logging.warning(f"‚ö†Ô∏è Final People & Ops chunk discarded (too small): {len(current_chunk['question_responses'])} questions, {current_chunk['word_count']} words < {min_size} min")
        
        # Calculate final statistics
        avg_words_per_chunk = total_words_generated // len(chunks) if chunks else 0
        avg_questions_per_chunk = total_questions_processed // len(chunks) if chunks else 0
        
        logging.info(f"üéâ People & Ops Q&R chunk creation completed for section: {section_name}")
        logging.info(f"üìä Final statistics:")
        logging.info(f"   - Total chunks created: {len(chunks)}")
        logging.info(f"   - Total questions processed: {total_questions_processed}")
        logging.info(f"   - Total questions attempted: {len(responses)}")
        logging.info(f"   - Total words generated: {total_words_generated:,}")
        logging.info(f"   - Average words per chunk: {avg_words_per_chunk}")
        logging.info(f"   - Average questions per chunk: {avg_questions_per_chunk}")
        logging.info(f"   - AI analysis skipped: {ai_analysis_skipped_count} (to preserve API keys)")
        logging.info(f"   - Processing errors: {error_count}")
        logging.info(f"   - Success rate: {((total_questions_processed / len(responses)) * 100):.1f}%" if responses else "N/A")
        
        return chunks
        
    except Exception as e:
        logging.error(f"‚ùå Fatal error creating People & Ops section Q&R chunks for {section_name}: {str(e)}")
        import traceback
        logging.error(f"üîç Full traceback: {traceback.format_exc()}")
        return []

def create_people_ops_qr_chunk_word_document(chunk_content: Dict, title: str, user_profile: Dict, section_name: str, chunk_id: str) -> Document:
    """Create a professionally formatted Word document for People & Ops Question-Response chunk"""
    try:
        doc = Document()
        
        # Enhanced styling
        style = doc.styles['Normal']
        style.font.name = 'Calibri'
        style.font.size = Pt(11)
        
        # Add header with branding
        header = doc.add_heading("BACKABLE PEOPLE & OPERATIONS ENGINE - Q&A CONTEXT", 0)
        header.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
        header_run = header.runs[0]
        header_run.font.size = Pt(20)
        header_run.font.bold = True
        header_run.font.color.rgb = RGBColor(0, 51, 102)
        
        # Add chunk title
        chunk_title = doc.add_heading(title, 1)
        chunk_title.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT
        title_run = chunk_title.runs[0]
        title_run.font.size = Pt(16)
        title_run.font.color.rgb = RGBColor(255, 102, 0)  # Orange for People & Ops
        
        # Add metadata section
        if user_profile:
            metadata_para = doc.add_paragraph()
            metadata_para.add_run("Business People & Operations Context:").bold = True
            metadata_para.add_run(f"\nBusiness: {user_profile.get('business_name', 'Unknown')}")
            metadata_para.add_run(f"\nIndustry: {user_profile.get('industry', 'Unknown')}")
            metadata_para.add_run(f"\nTeam Size: {user_profile.get('team_size', 'Unknown')} employees")
            metadata_para.add_run(f"\nOrganizational Section: {section_name}")
            metadata_para.add_run(f"\nChunk ID: {chunk_id}")
            metadata_para.add_run(f"\nQuestions Included: {len(chunk_content['question_responses'])}")
            metadata_para.add_run(f"\nGenerated: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}")
        
        # Add separator
        doc.add_paragraph("‚îÄ" * 60)
        
        # Add RAG context note
        rag_note = doc.add_paragraph()
        rag_note_run = rag_note.add_run("üë• PEOPLE & OPS RAG CONTEXT: This document contains the client's actual people & operations questions and responses for AI context. Use this to understand their specific organizational choices, leadership preferences, and operational reasoning.")
        rag_note_run.font.color.rgb = RGBColor(255, 102, 0)  # Orange for People & Ops
        rag_note_run.italic = True
        
        doc.add_paragraph("‚îÄ" * 60)
        
        # Process each question-response pair
        for i, qr in enumerate(chunk_content['question_responses']):
            # Question header
            question_heading = doc.add_heading(f"People & Ops Question {i+1}: {qr['question_id']}", 2)
            question_heading_run = question_heading.runs[0]
            question_heading_run.font.color.rgb = RGBColor(0, 51, 102)
            
            # Question text
            question_para = doc.add_paragraph()
            question_para.add_run("Organizational Q: ").bold = True
            question_para.add_run(qr['question_text'])
            
            # Response text
            response_para = doc.add_paragraph()
            response_para.add_run("Leadership A: ").bold = True
            response_para.add_run(qr['response_text'])
            
            # Add people & ops-specific metadata if available
            metadata = qr.get('metadata', {})
            if metadata:
                timing_data = metadata.get('timing_data', {})
                if timing_data.get('total_engagement_time'):
                    meta_para = doc.add_paragraph()
                    meta_run = meta_para.add_run(f"Decision Time: {timing_data['total_engagement_time']} seconds")
                    meta_run.font.size = Pt(9)
                    meta_run.font.color.rgb = RGBColor(128, 128, 128)
            
            # Add space between Q&R pairs
            if i < len(chunk_content['question_responses']) - 1:
                doc.add_paragraph("‚îÄ" * 30)
        
        # Add footer
        footer_para = doc.add_paragraph()
        footer_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
        footer_run = footer_para.add_run("Generated by Backable AI People & Operations Intelligence for RAG Context")
        footer_run.font.size = Pt(9)
        footer_run.font.color.rgb = RGBColor(128, 128, 128)
        
        logging.info(f"üìÑ Created People & Ops Q&R Word document: {len(chunk_content['question_responses'])} questions")
        return doc
        
    except Exception as e:
        logging.error(f"‚ùå Error creating People & Ops Q&R Word document: {str(e)}")
        # Return minimal document on error
        doc = Document()
        doc.add_heading("Error Creating People & Ops Q&R Document", 1)
        doc.add_paragraph(f"Error: {str(e)}")
        return doc

# ======================================================
#           UTILITY FUNCTIONS
# ======================================================

def get_last_n_words(text: str, n: int) -> str:
    """Get last N words from text for overlap between chunks"""
    words = text.split()
    if len(words) <= n:
        return text
    return " ".join(words[-n:])

def get_first_n_words(text: str, n: int) -> str:
    """Get first N words from text for overlap between chunks"""
    words = text.split()
    if len(words) <= n:
        return text
    return " ".join(words[:n])

# ======================================================
#           People & Operations Indexer Integration  
# ======================================================

async def trigger_people_ops_indexer_for_client(client_id: str, force: bool = False, new_client: bool = False) -> tuple[bool, str, Optional[str]]:
    """Enhanced people & ops indexer trigger with comprehensive error handling and retry logic"""
    
    logging.info(f"üöÄ PEOPLE & OPS INDEXER: Starting for client_id={client_id}")
    logging.info(f"üìä Indexer parameters:")
    logging.info(f"   - Client ID: {client_id}")
    logging.info(f"   - Force reindex: {force}")
    logging.info(f"   - New client: {new_client}")
    logging.info(f"   - API Base URL: {INDEXER_API_BASE_URL}")
    logging.info(f"   - Timeout: {INDEXER_TIMEOUT}s")
    logging.info(f"   - Max retries: {INDEXER_RETRY_ATTEMPTS}")
    
    # Track retry attempts for this specific call
    max_retries = INDEXER_RETRY_ATTEMPTS
    base_delay = INDEXER_RETRY_DELAY
    
    for attempt in range(max_retries):
        attempt_start_time = time.time()
        logging.info(f"üîÑ PEOPLE & OPS INDEXER: Attempt {attempt + 1}/{max_retries} for client_id={client_id}")
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=INDEXER_TIMEOUT)) as session:
                payload = {
                    "client_id": client_id,
                    "force": force,
                    "new_client": new_client
                }
                
                # Enhanced payload logging for people & ops
                logging.info(f"üì§ PEOPLE & OPS INDEXER: Sending payload")
                logging.info(f"üìä Payload details:")
                logging.info(f"   - Client ID: {payload['client_id']}")
                logging.info(f"   - Force: {payload['force']}")
                logging.info(f"   - New client: {payload['new_client']}")
                logging.info(f"   - JSON size: {len(json.dumps(payload))} bytes")
                
                # Make API request
                indexer_url = f"{INDEXER_API_BASE_URL}/run-indexer"
                logging.info(f"üåê PEOPLE & OPS INDEXER: Making request to {indexer_url}")
                
                async with session.post(
                    indexer_url,
                    json=payload,
                    headers={"Content-Type": "application/json"}
                ) as response:
                    
                    request_time = time.time() - attempt_start_time
                    
                    # Enhanced response logging for people & ops
                    logging.info(f"üì° PEOPLE & OPS INDEXER: Response received")
                    logging.info(f"üìä Response details:")
                    logging.info(f"   - Status code: {response.status}")
                    logging.info(f"   - Response time: {request_time:.3f}s")
                    logging.info(f"   - Content type: {response.headers.get('content-type', 'Unknown')}")
                    logging.info(f"   - Content length: {response.headers.get('content-length', 'Unknown')}")
                    logging.info(f"   - Headers: {dict(response.headers)}")
                    
                    try:
                        response_data = await response.json()
                        logging.info(f"‚úÖ PEOPLE & OPS INDEXER: JSON parsing successful")
                        logging.info(f"üìä Response data keys: {list(response_data.keys())}")
                        
                    except Exception as json_error:
                        logging.error(f"‚ùå PEOPLE & OPS INDEXER: JSON parse error: {json_error}")
                        response_text = await response.text()
                        logging.error(f"üîç Raw response text (first 500 chars): {response_text[:500]}...")
                        logging.error(f"üîç Response text length: {len(response_text)}")
                        
                        if attempt < max_retries - 1:
                            wait_time = base_delay * (2 ** attempt)  # Exponential backoff
                            logging.warning(f"‚è≥ PEOPLE & OPS INDEXER: JSON parse failed, retrying in {wait_time}s...")
                            await asyncio.sleep(wait_time)
                            continue
                        else:
                            return False, f"JSON parse error: {json_error}", None
                    
                    # Handle different response statuses with people & ops context
                    if response.status == 202:  # Accepted - Success
                        job_id = response_data.get("job_id")
                        message = response_data.get("message", "People & ops indexer job started successfully")
                        
                        # Enhanced success logging for people & ops
                        logging.info(f"üéâ PEOPLE & OPS INDEXER: TRIGGER SUCCESSFUL!")
                        logging.info(f"‚úÖ Success details:")
                        logging.info(f"   - Client ID: {client_id}")
                        logging.info(f"   - Job ID: {job_id}")
                        logging.info(f"   - Message: {message}")
                        logging.info(f"   - Attempt: {attempt + 1}/{max_retries}")
                        logging.info(f"   - Request time: {request_time:.3f}s")
                        logging.info(f"   - Response data: {response_data}")
                        
                        return True, message, job_id
                    
                    elif response.status == 409:  # Conflict - Job already in progress
                        message = response_data.get("message", "People & ops indexer job already in progress")
                        logging.warning(f"‚ö†Ô∏è PEOPLE & OPS INDEXER: Conflict for client_id={client_id}")
                        logging.warning(f"üìä Conflict details:")
                        logging.warning(f"   - Message: {message}")
                        logging.warning(f"   - This means indexing is already running for this client")
                        logging.warning(f"   - No retry needed - existing job will complete")
                        
                        # For conflicts, we don't retry - return immediately
                        return False, message, None
                    
                    elif response.status == 404:  # Client not found
                        message = response_data.get("message", "Client not found in indexer")
                        logging.warning(f"‚ö†Ô∏è PEOPLE & OPS INDEXER: Client not found: client_id={client_id}")
                        logging.warning(f"üìä 404 details:")
                        logging.warning(f"   - Message: {message}")
                        logging.warning(f"   - New client flag: {new_client}")
                        
                        # Auto-retry with new_client=True if not already set
                        if not new_client and attempt == 0:
                            logging.info(f"üîÑ PEOPLE & OPS INDEXER: Retrying with new_client=True for {client_id}")
                            return await trigger_people_ops_indexer_for_client(client_id, force, True)
                        else:
                            return False, f"Client not found: {message}", None
                    
                    elif response.status == 429:  # Rate Limited
                        message = response_data.get("message", "People & ops indexer rate limited")
                        logging.warning(f"üö¶ PEOPLE & OPS INDEXER: Rate limited for client_id={client_id}")
                        logging.warning(f"üìä Rate limit details:")
                        logging.warning(f"   - Message: {message}")
                        logging.warning(f"   - Response data: {response_data}")
                        
                        # Wait longer for rate limits
                        if attempt < max_retries - 1:
                            wait_time = base_delay * 2 * (attempt + 1)  # Longer wait for rate limits
                            logging.info(f"‚è≥ PEOPLE & OPS INDEXER: Rate limited, waiting {wait_time}s before retry...")
                            await asyncio.sleep(wait_time)
                            continue
                        else:
                            return False, f"Rate limited: {message}", None
                    
                    elif response.status >= 500:  # Server errors - retry
                        message = response_data.get("message", f"People & ops indexer server error {response.status}")
                        logging.error(f"üö® PEOPLE & OPS INDEXER: Server error {response.status} for client_id={client_id}")
                        logging.error(f"üìä Server error details:")
                        logging.error(f"   - Status: {response.status}")
                        logging.error(f"   - Message: {message}")
                        logging.error(f"   - Response data: {response_data}")
                        logging.error(f"   - Request time: {request_time:.3f}s")
                        
                        if attempt < max_retries - 1:
                            wait_time = base_delay * (2 ** attempt)
                            logging.info(f"‚è≥ PEOPLE & OPS INDEXER: Server error, retrying in {wait_time}s...")
                            await asyncio.sleep(wait_time)
                            continue
                        else:
                            return False, f"Server error: {message}", None
                    
                    else:  # Other client errors - don't retry
                        message = response_data.get("message", f"People & ops indexer failed with status {response.status}")
                        logging.error(f"‚ùå PEOPLE & OPS INDEXER: Client error {response.status} for client_id={client_id}")
                        logging.error(f"üìä Client error details:")
                        logging.error(f"   - Status: {response.status}")
                        logging.error(f"   - Message: {message}")
                        logging.error(f"   - Response data: {response_data}")
                        logging.error(f"   - Will not retry for client errors")
                        
                        return False, f"Client error: {message}", None
                        
        except asyncio.TimeoutError:
            request_time = time.time() - attempt_start_time
            error_msg = f"People & ops indexer request timed out after {INDEXER_TIMEOUT}s"
            
            logging.error(f"‚è∞ PEOPLE & OPS INDEXER: TIMEOUT (attempt {attempt + 1}/{max_retries})")
            logging.error(f"üìä Timeout details:")
            logging.error(f"   - Configured timeout: {INDEXER_TIMEOUT}s")
            logging.error(f"   - Actual time: {request_time:.3f}s")
            logging.error(f"   - Client ID: {client_id}")
            logging.error(f"   - API URL: {INDEXER_API_BASE_URL}")
            
            if attempt < max_retries - 1:
                wait_time = base_delay * (attempt + 1)
                logging.info(f"‚è≥ PEOPLE & OPS INDEXER: Timeout, retrying in {wait_time}s...")
                await asyncio.sleep(wait_time)
                continue
            else:
                return False, error_msg, None
                
        except aiohttp.ClientError as e:
            request_time = time.time() - attempt_start_time
            error_msg = f"People & ops indexer HTTP client error: {str(e)}"
            
            logging.error(f"üåê PEOPLE & OPS INDEXER: HTTP CLIENT ERROR (attempt {attempt + 1}/{max_retries})")
            logging.error(f"üìä HTTP error details:")
            logging.error(f"   - Error type: {type(e).__name__}")
            logging.error(f"   - Error message: {str(e)}")
            logging.error(f"   - Request time: {request_time:.3f}s")
            logging.error(f"   - Client ID: {client_id}")
            
            if attempt < max_retries - 1:
                wait_time = base_delay * (attempt + 1)
                logging.info(f"‚è≥ PEOPLE & OPS INDEXER: HTTP error, retrying in {wait_time}s...")
                await asyncio.sleep(wait_time)
                continue
            else:
                return False, error_msg, None
                
        except Exception as e:
            request_time = time.time() - attempt_start_time
            error_msg = f"People & ops indexer unexpected error: {str(e)}"
            
            logging.error(f"üí• PEOPLE & OPS INDEXER: UNEXPECTED ERROR (attempt {attempt + 1}/{max_retries})")
            logging.error(f"üìä Unexpected error details:")
            logging.error(f"   - Error type: {type(e).__name__}")
            logging.error(f"   - Error message: {str(e)}")
            logging.error(f"   - Request time: {request_time:.3f}s")
            logging.error(f"   - Client ID: {client_id}")
            
            # Log full traceback for unexpected errors
            import traceback
            logging.error(f"üîç PEOPLE & OPS INDEXER: Unexpected error traceback:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    logging.error(f"   {line}")
            
            if attempt < max_retries - 1:
                wait_time = base_delay * (attempt + 1)
                logging.info(f"‚è≥ PEOPLE & OPS INDEXER: Unexpected error, retrying in {wait_time}s...")
                await asyncio.sleep(wait_time)
                continue
            else:
                return False, error_msg, None
    
    # If we get here, all retries failed
    total_time = time.time() - attempt_start_time if 'attempt_start_time' in locals() else 0
    final_error = f"People & ops indexer failed after {max_retries} attempts"
    
    logging.error(f"üí• PEOPLE & OPS INDEXER: ALL ATTEMPTS FAILED")
    logging.error(f"üìä Final failure summary:")
    logging.error(f"   - Client ID: {client_id}")
    logging.error(f"   - Total attempts: {max_retries}")
    logging.error(f"   - Total time: {total_time:.3f}s")
    logging.error(f"   - Force flag: {force}")
    logging.error(f"   - New client flag: {new_client}")
    logging.error(f"   - Final error: {final_error}")
    
    return False, final_error, None

def store_people_ops_indexer_job_metadata(report_id: str, user_id: str, indexer_job_id: str, indexer_status: str, 
                                        indexer_response: str = None, error_message: str = None):
    """Enhanced storage of people & ops indexer job metadata with comprehensive tracking"""
    
    conn = None
    try:
        logging.info(f"üíæ PEOPLE & OPS INDEXER: Storing metadata for report_id={report_id}")
        logging.info(f"üìä Metadata storage parameters:")
        logging.info(f"   - Report ID: {report_id}")
        logging.info(f"   - User ID: {user_id}")
        logging.info(f"   - Indexer Job ID: {indexer_job_id}")
        logging.info(f"   - Indexer Status: {indexer_status}")
        logging.info(f"   - Has response: {bool(indexer_response)}")
        logging.info(f"   - Has error: {bool(error_message)}")
        
        conn = get_people_ops_connection()
        
        with conn.cursor() as cur:
            # Check if the report exists first
            check_sql = """
                SELECT COUNT(*) FROM people_ops_reports WHERE report_id = %s AND user_id = %s
            """
            cur.execute(check_sql, (report_id, user_id))
            exists = cur.fetchone()[0] > 0
            
            logging.info(f"üìã PEOPLE & OPS INDEXER: Report existence check: {exists}")
            
            if not exists:
                logging.error(f"‚ùå PEOPLE & OPS INDEXER: Report not found in database")
                logging.error(f"üìä Missing report details:")
                logging.error(f"   - Report ID: {report_id}")
                logging.error(f"   - User ID: {user_id}")
                logging.error(f"   - Cannot store indexer metadata without existing report")
                return False
            
            # Update with comprehensive indexer information
            update_sql = """
                UPDATE people_ops_reports 
                SET 
                    indexer_job_id = %s,
                    indexer_status = %s,
                    indexer_triggered_at = %s,
                    indexer_completed_at = CASE WHEN %s = 'completed' THEN %s ELSE indexer_completed_at END,
                    indexer_error_message = %s,
                    indexer_retry_count = COALESCE(indexer_retry_count, 0) + CASE WHEN %s != 'triggered' THEN 1 ELSE 0 END
                WHERE report_id = %s AND user_id = %s
            """
            
            current_time = datetime.now()
            
            logging.info(f"üìù PEOPLE & OPS INDEXER: Executing database update")
            logging.info(f"üìä SQL parameters:")
            logging.info(f"   - Job ID: {indexer_job_id}")
            logging.info(f"   - Status: {indexer_status}")
            logging.info(f"   - Triggered at: {current_time.isoformat()}")
            logging.info(f"   - Will set completed_at: {indexer_status == 'completed'}")
            logging.info(f"   - Error message: {error_message if error_message else 'None'}")
            
            cur.execute(update_sql, (
                indexer_job_id,
                indexer_status,
                current_time,
                indexer_status,  # For CASE WHEN condition
                current_time if indexer_status == 'completed' else None,
                error_message,
                indexer_status,  # For retry count condition
                report_id,
                user_id
            ))
            
            rows_affected = cur.rowcount
            
            if rows_affected > 0:
                logging.info(f"‚úÖ PEOPLE & OPS INDEXER: Database update successful")
                logging.info(f"üìä Update results:")
                logging.info(f"   - Report ID: {report_id}")
                logging.info(f"   - Job ID: {indexer_job_id}")
                logging.info(f"   - Status: {indexer_status}")
                logging.info(f"   - Rows affected: {rows_affected}")
                logging.info(f"   - Timestamp: {current_time.isoformat()}")
                
                # Log additional context if error
                if error_message:
                    logging.warning(f"‚ö†Ô∏è PEOPLE & OPS INDEXER: Error message stored in database")
                    logging.warning(f"üìä Error details:")
                    logging.warning(f"   - Error: {error_message}")
                    logging.warning(f"   - Error length: {len(error_message)} chars")
                    
                # Log successful completion
                if indexer_status == 'completed':
                    logging.info(f"üéâ PEOPLE & OPS INDEXER: Marked as COMPLETED in database")
                elif indexer_status == 'triggered':
                    logging.info(f"üîÑ PEOPLE & OPS INDEXER: Marked as TRIGGERED in database")
                elif indexer_status == 'failed':
                    logging.warning(f"‚ùå PEOPLE & OPS INDEXER: Marked as FAILED in database")
                    
                return True
            else:
                logging.error(f"‚ùå PEOPLE & OPS INDEXER: Database update failed - no rows affected")
                logging.error(f"üìä Update failure details:")
                logging.error(f"   - Report ID: {report_id}")
                logging.error(f"   - User ID: {user_id}")
                logging.error(f"   - Expected 1 row, got {rows_affected}")
                logging.error(f"   - This indicates report may not exist or ownership mismatch")
                return False
                
    except Exception as e:
        logging.error(f"‚ùå PEOPLE & OPS INDEXER: Database storage error")
        logging.error(f"üìä Storage error details:")
        logging.error(f"   - Error type: {type(e).__name__}")
        logging.error(f"   - Error message: {str(e)}")
        logging.error(f"   - Report ID: {report_id}")
        logging.error(f"   - User ID: {user_id}")
        logging.error(f"   - Indexer Job ID: {indexer_job_id}")
        logging.error(f"   - Indexer Status: {indexer_status}")
        
        # Log full traceback for database errors
        import traceback
        logging.error(f"üîç PEOPLE & OPS INDEXER: Database error traceback:")
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                logging.error(f"   {line}")
        
        return False
        
    finally:
        if conn:
            try:
                conn.close()
                logging.debug(f"üîó PEOPLE & OPS INDEXER: Database connection closed")
            except Exception as close_error:
                logging.warning(f"‚ö†Ô∏è PEOPLE & OPS INDEXER: Error closing connection: {close_error}")

async def trigger_and_monitor_people_ops_indexer(report_id: str, user_id: str, container_name: str) -> Dict:
    """Comprehensive people & ops indexer trigger with monitoring and database integration"""
    
    logging.info(f"üöÄ PEOPLE & OPS INDEXER: Starting comprehensive indexer process")
    logging.info(f"üìä Monitor parameters:")
    logging.info(f"   - Report ID: {report_id}")
    logging.info(f"   - User ID: {user_id}")
    logging.info(f"   - Container: {container_name}")
    
    monitor_start_time = time.time()
    
    # Step 1: Trigger the indexer
    logging.info(f"üì§ PEOPLE & OPS INDEXER: Step 1 - Triggering indexer")
    trigger_start_time = time.time()
    
    success, message, job_id = await trigger_people_ops_indexer_for_client(user_id)
    trigger_time = time.time() - trigger_start_time
    
    logging.info(f"üìä PEOPLE & OPS INDEXER: Trigger completed in {trigger_time:.3f}s")
    logging.info(f"üìä Trigger results:")
    logging.info(f"   - Success: {success}")
    logging.info(f"   - Message: {message}")
    logging.info(f"   - Job ID: {job_id}")
    
    if success and job_id:
        # Step 2: Store successful trigger in database
        logging.info(f"üíæ PEOPLE & OPS INDEXER: Step 2 - Storing successful trigger")
        store_start_time = time.time()
        
        store_result = store_people_ops_indexer_job_metadata(
            report_id=report_id,
            user_id=user_id,
            indexer_job_id=job_id,
            indexer_status="triggered",
            indexer_response=message
        )
        
        store_time = time.time() - store_start_time
        
        logging.info(f"üìä PEOPLE & OPS INDEXER: Database storage completed in {store_time:.3f}s")
        logging.info(f"üìä Storage result: {store_result}")
        
        if store_result:
            total_monitor_time = time.time() - monitor_start_time
            
            logging.info(f"‚úÖ PEOPLE & OPS INDEXER: PROCESS COMPLETED SUCCESSFULLY!")
            logging.info(f"üìä Final success metrics:")
            logging.info(f"   - Report ID: {report_id}")
            logging.info(f"   - Job ID: {job_id}")
            logging.info(f"   - User ID: {user_id}")
            logging.info(f"   - Container: {container_name}")
            logging.info(f"   - Trigger time: {trigger_time:.3f}s")
            logging.info(f"   - Storage time: {store_time:.3f}s")
            logging.info(f"   - Total monitor time: {total_monitor_time:.3f}s")
            logging.info(f"   - Background processing: ACTIVE")
            
            # Simplified: Skip status checking since endpoints don't exist
            return_status = "triggered"  # Assume success after successful trigger
            logging.info(f"üìä PEOPLE & OPS INDEXER: Status checking disabled to avoid 404 errors")
            logging.info(f"üìä Job ID {job_id} is assumed to be processing successfully")
            logging.info(f"üìä Expected completion: 2-5 minutes for full indexing")
            
            return {
                "success": True,
                "job_id": job_id,
                "message": message,
                "status": return_status,
                "stored_in_db": True,
                "report_id": report_id,
                "container_name": container_name,
                "trigger_time": trigger_time,
                "storage_time": store_time,
                "total_time": total_monitor_time,
                "status_check_note": "Status checking disabled - indexer endpoints not available",
                "expected_completion": "2-5 minutes"
            }
        else:
            logging.error(f"‚ùå PEOPLE & OPS INDEXER: Triggered but database storage failed")
            logging.error(f"üìä Storage failure details:")
            logging.error(f"   - Trigger successful: {success}")
            logging.error(f"   - Job ID received: {job_id}")
            logging.error(f"   - Database storage: FAILED")
            logging.error(f"   - Impact: Indexer running but not tracked in database")
            
            return {
                "success": False,
                "error": "Triggered but database storage failed",
                "job_id": job_id,
                "message": message,
                "trigger_successful": True,
                "storage_failed": True
            }
    else:
        # Step 2: Store failed trigger in database
        logging.error(f"‚ùå PEOPLE & OPS INDEXER: Trigger failed, storing failure")
        
        store_people_ops_indexer_job_metadata(
            report_id=report_id,
            user_id=user_id,
            indexer_job_id=job_id or "failed",
            indexer_status="failed",
            error_message=message
        )
        
        total_monitor_time = time.time() - monitor_start_time
        
        logging.error(f"üí• PEOPLE & OPS INDEXER: TRIGGER PROCESS FAILED")
        logging.error(f"üìä Failure summary:")
        logging.error(f"   - Report ID: {report_id}")
        logging.error(f"   - User ID: {user_id}")
        logging.error(f"   - Container: {container_name}")
        logging.error(f"   - Error: {message}")
        logging.error(f"   - Job ID: {job_id if job_id else 'None'}")
        logging.error(f"   - Total time: {total_monitor_time:.3f}s")
        logging.error(f"   - Trigger time: {trigger_time:.3f}s")
        
        return {
            "success": False,
            "error": message,
            "job_id": job_id,
            "status": "failed",
            "stored_in_db": True,
            "report_id": report_id,
            "trigger_time": trigger_time,
            "total_time": total_monitor_time
        }

# Synchronous wrapper for background tasks
def trigger_people_ops_indexer_sync(report_id: str, user_id: str, container_name: str) -> Dict:
    """Synchronous wrapper for people & ops indexer trigger (for background tasks)"""
    
    sync_start_time = time.time()
    thread_id = threading.current_thread().ident
    
    logging.info(f"üîÑ PEOPLE & OPS INDEXER SYNC: Starting wrapper")
    logging.info(f"üìä Sync wrapper parameters:")
    logging.info(f"   - Report ID: {report_id}")
    logging.info(f"   - User ID: {user_id}")
    logging.info(f"   - Container: {container_name}")
    logging.info(f"   - Thread ID: {thread_id}")
    logging.info(f"   - Platform: {platform.system()}")
    
    try:
        # Handle Windows event loop policy
        if platform.system() == 'Windows':
            logging.debug(f"ü™ü PEOPLE & OPS INDEXER: Setting Windows event loop policy")
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        
        # Create new event loop for this thread
        logging.debug(f"üîÑ PEOPLE & OPS INDEXER: Creating new event loop")
        loop_creation_start = time.time()
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        loop_creation_time = time.time() - loop_creation_start
        logging.debug(f"‚úÖ PEOPLE & OPS INDEXER: Event loop created in {loop_creation_time:.3f}s")
        
        try:
            # Execute the async indexer function
            logging.info(f"‚öôÔ∏è PEOPLE & OPS INDEXER: Executing async trigger function")
            execution_start_time = time.time()
            
            result = loop.run_until_complete(
                trigger_and_monitor_people_ops_indexer(report_id, user_id, container_name)
            )
            
            execution_time = time.time() - execution_start_time
            total_sync_time = time.time() - sync_start_time
            
            logging.info(f"‚úÖ PEOPLE & OPS INDEXER SYNC: Execution completed")
            logging.info(f"üìä Sync execution metrics:")
            logging.info(f"   - Execution time: {execution_time:.3f}s")
            logging.info(f"   - Total sync time: {total_sync_time:.3f}s")
            logging.info(f"   - Loop creation time: {loop_creation_time:.3f}s")
            logging.info(f"   - Result success: {result.get('success', False)}")
            logging.info(f"   - Result job_id: {result.get('job_id', 'None')}")
            
            logging.info(f"üéØ People & ops indexer sync wrapper completed for report_id={report_id}")
            return result
            
        finally:
            # Clean up event loop
            logging.debug(f"üîÑ PEOPLE & OPS INDEXER: Cleaning up event loop")
            loop_cleanup_start = time.time()
            
            try:
                # Cancel any pending tasks
                pending_tasks = [task for task in asyncio.all_tasks(loop) if not task.done()]
                if pending_tasks:
                    logging.debug(f"üîß PEOPLE & OPS INDEXER: Cancelling {len(pending_tasks)} pending tasks")
                    for task in pending_tasks:
                        task.cancel()
                
                loop.close()
                loop_cleanup_time = time.time() - loop_cleanup_start
                logging.debug(f"‚úÖ PEOPLE & OPS INDEXER: Event loop cleaned up in {loop_cleanup_time:.3f}s")
                
            except Exception as cleanup_error:
                loop_cleanup_time = time.time() - loop_cleanup_start
                logging.warning(f"‚ö†Ô∏è PEOPLE & OPS INDEXER: Loop cleanup error after {loop_cleanup_time:.3f}s: {cleanup_error}")
            
    except Exception as e:
        total_sync_time = time.time() - sync_start_time
        error_msg = f"People & ops indexer sync wrapper error: {str(e)}"
        
        logging.error(f"üí• PEOPLE & OPS INDEXER SYNC: WRAPPER ERROR")
        logging.error(f"üìä Wrapper error details:")
        logging.error(f"   - Error type: {type(e).__name__}")
        logging.error(f"   - Error message: {str(e)}")
        logging.error(f"   - Total sync time: {total_sync_time:.3f}s")
        logging.error(f"   - Thread ID: {thread_id}")
        logging.error(f"   - Platform: {platform.system()}")
        
        # Log full traceback for sync wrapper errors
        import traceback
        logging.error(f"üîç PEOPLE & OPS INDEXER SYNC: Error traceback:")
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                logging.error(f"   {line}")
        
        # Still try to store the error in database
        try:
            logging.info(f"üíæ PEOPLE & OPS INDEXER: Attempting to store sync error in database")
            store_people_ops_indexer_job_metadata(
                report_id=report_id,
                user_id=user_id,
                indexer_job_id="sync_error",
                indexer_status="error",
                error_message=error_msg
            )
            logging.info(f"‚úÖ PEOPLE & OPS INDEXER: Sync error stored in database")
        except Exception as store_error:
            logging.error(f"‚ùå PEOPLE & OPS INDEXER: Failed to store sync error: {store_error}")
        
        return {
            "success": False,
            "error": error_msg,
            "status": "sync_error",
            "report_id": report_id,
            "total_sync_time": total_sync_time,
            "thread_id": thread_id
        }

# Background task integration
def trigger_people_ops_indexer_background(report_id: str, user_id: str, container_name: str):
    """Background thread function for people & ops indexer triggering with comprehensive logging"""
    
    def indexer_worker():
        worker_start_time = time.time()
        thread_id = threading.current_thread().ident
        thread_name = f"PeopleOpsIndexer-{user_id}-{int(time.time())}"
        
        # Set thread name for better debugging
        threading.current_thread().name = thread_name
        
        logging.info(f"üîÑ PEOPLE & OPS INDEXER WORKER: Starting background worker")
        logging.info(f"üìä Worker details:")
        logging.info(f"   - Thread ID: {thread_id}")
        logging.info(f"   - Thread name: {thread_name}")
        logging.info(f"   - Report ID: {report_id}")
        logging.info(f"   - User ID: {user_id}")
        logging.info(f"   - Container: {container_name}")
        logging.info(f"   - Worker start time: {datetime.fromtimestamp(worker_start_time).isoformat()}")
        
        try:
            logging.info(f"‚öôÔ∏è PEOPLE & OPS INDEXER WORKER: Calling sync wrapper")
            
            result = trigger_people_ops_indexer_sync(report_id, user_id, container_name)
            
            worker_time = time.time() - worker_start_time
            
            if result["success"]:
                logging.info(f"üéâ PEOPLE & OPS INDEXER WORKER: BACKGROUND SUCCESS!")
                logging.info(f"üìä Success details:")
                logging.info(f"   - Job ID: {result.get('job_id')}")
                logging.info(f"   - Status: {result.get('status')}")
                logging.info(f"   - Message: {result.get('message')}")
                logging.info(f"   - Worker time: {worker_time:.3f}s")
                logging.info(f"   - Trigger time: {result.get('trigger_time', 0):.3f}s")
                logging.info(f"   - Storage time: {result.get('storage_time', 0):.3f}s")
                logging.info(f"   - Thread: {thread_name}")
                
                # Log success to make it easy to find in logs
                logging.info(f"üéØ INDEXER SUCCESS: People & ops report {report_id} indexer job {result.get('job_id')} triggered successfully")
                
            else:
                logging.error(f"‚ùå PEOPLE & OPS INDEXER WORKER: BACKGROUND FAILURE")
                logging.error(f"üìä Failure details:")
                logging.error(f"   - Error: {result.get('error')}")
                logging.error(f"   - Status: {result.get('status')}")
                logging.error(f"   - Job ID: {result.get('job_id', 'None')}")
                logging.error(f"   - Worker time: {worker_time:.3f}s")
                logging.error(f"   - Thread: {thread_name}")
                
                # Log failure to make it easy to find in logs
                logging.error(f"üí• INDEXER FAILURE: People & ops report {report_id} indexer failed - {result.get('error')}")
                
        except Exception as e:
            worker_time = time.time() - worker_start_time
            
            logging.error(f"üí• PEOPLE & OPS INDEXER WORKER: CRITICAL ERROR")
            logging.error(f"üìä Critical error details:")
            logging.error(f"   - Error type: {type(e).__name__}")
            logging.error(f"   - Error message: {str(e)}")
            logging.error(f"   - Worker time: {worker_time:.3f}s")
            logging.error(f"   - Thread ID: {thread_id}")
            logging.error(f"   - Thread name: {thread_name}")
            logging.error(f"   - Report ID: {report_id}")
            logging.error(f"   - User ID: {user_id}")
            
            # Log full traceback for worker errors
            import traceback
            logging.error(f"üîç PEOPLE & OPS INDEXER WORKER: Error traceback:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    logging.error(f"   {line}")
            
            # Try to store the worker error
            try:
                store_people_ops_indexer_job_metadata(
                    report_id=report_id,
                    user_id=user_id,
                    indexer_job_id="worker_error",
                    indexer_status="worker_error",
                    error_message=f"Background worker error: {str(e)}"
                )
                logging.info(f"‚úÖ PEOPLE & OPS INDEXER: Worker error stored in database")
            except Exception as store_error:
                logging.error(f"‚ùå PEOPLE & OPS INDEXER: Failed to store worker error: {store_error}")
        
        finally:
            final_worker_time = time.time() - worker_start_time
            
            logging.info(f"üèÅ PEOPLE & OPS INDEXER WORKER: Background worker completed")
            logging.info(f"üìä Final worker metrics:")
            logging.info(f"   - Total worker time: {final_worker_time:.3f}s")
            logging.info(f"   - Thread ID: {thread_id}")
            logging.info(f"   - Thread name: {thread_name}")
            logging.info(f"   - Worker end time: {datetime.now().isoformat()}")
    
    # üî• ENHANCED: Better thread creation with comprehensive logging
    try:
        logging.info(f"üöÄ PEOPLE & OPS INDEXER: Launching background thread")
        
        # Create thread with proper naming and error handling
        thread_creation_start = time.time()
        
        indexer_thread = Thread(
            target=indexer_worker, 
            daemon=True,
            name=f"PeopleOpsIndexer-{user_id}-{report_id[-8:]}"  # Last 8 chars of report_id
        )
        
        # Store metadata in thread for debugging
        indexer_thread._indexer_data = {
            'report_id': report_id,
            'user_id': user_id,
            'container_name': container_name,
            'created_at': time.time(),
            'created_datetime': datetime.now().isoformat()
        }
        
        indexer_thread.start()
        thread_creation_time = time.time() - thread_creation_start
        
        logging.info(f"‚úÖ PEOPLE & OPS INDEXER: Background thread launched successfully")
        logging.info(f"üìä Thread launch details:")
        logging.info(f"   - Thread name: {indexer_thread.name}")
        logging.info(f"   - Thread ID: {indexer_thread.ident}")
        logging.info(f"   - Launch time: {thread_creation_time:.3f}s")
        logging.info(f"   - Daemon thread: {indexer_thread.daemon}")
        logging.info(f"   - Thread alive: {indexer_thread.is_alive()}")
        logging.info(f"   - Report ID: {report_id}")
        logging.info(f"   - Background processing: ACTIVE")
        
        # Enhanced thread monitoring for debugging
        if logging.getLogger().isEnabledFor(logging.DEBUG):
            def monitor_thread():
                time.sleep(1)  # Give thread time to start
                if indexer_thread.is_alive():
                    logging.debug(f"‚úÖ PEOPLE & OPS INDEXER: Thread {indexer_thread.name} is running successfully")
                else:
                    logging.warning(f"‚ö†Ô∏è PEOPLE & OPS INDEXER: Thread {indexer_thread.name} finished quickly (this may be normal)")
            
            Thread(target=monitor_thread, daemon=True, name=f"IndexerMonitor-{user_id}").start()
        
        return indexer_thread
        
    except Exception as thread_error:
        thread_creation_time = time.time() - thread_creation_start if 'thread_creation_start' in locals() else 0
        
        logging.error(f"üí• PEOPLE & OPS INDEXER: THREAD CREATION FAILED")
        logging.error(f"üìä Thread creation error details:")
        logging.error(f"   - Error type: {type(thread_error).__name__}")
        logging.error(f"   - Error message: {str(thread_error)}")
        logging.error(f"   - Creation time: {thread_creation_time:.3f}s")
        logging.error(f"   - Report ID: {report_id}")
        logging.error(f"   - User ID: {user_id}")
        logging.error(f"   - Container: {container_name}")
        
        # Log full traceback for thread creation errors
        import traceback
        logging.error(f"üîç PEOPLE & OPS INDEXER: Thread creation traceback:")
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                logging.error(f"   {line}")
        
        # Try to store thread creation error
        try:
            store_people_ops_indexer_job_metadata(
                report_id=report_id,
                user_id=user_id,
                indexer_job_id="thread_error",
                indexer_status="thread_error",
                error_message=f"Thread creation error: {str(thread_error)}"
            )
            logging.info(f"‚úÖ PEOPLE & OPS INDEXER: Thread creation error stored in database")
        except Exception as store_error:
            logging.error(f"‚ùå PEOPLE & OPS INDEXER: Failed to store thread error: {store_error}")
            return None  # Return None for failed thread creation
# ======================================================
#           API Endpoints
# ======================================================

app = FastAPI(title="People & Operations Engine API", version="2.1")

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models
class PeopleOpsAssessmentRequest(BaseModel):
    user_id: str
    business_name: str
    assessment_data: Dict[str, Any]

class PeopleOpsProgressRequest(BaseModel):
    user_id: str
    business_name: str
    assessment_data: Dict[str, Any]
    current_chapter: int
    auto_save: bool = False

# Application lifespan
# Replace the existing lifespan function with this fixed version
@asynccontextmanager
async def lifespan(app: FastAPI):
    global _connection_pools  # Keep only ONE global declaration at the top
    
    # Startup
    logger = setup_people_ops_logging()
    logging.info("üöÄ People & Operations Engine API Starting Up")
    logging.info("üîë Loaded API keys: " + ", ".join([f"PeopleOps_{i+1:02d}" for i in range(len(GEMINI_API_KEYS))]))
    logging.info("üìä Multi-Database Intelligence: ENABLED")
    logging.info("üß† Behavioral Analytics: ENABLED")
    logging.info("üìÑ Word Document Chunking: ENABLED")
    logging.info("üß† Question-Response Chunking: ENABLED")
    logging.info("üîç Auto-Indexer Integration: ENABLED")
    
    # FIX 1: Clean up any existing connection pools on startup
    try:
        if _connection_pools:
            logging.info(f"üßπ Cleaning up {len(_connection_pools)} existing connection pools...")
            for pool_name, pool in list(_connection_pools.items()):
                try:
                    if not pool.is_closing():
                        await pool.close()
                        await asyncio.sleep(0.1)  # Wait for cleanup
                    logging.info(f"‚úÖ Cleaned startup pool: {pool_name}")
                except Exception as cleanup_error:
                    logging.warning(f"‚ö†Ô∏è Error cleaning startup pool {pool_name}: {cleanup_error}")
            
            _connection_pools.clear()
            logging.info("‚úÖ Startup pool cleanup completed")
    except Exception as startup_cleanup_error:
        logging.warning(f"‚ö†Ô∏è Startup pool cleanup error: {startup_cleanup_error}")
    
    # FIX 2: Enhanced database table initialization with better error handling
    try:
        logging.info("üîß Initializing database tables on startup...")
        
        # FIX 3: Use a simple synchronous approach for table creation
        try:
            conn = get_people_ops_connection()
            
            # Test connection first
            with conn.cursor() as test_cur:
                test_cur.execute("SELECT 1")
                logging.info("‚úÖ Database connection test passed")
            
            # Create tables
            create_people_ops_tables(conn)
            
            # Verify tables exist
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'public' 
                    AND table_name IN ('people_ops_assessments', 'people_ops_responses', 'people_ops_behavioral_analytics', 'people_ops_reports')
                """)
                existing_tables = [row[0] for row in cur.fetchall()]
                
                logging.info(f"‚úÖ Verified tables exist: {existing_tables}")
                
                if len(existing_tables) >= 4:
                    logging.info("‚úÖ Database tables initialization complete - All People & Operations tables ready")
                else:
                    missing_tables = ['people_ops_assessments', 'people_ops_responses', 'people_ops_behavioral_analytics', 'people_ops_reports']
                    missing = [t for t in missing_tables if t not in existing_tables]
                    logging.error(f"‚ùå Missing tables: {missing}")
                    raise Exception(f"Missing required tables: {missing}")
            
            conn.close()
            
        except Exception as table_error:
            logging.error(f"‚ùå Table initialization failed: {str(table_error)}")
            
            # FIX 4: Emergency table creation with detailed error handling
            try:
                logging.info("üö® EMERGENCY: Attempting direct table creation...")
                emergency_conn = get_people_ops_connection()
                
                with emergency_conn.cursor() as cur:
                    # Create tables with explicit error handling for each table
                    tables_to_create = [
                        ("people_ops_assessments", """
                            CREATE TABLE IF NOT EXISTS people_ops_assessments (
                                id SERIAL PRIMARY KEY,
                                user_id VARCHAR(255) UNIQUE NOT NULL,
                                assessment_type VARCHAR(100) NOT NULL,
                                version VARCHAR(20) NOT NULL,
                                created_at TIMESTAMPTZ,
                                last_updated TIMESTAMPTZ,
                                timezone VARCHAR(100),
                                session_metadata JSONB,
                                device_fingerprint JSONB,
                                progress_tracking JSONB,
                                completion_flags JSONB,
                                raw_data JSONB,
                                multi_database_intelligence JSONB,
                                created_timestamp TIMESTAMPTZ DEFAULT NOW()
                            )
                        """),
                        ("people_ops_responses", """
                            CREATE TABLE IF NOT EXISTS people_ops_responses (
                                id SERIAL PRIMARY KEY,
                                assessment_id INTEGER REFERENCES people_ops_assessments(id),
                                user_id VARCHAR(255) NOT NULL,
                                question_id VARCHAR(50) NOT NULL,
                                section VARCHAR(100) NOT NULL,
                                question_type VARCHAR(50),
                                question_text TEXT,
                                response_format VARCHAR(50),
                                response_data JSONB,
                                all_options JSONB,
                                metadata JSONB,
                                weight VARCHAR(20),
                                answered_at TIMESTAMPTZ,
                                last_modified_at TIMESTAMPTZ,
                                created_timestamp TIMESTAMPTZ DEFAULT NOW(),
                                UNIQUE(assessment_id, question_id)
                            )
                        """),
                        ("people_ops_behavioral_analytics", """
                            CREATE TABLE IF NOT EXISTS people_ops_behavioral_analytics (
                                id SERIAL PRIMARY KEY,
                                assessment_id INTEGER REFERENCES people_ops_assessments(id) UNIQUE,
                                user_id VARCHAR(255) NOT NULL,
                                mouse_behavior JSONB,
                                keyboard_behavior JSONB,
                                attention_patterns JSONB,
                                decision_making_style JSONB,
                                leadership_decision_patterns JSONB,
                                created_at TIMESTAMPTZ,
                                created_timestamp TIMESTAMPTZ DEFAULT NOW()
                            )
                        """),
                        ("people_ops_reports", """
                            CREATE TABLE IF NOT EXISTS people_ops_reports (
                                id SERIAL PRIMARY KEY,
                                report_id VARCHAR(255) UNIQUE NOT NULL,
                                user_id VARCHAR(255) NOT NULL,
                                assessment_id INTEGER REFERENCES people_ops_assessments(id),
                                report_type VARCHAR(100) NOT NULL,
                                status VARCHAR(50) NOT NULL,
                                azure_container VARCHAR(255),
                                blob_paths JSONB,
                                chunk_count INTEGER,
                                generation_metadata JSONB,
                                created_at TIMESTAMPTZ DEFAULT NOW(),
                                completed_at TIMESTAMPTZ,
                                indexer_job_id VARCHAR(255),
                                indexer_status VARCHAR(50),
                                indexer_triggered_at TIMESTAMPTZ,
                                indexer_completed_at TIMESTAMPTZ,
                                indexer_error_message TEXT,
                                indexer_retry_count INTEGER DEFAULT 0,
                                multi_database_integration JSONB
                            )
                        """)
                    ]
                    
                    # Create each table individually with error handling
                    for table_name, create_sql in tables_to_create:
                        try:
                            cur.execute(create_sql)
                            logging.info(f"‚úÖ Emergency created table: {table_name}")
                        except Exception as table_create_error:
                            logging.error(f"‚ùå Failed to create table {table_name}: {table_create_error}")
                    
                    # Create indexes with individual error handling
                    indexes = [
                        ("idx_people_ops_assessments_user_id", "CREATE INDEX IF NOT EXISTS idx_people_ops_assessments_user_id ON people_ops_assessments(user_id)"),
                        ("idx_people_ops_responses_user_id", "CREATE INDEX IF NOT EXISTS idx_people_ops_responses_user_id ON people_ops_responses(user_id)"),
                        ("idx_people_ops_responses_section", "CREATE INDEX IF NOT EXISTS idx_people_ops_responses_section ON people_ops_responses(section)"),
                        ("idx_people_ops_reports_user_id", "CREATE INDEX IF NOT EXISTS idx_people_ops_reports_user_id ON people_ops_reports(user_id)"),
                        ("idx_people_ops_reports_report_id", "CREATE INDEX IF NOT EXISTS idx_people_ops_reports_report_id ON people_ops_reports(report_id)"),
                        ("idx_people_ops_reports_indexer_job_id", "CREATE INDEX IF NOT EXISTS idx_people_ops_reports_indexer_job_id ON people_ops_reports(indexer_job_id)"),
                        ("idx_people_ops_reports_indexer_status", "CREATE INDEX IF NOT EXISTS idx_people_ops_reports_indexer_status ON people_ops_reports(indexer_status)")
                    ]
                    
                    for index_name, index_sql in indexes:
                        try:
                            cur.execute(index_sql)
                            logging.debug(f"‚úÖ Created index: {index_name}")
                        except Exception as index_error:
                            logging.warning(f"‚ö†Ô∏è Failed to create index {index_name}: {index_error}")
                    
                    # Final verification
                    cur.execute("""
                        SELECT table_name 
                        FROM information_schema.tables 
                        WHERE table_schema = 'public' 
                        AND table_name IN ('people_ops_assessments', 'people_ops_responses', 'people_ops_behavioral_analytics', 'people_ops_reports')
                    """)
                    final_tables = [row[0] for row in cur.fetchall()]
                    
                    logging.info(f"‚úÖ EMERGENCY VERIFICATION: {len(final_tables)} tables confirmed: {final_tables}")
                    
                    if len(final_tables) >= 4:
                        logging.info("‚úÖ EMERGENCY TABLE CREATION SUCCESS - All required tables available")
                    else:
                        logging.error(f"‚ùå EMERGENCY TABLE CREATION PARTIAL: Only {len(final_tables)}/4 tables created")
                        
                emergency_conn.close()
                
            except Exception as emergency_error:
                logging.error(f"‚ùå EMERGENCY table creation failed: {str(emergency_error)}")
                logging.error("üö® CRITICAL: Database tables unavailable - API functionality severely limited")
                if 'emergency_conn' in locals():
                    try:
                        emergency_conn.close()
                    except:
                        pass
            
    except Exception as startup_error:
        logging.error(f"‚ùå Critical startup error: {str(startup_error)}")
        import traceback
        logging.error(f"üîç Full startup traceback: {traceback.format_exc()}")
    
    # FIX 5: Add startup success confirmation
    logging.info("‚úÖ People & Operations Engine startup sequence completed")
    logging.info(f"üîë API Key Health: {get_api_key_status_summary() if 'get_api_key_status_summary' in globals() else 'Not initialized'}")
    
    yield
    
    # Shutdown with enhanced pool cleanup
    logging.info("‚¨áÔ∏è People & Operations Engine API Shutting Down")
    
    # REMOVED: The duplicate global _connection_pools declaration that was here
    # The global declaration at the top of the function is sufficient
    
    # FIX 6: Enhanced connection pool cleanup with timeout and error handling
    try:
        if _connection_pools:
            logging.info(f"üîå Gracefully closing {len(_connection_pools)} connection pools...")
            
            # Create list to avoid modification during iteration
            pools_to_close = list(_connection_pools.items())
            successful_closures = 0
            failed_closures = 0
            
            for pool_name, pool in pools_to_close:
                pool_close_start = time.time()
                try:
                    # FIX 7: Check if pool is already closing
                    if pool.is_closing():
                        logging.info(f"‚ÑπÔ∏è Pool {pool_name} already closing, skipping")
                        continue
                    
                    # FIX 8: Close with timeout
                    await asyncio.wait_for(pool.close(), timeout=5.0)
                    
                    # FIX 9: Wait for closure to complete
                    while not pool.is_closing():
                        await asyncio.sleep(0.1)
                        if time.time() - pool_close_start > 5.0:
                            logging.warning(f"‚è∞ Pool {pool_name} closure timeout")
                            break
                    
                    pool_close_time = time.time() - pool_close_start
                    logging.info(f"‚úÖ Closed connection pool: {pool_name} ({pool_close_time:.2f}s)")
                    successful_closures += 1
                    
                except asyncio.TimeoutError:
                    pool_close_time = time.time() - pool_close_start
                    logging.error(f"‚è∞ Pool {pool_name} close timeout after {pool_close_time:.2f}s")
                    failed_closures += 1
                except Exception as pool_error:
                    pool_close_time = time.time() - pool_close_start
                    logging.error(f"‚ùå Error closing pool {pool_name} after {pool_close_time:.2f}s: {pool_error}")
                    failed_closures += 1
                finally:
                    # FIX 10: Always remove from dictionary
                    _connection_pools.pop(pool_name, None)
            
            # FIX 11: Clear the dictionary regardless
            _connection_pools.clear()
            
            logging.info(f"üîå Pool cleanup summary: {successful_closures} successful, {failed_closures} failed")
            
            if successful_closures > 0:
                logging.info("‚úÖ Connection pools closed successfully")
            if failed_closures > 0:
                logging.warning(f"‚ö†Ô∏è {failed_closures} pools failed to close properly")
                
        else:
            logging.info("‚ÑπÔ∏è No connection pools to close")
            
    except Exception as shutdown_error:
        logging.error(f"‚ùå Error during graceful shutdown: {shutdown_error}")
        
        # FIX 12: Force cleanup on error
        try:
            logging.info("üö® FORCE CLEANUP: Attempting to clear connection pools...")
            _connection_pools.clear()
            logging.info("‚úÖ Force cleanup completed")
        except Exception as force_error:
            logging.error(f"‚ùå Force cleanup failed: {force_error}")
    
    # FIX 13: Final cleanup verification
    try:
        remaining_pools = len(_connection_pools)
        if remaining_pools > 0:
            logging.warning(f"‚ö†Ô∏è {remaining_pools} connection pools still in memory after cleanup")
            _connection_pools.clear()
        else:
            logging.info("‚úÖ All connection pools successfully cleaned up")
    except Exception as final_check_error:
        logging.error(f"‚ùå Final cleanup verification error: {final_check_error}")
    
    logging.info("üèÅ People & Operations Engine shutdown complete")

app.router.lifespan_context = lifespan

# ======================================================
#           JWT Authentication Configuration
# ======================================================

# JWT Secret Key - must match the key used by philotimo-backend
JWT_SECRET = os.getenv("JWT_SECRET", "philotimo-global-jwt-secret-2024!!")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")

# Philotimo database configuration for token validation
PHILOTIMO_DB_CONFIG = {
    "host": "philotimo-staging-db.postgres.database.azure.com",
    "database": "philotimodb",
    "user": "wchen",
    "password": "DevPhilot2024!!",
    "port": 5432,
    "sslmode": "require"
}

def hash_token(token: str) -> str:
    """Hash a JWT token using SHA256 for database comparison"""
    return hashlib.sha256(token.encode()).hexdigest()

async def verify_jwt_token(authorization: str = Header(None)) -> Dict:
    """
    Verify JWT token from Authorization header and validate against database

    Returns:
        Dict containing: user_id, client_id, email, jti

    Raises:
        HTTPException: If token is invalid, expired, or revoked
    """
    if not authorization:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Missing authorization header",
            headers={"WWW-Authenticate": "Bearer"}
        )

    # Extract token from "Bearer <token>" format
    parts = authorization.split()
    if len(parts) != 2 or parts[0].lower() != "bearer":
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authorization header format. Expected 'Bearer <token>'",
            headers={"WWW-Authenticate": "Bearer"}
        )

    token = parts[1]

    try:
        # Decode JWT token
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])

        # Extract claims
        user_id = payload.get("sub")
        email = payload.get("email")
        jti = payload.get("jti")

        if not user_id or not jti:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid token payload: missing required claims"
            )

        # Hash the token for database lookup
        token_hash = hash_token(token)

        # Validate token against database
        conn = None
        try:
            conn = psycopg2.connect(**PHILOTIMO_DB_CONFIG)
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                # Join api_tokens with users to get client_id
                cur.execute("""
                    SELECT
                        t.user_id,
                        t.is_revoked AS revoked,
                        t.expires_at,
                        u.client_id,
                        u.email
                    FROM api_tokens t
                    JOIN users u ON t.user_id = u.id
                    WHERE t.jti = %s AND t.token_hash = %s
                """, (jti, token_hash))

                token_record = cur.fetchone()

                if not token_record:
                    raise HTTPException(
                        status_code=status.HTTP_401_UNAUTHORIZED,
                        detail="Token not found in database"
                    )

                # Check if token is revoked
                if token_record["revoked"]:
                    raise HTTPException(
                        status_code=status.HTTP_401_UNAUTHORIZED,
                        detail="Token has been revoked"
                    )

                # Check if token is expired (database-level check)
                if token_record['expires_at'] and token_record['expires_at'] < datetime.now(token_record['expires_at'].tzinfo):
                    raise HTTPException(
                        status_code=status.HTTP_401_UNAUTHORIZED,
                        detail="Token has expired"
                    )

                # Return authenticated user info
                return {
                    "user_id": int(token_record["user_id"]),
                    "client_id": token_record.get("client_id"),
                    "email": token_record.get("email"),
                    "jti": jti
                }

        finally:
            if conn:
                conn.close()

    except jwt.ExpiredSignatureError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Token has expired"
        )
    except jwt.InvalidTokenError as e:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail=f"Invalid token: {str(e)}"
        )
    except Exception as e:
        import traceback
        logging.error(f"Token validation error: {e}")
        logging.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error validating token: {str(e)}"
        )

# ======================================================
#                   API Endpoints
# ======================================================

@app.get("/auth/me")
async def get_authenticated_user(auth: Dict = Depends(verify_jwt_token)):
    """
    Get authenticated user information from JWT token
    This endpoint allows the frontend to verify authentication and get user_id
    """
    return {
        "status": "success",
        "user_id": str(auth["user_id"]),
        "client_id": auth.get("client_id"),
        "email": auth.get("email"),
        "authenticated": True
    }

@app.get("/")
async def root():
    return {
        "message": "People & Operations Engine API v2.1",
        "status": "operational",
        "features": {
            "multi_database_intelligence": True,
            "enhanced_api_key_management": True,
            "load_balancing": True,
            "gemini_ai_analysis": True,
            "behavioral_analytics": True,
            "word_document_chunking": True,
            "question_response_chunking": True,
            "auto_indexer_integration": True,
            "complete_qa_extraction": True
        },
        "api_keys_status": get_enhanced_api_key_status()
    }

@app.get("/api-key-health")
async def get_api_key_health():
    """Get detailed API key health information"""
    return {
        "timestamp": datetime.now().isoformat(),
        "summary": get_api_key_status_summary(),
        "detailed_status": get_enhanced_api_key_status()
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "2.1",
        "api_keys_status": get_api_key_status_summary()
    }

@app.post("/people-operations-audit/{user_id}")
async def process_people_ops_audit(user_id: str, request: PeopleOpsAssessmentRequest, auth: Dict = Depends(verify_jwt_token)):
    """Process comprehensive people & operations audit with multi-database intelligence and indexer integration - ENHANCED"""

    # Permission check: user can only access their own data
    if int(user_id) != auth["user_id"]:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="You can only access your own audit data"
        )

    start_time = time.time()
    logging.info(f"üöÄ Starting People & Operations Audit for user_id={user_id}")
    
    # Generate unique report ID
    report_id = f"people_ops_report_{user_id}_{int(datetime.now().timestamp())}"
    
    # Initialize job status
    people_ops_job_status[report_id] = {
        "status": "processing",
        "message": "Starting people & operations analysis...",
        "progress": 0,
        "sections_completed": 0,
        "started_at": datetime.now().isoformat(),
        "user_id": user_id,
        "business_name": request.business_name
    }
    
    try:
        # Get user profile data with connection pooling
        logging.info(f"üë§ Retrieving user profile for {user_id}")
        user_profile = await get_user_profile_data(user_id)
        
        if not user_profile:
            logging.warning(f"‚ö†Ô∏è No user profile found for {user_id}, using provided data")
            user_profile = {
                "username": user_id,
                "business_name": request.business_name,
                "industry": "Unknown Industry",
                "team_size": "Unknown",
                "biggest_challenge": "Organizational optimization"
            }
        
        # Initialize smart notification controller
        notification_controller = NotificationController(user_id, user_profile)
        
        #  NOTIFICATION 1: START - Personalized start message
        notification_controller.force_send_notification("start")
        
        # Store assessment data with multi-database intelligence
        logging.info(f"üíæ Storing people & ops assessment data...")
        assessment_id = store_people_ops_assessment(user_id, request.assessment_data, include_multi_db=True)
        
        # Get multi-database intelligence with connection pooling (ENHANCED)
        logging.info(f"üß† Extracting enhanced multi-database intelligence...")
        multi_db_intelligence = await get_multi_database_intelligence(user_id)
        
        # ‚úÖ ENHANCED: Add raw_assessment_data to complete_raw_data for Q&R chunking
        complete_raw_data = {
            "user_id": user_id,
            "report_id": report_id,
            "user_profile": user_profile,
            "responses": request.assessment_data.get("responses", []),
            "assessment_metadata": request.assessment_data.get("assessment_metadata", {}),
            "comprehensive_metadata": request.assessment_data.get("comprehensive_metadata", {}),
            "multi_database_intelligence": multi_db_intelligence,
            "behavioral_analytics": request.assessment_data.get("comprehensive_metadata", {}).get("behavioral_analytics", {}),
            "completion_flags": request.assessment_data.get("completion_flags", {}),
            "text_responses": request.assessment_data.get("text_responses", {}),
            "numeric_inputs": request.assessment_data.get("numeric_inputs", {}),
            "processing_timestamp": datetime.now().isoformat(),
            "raw_assessment_data": request.assessment_data  # ‚úÖ ENHANCED: For Q&R chunking
        }
        
        # Update job status
        people_ops_job_status[report_id]["message"] = "Generating comprehensive people and operations strategy..."
        people_ops_job_status[report_id]["progress"] = 20
        
        # üî• FIX 1: SAFER REPORT GENERATION - Use ThreadPoolExecutor directly
        logging.info(f"üß† Generating comprehensive people & operations report...")
        
        # FIXED: Use ThreadPoolExecutor directly instead of nested async wrapper
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(generate_comprehensive_people_ops_report, complete_raw_data, report_id)
            report_data = await asyncio.get_event_loop().run_in_executor(None, lambda: future.result())
        
        # ‚úÖ ENHANCED: Ensure raw assessment data is in report metadata for Q&R chunking
        if "_enhanced_people_ops_report_metadata" not in report_data:
            report_data["_enhanced_people_ops_report_metadata"] = {}
        
        report_data["_enhanced_people_ops_report_metadata"]["raw_assessment_data"] = request.assessment_data
        
        logging.info(f"‚úÖ Added raw assessment data to report metadata for Q&R chunking")
        
        # Update job status
        people_ops_job_status[report_id]["message"] = "Uploading people and operations strategy to secure storage..."
        people_ops_job_status[report_id]["progress"] = 80
        
        # Get Azure container name
        container_name = get_azure_container_name(user_id)
        
        # üî• FIX 2: ACTUAL AZURE UPLOAD - Use the real function instead of placeholder
        logging.info(f"‚òÅÔ∏è Uploading people & ops report to Azure...")
        upload_success, upload_message = await upload_people_ops_report_to_azure(report_data, report_id, user_id)
        
        if not upload_success:
            raise Exception(f"Azure upload failed: {upload_message}")
        
        # Send persistent completion notification (saved to database)
        try:
            business_name = user_profile.get('business_name', 'Your Business')
            await send_people_ops_notification(
                user_id=user_id,
                title="üéâ People & Operations Strategy Complete!",
                body=f"Your comprehensive people and operations strategy for {business_name} is ready!",
                data_type="ai_report_complete",
                save_to_db=True,
                report_id=report_id,
                business_name=business_name
            )
            logging.info(f"‚úÖ Persistent completion notification sent for user {user_id}")
        except Exception as notif_error:
            logging.warning(f"‚ö†Ô∏è Completion notification failed (non-critical): {str(notif_error)}")
        
        # Store report metadata
        generation_metadata = {
            "total_sections": len([k for k in report_data.keys() if k != "_enhanced_people_ops_report_metadata"]),
            "total_words": report_data.get("_enhanced_people_ops_report_metadata", {}).get("total_words", 0),
            "generation_time": time.time() - start_time,
            "ai_model": "gemini-2.5-pro",
            "multi_database_sources": len(complete_raw_data.get("multi_database_intelligence", {}).get("data_sources_available", [])),
            "data_sources_used": complete_raw_data.get("multi_database_intelligence", {}).get("data_sources_available", []),
            "intelligence_correlation": True,
            "total_intelligence_sources": len(complete_raw_data.get("multi_database_intelligence", {}).get("data_sources_available", [])),
            "complete_qa_pairs": complete_raw_data.get("multi_database_intelligence", {}).get("complete_qa_data", {}).get("token_tracking", {}).get("qa_pairs_count", 0),
            "upload_message": upload_message,
            "database_pooling_enabled": True
        }
        
        # Store report metadata in database
        logging.info(f"üíæ Storing people & ops report metadata...")
        store_people_ops_report_metadata(report_id, user_id, assessment_id, 
                                       report_data.get("_enhanced_people_ops_report_metadata", {}).get("total_sections", 0),
                                       container_name, generation_metadata)
        
        # üî• ENHANCED: TRIGGER INDEXER WITH COMPREHENSIVE LOGGING
        logging.info(f"üöÄ INDEXER PHASE: Starting people & ops indexer trigger process")
        logging.info(f"üìä Indexer trigger parameters:")
        logging.info(f"   - Report ID: {report_id}")
        logging.info(f"   - User ID: {user_id}")
        logging.info(f"   - Container: {container_name}")
        logging.info(f"   - Assessment ID: {assessment_id}")
        logging.info(f"   - Total files to index: 57 (from upload summary)")
        
        # Update job status for indexer phase
        # Indexing is now handled automatically by the unified infrastructure
        # No need to manually trigger indexer - it runs automatically on blob storage
        logging.info(f"‚úÖ Files uploaded to unified storage - automatic indexing will process them")

        # Final status update
        total_time = time.time() - start_time
        people_ops_job_status[report_id]["status"] = "completed"
        people_ops_job_status[report_id]["message"] = f"People & operations strategy complete! Generated in {total_time:.1f}s"
        people_ops_job_status[report_id]["progress"] = 100
        people_ops_job_status[report_id]["completed_at"] = datetime.now().isoformat()
        people_ops_job_status[report_id]["total_generation_time"] = total_time
        
        # üî• ENHANCED: Final comprehensive logging
        logging.info(f"üéâ PEOPLE & OPERATIONS AUDIT COMPLETED!")
        logging.info(f"üìä FINAL COMPLETION SUMMARY:")
        logging.info(f"   ‚úÖ Report ID: {report_id}")
        logging.info(f"   ‚úÖ User ID: {user_id}")
        logging.info(f"   ‚úÖ Business: {request.business_name}")
        logging.info(f"   ‚úÖ Total time: {total_time:.2f}s")
        logging.info(f"   ‚úÖ Assessment stored: ID {assessment_id}")
        logging.info(f"   ‚úÖ Azure upload: {upload_message}")
        logging.info(f"   ‚úÖ Container: {container_name}")
        logging.info(f"   ‚úÖ Total sections: {generation_metadata.get('total_sections', 0)}")
        logging.info(f"   ‚úÖ Total words: {generation_metadata.get('total_words', 0):,}")
        logging.info(f"   ‚úÖ Multi-DB sources: {generation_metadata.get('multi_database_sources', 0)}")
        logging.info(f"   ‚úÖ Complete Q&A pairs: {generation_metadata.get('complete_qa_pairs', 0)}")
        
        # Log indexer status
        indexer_info = generation_metadata.get("indexer_integration", {})
        if indexer_info.get("trigger_successful", False):
            logging.info(f"   ‚úÖ Indexer: TRIGGERED (background processing)")
            logging.info(f"   üìä Expected indexing completion: 2-5 minutes")
        else:
            logging.warning(f"   ‚ö†Ô∏è Indexer: FAILED - {indexer_info.get('trigger_error', 'Unknown error')}")
            logging.warning(f"   üìä Impact: Report available but search functionality limited")
        
        logging.info(f"‚úÖ People & Operations Audit completed for {user_id} in {total_time:.2f}s")
        
        return {
            "status": "processing",
            "report_id": report_id,
            "message": "People & operations strategy generation started",
            "estimated_completion": "2-3 minutes",
            "user_id": user_id,
            "business_name": request.business_name,
            "generation_metadata": generation_metadata,
            "indexer_info": {
                "indexer_triggered": indexer_info.get("trigger_successful", False),
                "indexer_message": "Background indexing started" if indexer_info.get("trigger_successful", False) else f"Indexer failed: {indexer_info.get('trigger_error', 'Unknown')}",
                "search_optimization": "In progress" if indexer_info.get("trigger_successful", False) else "Limited"
            }
        }
        
    except Exception as e:
        total_time = time.time() - start_time
        error_message = f"People & operations audit error: {str(e)}"
        
        logging.error(f"‚ùå PEOPLE & OPERATIONS AUDIT FAILED!")
        logging.error(f"üîç Failure details:")
        logging.error(f"   - Error type: {type(e).__name__}")
        logging.error(f"   - Error message: {str(e)}")
        logging.error(f"   - Total time before failure: {total_time:.2f}s")
        logging.error(f"   - User ID: {user_id}")
        logging.error(f"   - Business name: {request.business_name}")
        logging.error(f"   - Report ID: {report_id}")
        
        # Update job status with error
        people_ops_job_status[report_id]["status"] = "failed"
        people_ops_job_status[report_id]["message"] = error_message
        people_ops_job_status[report_id]["error"] = str(e)
        people_ops_job_status[report_id]["failed_at"] = datetime.now().isoformat()
        people_ops_job_status[report_id]["total_processing_time"] = total_time
        
        # Log full traceback for debugging
        import traceback
        logging.error(f"üîç FULL ERROR TRACEBACK:")
        for line_num, line in enumerate(traceback.format_exc().split('\n'), 1):
            if line.strip():
                logging.error(f"   {line_num:02d}: {line}")
        
        # Log context for debugging
        logging.error(f"üîç ERROR CONTEXT:")
        logging.error(f"   - Request data size: {len(str(request.assessment_data)) if request.assessment_data else 0} chars")
        logging.error(f"   - User profile available: {bool(user_profile) if 'user_profile' in locals() else False}")
        logging.error(f"   - Assessment ID created: {assessment_id if 'assessment_id' in locals() else 'Not created'}")
        logging.error(f"   - Multi-DB intelligence: {bool(multi_db_intelligence) if 'multi_db_intelligence' in locals() else False}")
        logging.error(f"   - Report data generated: {bool(report_data) if 'report_data' in locals() else False}")
        logging.error(f"   - Azure upload attempted: {bool(upload_success) if 'upload_success' in locals() else False}")
        
        raise HTTPException(status_code=500, detail=error_message)

@app.get("/people_ops_report_status/{report_id}")
async def get_people_ops_report_status(report_id: str, auth: Dict = Depends(verify_jwt_token)):
    """Get people & operations report generation status"""

    # No permission check - report_id doesn't directly contain user_id

    if report_id not in people_ops_job_status:
        # Try to get status from database
        conn = None
        try:
            conn = get_people_ops_connection()
            with conn.cursor() as cur:
                sql = """
                    SELECT status, generation_metadata, created_at, completed_at, 
                           indexer_status, indexer_job_id
                    FROM people_ops_reports 
                    WHERE report_id = %s
                """
                cur.execute(sql, (report_id,))
                row = cur.fetchone()
                
                if row:
                    status, metadata, created_at, completed_at, indexer_status, indexer_job_id = row
                    
                    return {
                        "status": status,
                        "report_id": report_id,
                        "message": f"Report {status}",
                        "created_at": created_at.isoformat() if created_at else None,
                        "completed_at": completed_at.isoformat() if completed_at else None,
                        "indexer_status": indexer_status,
                        "indexer_job_id": indexer_job_id,
                        "metadata": metadata
                    }
                else:
                    raise HTTPException(status_code=404, detail="People & operations report not found")
        finally:
            if conn:
                conn.close()
    
    return people_ops_job_status[report_id]

@app.post("/people_ops_assessment_progress")
async def save_people_ops_progress(request: PeopleOpsProgressRequest, auth: Dict = Depends(verify_jwt_token)):
    """Save people & operations assessment progress with enhanced tracking"""

    # Permission check: user can only save their own progress
    if int(request.user_id) != auth["user_id"]:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="You can only save your own progress"
        )

    try:
        logging.info(f"üíæ Saving people & ops progress for user {request.user_id}")
        logging.info(f"üìä Progress details: chapter {request.current_chapter}, auto_save: {request.auto_save}")
        
        # Build proper progress tracking data
        progress_tracking_data = {
            'completed_chapters': request.current_chapter,
            'total_chapters': 8,
            'percentage_complete': (request.current_chapter / 8) * 100,
            'last_saved_at': datetime.now().isoformat(),
            'auto_save': request.auto_save,
            'save_trigger': 'auto_save' if request.auto_save else 'manual_save',
            'chapters_completed': []
        }
        
        # Add completed chapters based on current chapter
        chapter_names = [
            "Chapter 1: The People Architecture",
            "Chapter 2: The Leadership Reality", 
            "Chapter 3: The Revenue Engine",
            "Chapter 4: The People Systems Reality",
            "Chapter 5: The Culture Engine",
            "Chapter 6: The Warning Signs",
            "Chapter 7: The Operational Foundations",
            "Chapter 8: The Operational Systems Reality"
        ]
        
        for i in range(min(request.current_chapter, len(chapter_names))):
            progress_tracking_data['chapters_completed'].append(chapter_names[i])
        
        logging.info(f"üìà Progress tracking: {progress_tracking_data['percentage_complete']:.1f}% complete")
        
        # Update assessment data with progress tracking
        enhanced_assessment_data = {
            **request.assessment_data,
            'progress_tracking': progress_tracking_data,
            'current_chapter': request.current_chapter,
            'last_updated': datetime.now().isoformat(),
            'save_metadata': {
                'save_timestamp': datetime.now().isoformat(),
                'save_type': 'auto_save' if request.auto_save else 'manual_save',
                'user_agent': 'people_ops_engine_frontend',
                'chapter_at_save': request.current_chapter
            }
        }
        
        # Count responses for logging
        response_count = 0
        if 'responses' in enhanced_assessment_data:
            if isinstance(enhanced_assessment_data['responses'], list):
                response_count = len(enhanced_assessment_data['responses'])
            elif isinstance(enhanced_assessment_data['responses'], dict):
                response_count = len(enhanced_assessment_data['responses'])
        
        logging.info(f"üìä Assessment data: {response_count} responses, chapter {request.current_chapter}")
        
        # Store progress data
        assessment_id = store_people_ops_assessment(request.user_id, enhanced_assessment_data)
        
        logging.info(f"‚úÖ People & ops progress saved successfully for user {request.user_id}")
        
        return {
            "status": "saved",
            "assessment_id": assessment_id,
            "user_id": request.user_id,
            "current_chapter": request.current_chapter,
            "auto_save": request.auto_save,
            "timestamp": datetime.now().isoformat(),
            "progress_percentage": progress_tracking_data['percentage_complete'],
            "chapters_completed": len(progress_tracking_data['chapters_completed']),
            "response_count": response_count,
            "save_metadata": {
                "save_type": "auto_save" if request.auto_save else "manual_save",
                "chapters_completed": progress_tracking_data['chapters_completed']
            }
        }
        
    except Exception as e:
        error_message = f"Error saving people & ops progress: {str(e)}"
        logging.error(f"‚ùå {error_message}")
        logging.error(f"üîç Save error context: user_id={request.user_id}, chapter={request.current_chapter}")
        import traceback
        logging.error(f"üîç Full traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=error_message)

@app.get("/people_ops_assessment_progress/{user_id}")
async def get_people_ops_progress(user_id: str, auth: Dict = Depends(verify_jwt_token)):
    """Get saved people & operations assessment progress for a user"""

    # Permission check: user can only access their own progress
    if int(user_id) != auth["user_id"]:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="You can only access your own progress"
        )
    
    conn = None
    try:
        logging.info(f"üì• Retrieving people & ops progress for user {user_id}")
        conn = get_people_ops_connection()
        with conn.cursor() as cur:
            # Get the most recent assessment for this user
            sql = """
                SELECT raw_data, progress_tracking, last_updated, created_at
                FROM people_ops_assessments 
                WHERE user_id = %s 
                ORDER BY last_updated DESC 
                LIMIT 1
            """
            
            cur.execute(sql, (user_id,))
            row = cur.fetchone()
            
            if row:
                raw_data, progress_tracking, last_updated, created_at = row
                
                logging.info(f"üîç Raw data type: {type(raw_data)}, Progress tracking type: {type(progress_tracking)}")
                
                # Handle both string and dict types for raw_data
                if isinstance(raw_data, str):
                    try:
                        assessment_data = json.loads(raw_data)
                        logging.info(f"‚úÖ Parsed raw_data from JSON string")
                    except json.JSONDecodeError as e:
                        logging.error(f"‚ùå Failed to parse raw_data JSON: {e}")
                        assessment_data = {}
                elif isinstance(raw_data, dict):
                    assessment_data = raw_data
                    logging.info(f"‚úÖ Used raw_data as dict (JSONB column)")
                else:
                    logging.warning(f"‚ö†Ô∏è Unexpected raw_data type: {type(raw_data)}")
                    assessment_data = {}
                
                # Handle both string and dict types for progress_tracking
                current_chapter = 1
                if progress_tracking:
                    if isinstance(progress_tracking, str):
                        try:
                            progress_data = json.loads(progress_tracking)
                            current_chapter = progress_data.get('completed_chapters', 1)
                            logging.info(f"‚úÖ Parsed progress_tracking from JSON string")
                        except json.JSONDecodeError as e:
                            logging.error(f"‚ùå Failed to parse progress_tracking JSON: {e}")
                            current_chapter = 1
                    elif isinstance(progress_tracking, dict):
                        current_chapter = progress_tracking.get('completed_chapters', 1)
                        logging.info(f"‚úÖ Used progress_tracking as dict")
                    else:
                        logging.warning(f"‚ö†Ô∏è Unexpected progress_tracking type: {type(progress_tracking)}")
                        current_chapter = 1
                
                logging.info(f"üìä Progress summary: {len(assessment_data.get('responses', []))} responses, chapter {current_chapter}")
                
                return {
                    "status": "found",
                    "user_id": user_id,
                    "assessment_data": assessment_data,
                    "current_chapter": current_chapter,
                    "created_at": created_at.isoformat() if created_at else None,
                    "updated_at": last_updated.isoformat() if last_updated else None
                }
            else:
                logging.info(f"‚ÑπÔ∏è No saved progress found for user {user_id}")
                return {
                    "status": "not_found",
                    "user_id": user_id,
                    "message": "No saved progress found"
                }
                
    except Exception as e:
        error_message = f"Error retrieving people & ops progress: {str(e)}"
        logging.error(f"‚ùå {error_message}")
        logging.error(f"üîç Error context: user_id={user_id}, error_type={type(e).__name__}")
        raise HTTPException(status_code=500, detail=error_message)
    finally:
        if conn:
            conn.close()

@app.get("/people_ops_reports/{user_id}")
async def get_user_people_ops_reports(user_id: str, auth: Dict = Depends(verify_jwt_token)):
    """Get all people & operations reports for a user"""

    # Permission check: user can only access their own reports
    if int(user_id) != auth["user_id"]:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="You can only access your own reports"
        )

    conn = None
    try:
        conn = get_people_ops_connection()
        with conn.cursor() as cur:
            sql = """
                SELECT report_id, report_type, status, created_at, completed_at, 
                       chunk_count, indexer_status, generation_metadata
                FROM people_ops_reports 
                WHERE user_id = %s 
                ORDER BY created_at DESC
            """
            
            cur.execute(sql, (user_id,))
            rows = cur.fetchall()
            
            reports = []
            for row in rows:
                report_id, report_type, status, created_at, completed_at, chunk_count, indexer_status, metadata = row
                
                reports.append({
                    "report_id": report_id,
                    "report_type": report_type,
                    "status": status,
                    "created_at": created_at.isoformat() if created_at else None,
                    "completed_at": completed_at.isoformat() if completed_at else None,
                    "chunk_count": chunk_count,
                    "indexer_status": indexer_status,
                    "metadata": metadata
                })
            
            return {
                "user_id": user_id,
                "total_reports": len(reports),
                "reports": reports
            }
            
    except Exception as e:
        logging.error(f"‚ùå Error getting people & ops reports: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if conn:
            conn.close()

@app.get("/notification_health")
async def check_notification_health():
    """Check notification system health (optional debugging endpoint)"""
    
    try:
        health_info = get_notification_system_health()
        
        logging.info(f"üìä Notification health check requested")
        logging.info(f"   - Active threads: {health_info['active_notification_threads']}")
        
        return {
            "status": "healthy",
            "health_info": health_info
        }
        
    except Exception as e:
        logging.error(f"‚ùå Error checking notification health: {str(e)}")
        return {
            "status": "error",
            "error": str(e)
        }

@app.get("/extract_qa_data/{user_id}")
async def extract_qa_data_endpoint(user_id: str, auth: Dict = Depends(verify_jwt_token)):
    """Extract Q&A data from all engines for a specific user (debugging endpoint)"""

    # Permission check: user can only access their own data
    if int(user_id) != auth["user_id"]:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="You can only access your own data"
        )

    try:
        logging.info(f"üéØ Extracting Q&A data for user {user_id} via API endpoint")
        
        qa_data = await extract_complete_qa_data_for_user(user_id)
        
        # Create summary for response
        summary = {
            "user_id": user_id,
            "extraction_timestamp": qa_data.get("extraction_timestamp"),
            "total_qa_pairs": qa_data.get("token_tracking", {}).get("qa_pairs_count", 0),
            "total_tokens": qa_data.get("token_tracking", {}).get("total_tokens", 0),
            "by_engine": qa_data.get("token_tracking", {}).get("by_engine", {}),
            "engines_with_data": [],
            "sample_data": {}
        }
        
        # Add engines with data and sample
        for engine, qa_list in qa_data.get("complete_qa_data", {}).items():
            if qa_list:
                summary["engines_with_data"].append(engine)
                # Add sample Q&A pair
                if len(qa_list) > 0:
                    sample = qa_list[0]
                    summary["sample_data"][engine] = {
                        "question_preview": sample.get("question", "")[:100] + "..." if len(sample.get("question", "")) > 100 else sample.get("question", ""),
                        "response_preview": str(sample.get("response", ""))[:100] + "..." if len(str(sample.get("response", ""))) > 100 else str(sample.get("response", ""))
                    }
        
        logging.info(f"‚úÖ Q&A extraction successful: {summary['total_qa_pairs']} pairs from {len(summary['engines_with_data'])} engines")
        
        return summary
        
    except Exception as e:
        error_message = f"Error extracting Q&A data: {str(e)}"
        logging.error(f"‚ùå {error_message}")
        raise HTTPException(status_code=500, detail=error_message)

# 1. ADD THIS SIMPLE DEBUG ENDPOINT (just copy-paste this)
@app.get("/check_indexer/{report_id}")
async def check_indexer(report_id: str):
    """Quick check if indexer completed - MINIMAL CODE CHANGE"""
    
    conn = None
    try:
        conn = get_people_ops_connection()
        with conn.cursor() as cur:
            sql = """
                SELECT 
                    indexer_job_id, indexer_status, indexer_triggered_at, 
                    indexer_completed_at, indexer_error_message
                FROM people_ops_reports 
                WHERE report_id = %s
            """
            cur.execute(sql, (report_id,))
            row = cur.fetchone()
            
            if row:
                job_id, status, triggered_at, completed_at, error_msg = row
                
                # Calculate time since trigger
                time_since_trigger = None
                if triggered_at:
                    time_since_trigger = (datetime.now() - triggered_at.replace(tzinfo=None)).total_seconds()
                
                # Simple status determination
                if status == "completed":
                    actual_status = "‚úÖ SUCCESS - Indexer completed!"
                elif status == "failed":
                    actual_status = f"‚ùå FAILED - {error_msg}"
                elif status == "triggered" and time_since_trigger and time_since_trigger > 600:
                    actual_status = "‚ùì LIKELY FAILED - No completion after 10+ minutes"
                elif status == "triggered":
                    actual_status = f"üîÑ UNKNOWN - Triggered {int(time_since_trigger)}s ago, no completion feedback"
                else:
                    actual_status = f"‚ùì UNKNOWN STATUS - {status}"
                
                return {
                    "report_id": report_id,
                    "indexer_job_id": job_id,
                    "database_status": status,
                    "actual_status": actual_status,
                    "time_since_trigger_seconds": int(time_since_trigger) if time_since_trigger else None,
                    "error_message": error_msg
                }
            else:
                return {"error": "Report not found", "report_id": report_id}
                
    except Exception as e:
        return {"error": str(e)}
    finally:
        if conn:
            conn.close()

# ======================================================
# STEP 4: Optional - Add reset endpoints for manual control
# ======================================================

@app.post("/reset_api_key/{key_suffix}")
async def reset_specific_api_key(key_suffix: str):
    """Reset a specific API key by suffix (last 4 characters)"""
    try:
        for api_key in GEMINI_API_KEYS:
            if api_key.endswith(key_suffix):
                reset_api_key_immediately(api_key)
                return {
                    "status": "success",
                    "message": f"API key ...{key_suffix} reset successfully",
                    "key_health": api_key_health.get(api_key, {})
                }
        
        return {"status": "error", "message": f"API key ending with {key_suffix} not found"}
        
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.post("/reset_all_failed_keys")
async def reset_all_failed_keys_endpoint():
    """Reset all failed API keys"""
    try:
        reset_count = reset_all_failed_api_keys()
        ecosystem_health = get_enhanced_api_key_status()
        
        return {
            "status": "success",
            "message": f"Reset {reset_count} failed API keys",
            "reset_count": reset_count,
            "ecosystem_health": ecosystem_health
        }
        
    except Exception as e:
        return {"status": "error", "message": str(e)}



# Main execution
if __name__ == "__main__":
    # Set up logging
    logger = setup_people_ops_logging()
    logger.info("üöÄ Starting Backable People & Operations Engine")
    
    # Get port from environment variable or use default
    port = int(os.environ.get("PORT", 8001))  # Different port from growth (8001) and component (8000)
    
    # Run with uvicorn for production
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=port,
        log_level="info",
        access_log=True,
        workers=1  # Single worker for optimal resource management
    )






